{
 "cells": [
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-02T14:20:02.392754Z",
     "start_time": "2025-11-02T14:14:18.065911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Simple GFlowNet Training with Variance Targeting\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "from gfn_environments.single_color_ramp import BlenderTerrainAPI\n",
    "from gfn_environments.single_color_ramp import (\n",
    "    ColorRampGFlowNet,\n",
    "    State,\n",
    "    ActionRegistry,\n",
    "    ReplayBuffer,\n",
    "    sample_trajectory_with_heightmaps\n",
    ")\n",
    "\n",
    "\n",
    "def train_variance_targeting_gfn(\n",
    "    target_variance_min: float = 0.3,\n",
    "    target_variance_max: float = 0.7,\n",
    "    num_epochs: int = 1000,\n",
    "    batch_size: int = 32,\n",
    "    buffer_capacity: int = 10000,\n",
    "    learning_rate: float = 1e-3,\n",
    "    initial_samples: int = 10000,\n",
    "    eval_interval: int = 100,\n",
    "    eval_samples: int = 100\n",
    "):\n",
    "    \"\"\"Train GFlowNet to generate terrains with variance in target range\"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    buffer = ReplayBuffer(capacity=buffer_capacity)\n",
    "    gfn = ColorRampGFlowNet(hidden_dim=128)\n",
    "    optimizer = optim.Adam(gfn.parameters(), lr=learning_rate)\n",
    "    blender_api = BlenderTerrainAPI()\n",
    "\n",
    "    # Log config\n",
    "    mlflow.log_params({\n",
    "        'target_variance_min': target_variance_min,\n",
    "        'target_variance_max': target_variance_max,\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'buffer_capacity': buffer_capacity,\n",
    "        'learning_rate': learning_rate,\n",
    "        'initial_samples': initial_samples,\n",
    "    })\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Training for variance range: [{target_variance_min:.3f}, {target_variance_max:.3f}]\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PHASE 1: Fill Buffer\n",
    "    # ========================================================================\n",
    "\n",
    "    print(f\"Phase 1: Filling buffer with {initial_samples} samples...\")\n",
    "\n",
    "    for i in range(initial_samples):\n",
    "        trajectory, final_state, heightmaps = sample_trajectory_with_heightmaps(\n",
    "            gfn, blender_api, max_steps=20\n",
    "        )\n",
    "\n",
    "        traj_id = buffer.add_trajectory(trajectory, final_state, heightmaps)\n",
    "        variance = heightmaps[-1].var().item()\n",
    "        buffer.add_reward(traj_id, 'variance', variance)\n",
    "\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"  Progress: {i + 1}/{initial_samples}\")\n",
    "\n",
    "    # Compute baseline\n",
    "    baseline_variances = [buffer.rewards[r.id]['variance'] for r in buffer.records]\n",
    "    baseline_in_range = sum(1 for v in baseline_variances\n",
    "                           if target_variance_min <= v <= target_variance_max)\n",
    "    baseline_success_rate = baseline_in_range / len(baseline_variances)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        'buffer/size': len(buffer),\n",
    "        'buffer/baseline_success_rate': baseline_success_rate,\n",
    "        'buffer/avg_variance': np.mean(baseline_variances),\n",
    "    }, step=0)\n",
    "\n",
    "    print(f\"✓ Buffer filled. Baseline success rate: {baseline_success_rate:.2%}\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PHASE 2: Training Loop\n",
    "    # ========================================================================\n",
    "\n",
    "    print(f\"Phase 2: Training for {num_epochs} epochs...\\n\")\n",
    "\n",
    "    best_success_rate = baseline_success_rate\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sample new trajectories and add to buffer\n",
    "        for _ in range(5):  # Add 5 new samples per epoch\n",
    "            trajectory, final_state, heightmaps = sample_trajectory_with_heightmaps(\n",
    "                gfn, blender_api, max_steps=20\n",
    "            )\n",
    "\n",
    "            traj_id = buffer.add_trajectory(trajectory, final_state, heightmaps)\n",
    "            variance = heightmaps[-1].var().item()\n",
    "            buffer.add_reward(traj_id, 'variance', variance)\n",
    "\n",
    "        # Compute rewards for all trajectories\n",
    "        for record in buffer.records:\n",
    "            traj_id = record.id\n",
    "            if traj_id in buffer.rewards:\n",
    "                var = buffer.rewards[traj_id]['variance']\n",
    "\n",
    "                # Simple reward: 1.0 if in range, decay outside\n",
    "                if target_variance_min <= var <= target_variance_max:\n",
    "                    reward = 1.0\n",
    "                else:\n",
    "                    distance = min(abs(var - target_variance_min),\n",
    "                                  abs(var - target_variance_max))\n",
    "                    reward = max(0.1, np.exp(-distance * 3))\n",
    "\n",
    "                buffer.add_reward(traj_id, 'reward', reward)\n",
    "\n",
    "        # Sample batch from buffer\n",
    "        import random\n",
    "        all_ids = [record.id for record in buffer.records]\n",
    "        batch_ids = random.sample(all_ids, min(batch_size, len(all_ids)))\n",
    "\n",
    "        # Train on batch\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for traj_id in batch_ids:\n",
    "            trajectory = buffer.get_trajectory(traj_id)\n",
    "            if trajectory is None:\n",
    "                continue\n",
    "\n",
    "            reward = buffer.rewards[traj_id].get('reward', 0.5)\n",
    "\n",
    "            # Forward pass through trajectory\n",
    "            optimizer.zero_grad()\n",
    "            traj_loss = 0.0\n",
    "            state = State()\n",
    "\n",
    "            for step in trajectory:\n",
    "                # Get policy logits\n",
    "                state_tensor = state.to_state_tensor().unsqueeze(0)\n",
    "                logits = gfn.policy(state_tensor).squeeze(0)\n",
    "\n",
    "                # Apply action mask\n",
    "                mask = state.to_action_mask()\n",
    "                masked_logits = torch.where(mask, logits, torch.tensor(-1e9))\n",
    "                log_probs = torch.nn.functional.log_softmax(masked_logits, dim=0)\n",
    "\n",
    "                # Get the action that was taken\n",
    "                target_action_idx = step['action_idx']\n",
    "\n",
    "                # Loss: negative log likelihood weighted by reward\n",
    "                step_loss = -log_probs[target_action_idx] * reward\n",
    "                traj_loss += step_loss\n",
    "\n",
    "                # Move to next state\n",
    "                state = state.apply_action(step['action_name'], step['value_idx'])\n",
    "\n",
    "            # Backprop\n",
    "            traj_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += traj_loss.item()\n",
    "\n",
    "        avg_loss = total_loss / len(batch_ids)\n",
    "\n",
    "        # Log training metrics\n",
    "        mlflow.log_metrics({\n",
    "            'train/loss': avg_loss,\n",
    "            'train/epoch': epoch,\n",
    "        }, step=epoch)\n",
    "\n",
    "        # Evaluation\n",
    "        if (epoch + 1) % eval_interval == 0 or epoch == 0:\n",
    "            print(f\"\\nEvaluating at epoch {epoch + 1}...\")\n",
    "\n",
    "            eval_variances = []\n",
    "            for _ in range(eval_samples):\n",
    "                trajectory, final_state, heightmaps = sample_trajectory_with_heightmaps(\n",
    "                    gfn, blender_api, max_steps=20\n",
    "                )\n",
    "                variance = heightmaps[-1].var().item()\n",
    "                eval_variances.append(variance)\n",
    "\n",
    "            in_range = sum(1 for v in eval_variances\n",
    "                          if target_variance_min <= v <= target_variance_max)\n",
    "            success_rate = in_range / len(eval_variances)\n",
    "            best_success_rate = max(best_success_rate, success_rate)\n",
    "\n",
    "            improvement = success_rate - baseline_success_rate\n",
    "\n",
    "            mlflow.log_metrics({\n",
    "                'eval/success_rate': success_rate,\n",
    "                'eval/best_success_rate': best_success_rate,\n",
    "                'eval/improvement': improvement,\n",
    "                'eval/avg_variance': np.mean(eval_variances),\n",
    "                'eval/std_variance': np.std(eval_variances),\n",
    "            }, step=epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:4d}: Loss={avg_loss:.4f}, \"\n",
    "                  f\"Success={success_rate:.2%}, Best={best_success_rate:.2%}, \"\n",
    "                  f\"Improve={improvement:+.2%}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Training Complete!\")\n",
    "    print(f\"  Best success rate: {best_success_rate:.2%}\")\n",
    "    print(f\"  Baseline: {baseline_success_rate:.2%}\")\n",
    "    print(f\"  Improvement: {best_success_rate - baseline_success_rate:+.2%}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return gfn, buffer, best_success_rate\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mlflow.set_experiment(\"gflownet_variance_targeting\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"simple_training\"):\n",
    "        trained_gfn, replay_buffer, best_rate = train_variance_targeting_gfn(\n",
    "            target_variance_min=0.3,\n",
    "            target_variance_max=0.7,\n",
    "            num_epochs=500,\n",
    "            batch_size=32,\n",
    "            learning_rate=1e-3,\n",
    "            initial_samples=10000,\n",
    "            eval_interval=100,\n",
    "            eval_samples=100\n",
    "        )\n",
    "\n",
    "        print(f\"\\n✓ Training complete. Best success rate: {best_rate:.2%}\")"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized GFlowNet:\n",
      "  Input dimension:  49\n",
      "  Output dimension: 46\n",
      "  Hidden dimension: 128\n",
      "Read blend: \"/home/jpleona/jpleona_c/bpygfn/gfn_environments/single_color_ramp.blend\"\n",
      "✓ Loaded template: /home/jpleona/jpleona_c/bpygfn/gfn_environments/single_color_ramp.blend\n",
      "================================================================================\n",
      "Training for variance range: [0.300, 0.700]\n",
      "================================================================================\n",
      "\n",
      "Phase 1: Filling buffer with 10000 samples...\n",
      "  Progress: 20/10000\n",
      "  Progress: 40/10000\n",
      "  Progress: 60/10000\n",
      "  Progress: 80/10000\n",
      "  Progress: 100/10000\n",
      "  Progress: 120/10000\n",
      "  Progress: 140/10000\n",
      "  Progress: 160/10000\n",
      "  Progress: 180/10000\n",
      "  Progress: 200/10000\n",
      "  Progress: 220/10000\n",
      "  Progress: 240/10000\n",
      "  Progress: 260/10000\n",
      "  Progress: 280/10000\n",
      "  Progress: 300/10000\n",
      "  Progress: 320/10000\n",
      "  Progress: 340/10000\n",
      "  Progress: 360/10000\n",
      "  Progress: 380/10000\n",
      "  Progress: 400/10000\n",
      "  Progress: 420/10000\n",
      "  Progress: 440/10000\n",
      "  Progress: 460/10000\n",
      "  Progress: 480/10000\n",
      "  Progress: 500/10000\n",
      "  Progress: 520/10000\n",
      "  Progress: 540/10000\n",
      "  Progress: 560/10000\n",
      "  Progress: 580/10000\n",
      "  Progress: 600/10000\n",
      "  Progress: 620/10000\n",
      "  Progress: 640/10000\n",
      "  Progress: 660/10000\n",
      "  Progress: 680/10000\n",
      "  Progress: 700/10000\n",
      "  Progress: 720/10000\n",
      "  Progress: 740/10000\n",
      "  Progress: 760/10000\n",
      "  Progress: 780/10000\n",
      "  Progress: 800/10000\n",
      "  Progress: 820/10000\n",
      "  Progress: 840/10000\n",
      "  Progress: 860/10000\n",
      "  Progress: 880/10000\n",
      "  Progress: 900/10000\n",
      "  Progress: 920/10000\n",
      "  Progress: 940/10000\n",
      "  Progress: 960/10000\n",
      "  Progress: 980/10000\n",
      "  Progress: 1000/10000\n",
      "  Progress: 1020/10000\n",
      "  Progress: 1040/10000\n",
      "  Progress: 1060/10000\n",
      "  Progress: 1080/10000\n",
      "  Progress: 1100/10000\n",
      "  Progress: 1120/10000\n",
      "  Progress: 1140/10000\n",
      "  Progress: 1160/10000\n",
      "  Progress: 1180/10000\n",
      "  Progress: 1200/10000\n",
      "  Progress: 1220/10000\n",
      "  Progress: 1240/10000\n",
      "  Progress: 1260/10000\n",
      "  Progress: 1280/10000\n",
      "  Progress: 1300/10000\n",
      "  Progress: 1320/10000\n",
      "  Progress: 1340/10000\n",
      "  Progress: 1360/10000\n",
      "  Progress: 1380/10000\n",
      "  Progress: 1400/10000\n",
      "  Progress: 1420/10000\n",
      "  Progress: 1440/10000\n",
      "  Progress: 1460/10000\n",
      "  Progress: 1480/10000\n",
      "  Progress: 1500/10000\n",
      "  Progress: 1520/10000\n",
      "  Progress: 1540/10000\n",
      "  Progress: 1560/10000\n",
      "  Progress: 1580/10000\n",
      "  Progress: 1600/10000\n",
      "  Progress: 1620/10000\n",
      "  Progress: 1640/10000\n",
      "  Progress: 1660/10000\n",
      "  Progress: 1680/10000\n",
      "  Progress: 1700/10000\n",
      "  Progress: 1720/10000\n",
      "  Progress: 1740/10000\n",
      "  Progress: 1760/10000\n",
      "  Progress: 1780/10000\n",
      "  Progress: 1800/10000\n",
      "  Progress: 1820/10000\n",
      "  Progress: 1840/10000\n",
      "  Progress: 1860/10000\n",
      "  Progress: 1880/10000\n",
      "  Progress: 1900/10000\n",
      "  Progress: 1920/10000\n",
      "  Progress: 1940/10000\n",
      "  Progress: 1960/10000\n",
      "  Progress: 1980/10000\n",
      "  Progress: 2000/10000\n",
      "  Progress: 2020/10000\n",
      "  Progress: 2040/10000\n",
      "  Progress: 2060/10000\n",
      "  Progress: 2080/10000\n",
      "  Progress: 2100/10000\n",
      "  Progress: 2120/10000\n",
      "  Progress: 2140/10000\n",
      "  Progress: 2160/10000\n",
      "  Progress: 2180/10000\n",
      "  Progress: 2200/10000\n",
      "  Progress: 2220/10000\n",
      "  Progress: 2240/10000\n",
      "  Progress: 2260/10000\n",
      "  Progress: 2280/10000\n",
      "  Progress: 2300/10000\n",
      "  Progress: 2320/10000\n",
      "  Progress: 2340/10000\n",
      "  Progress: 2360/10000\n",
      "  Progress: 2380/10000\n",
      "  Progress: 2400/10000\n",
      "  Progress: 2420/10000\n",
      "  Progress: 2440/10000\n",
      "  Progress: 2460/10000\n",
      "  Progress: 2480/10000\n",
      "  Progress: 2500/10000\n",
      "  Progress: 2520/10000\n",
      "  Progress: 2540/10000\n",
      "  Progress: 2560/10000\n",
      "  Progress: 2580/10000\n",
      "  Progress: 2600/10000\n",
      "  Progress: 2620/10000\n",
      "  Progress: 2640/10000\n",
      "  Progress: 2660/10000\n",
      "  Progress: 2680/10000\n",
      "  Progress: 2700/10000\n",
      "  Progress: 2720/10000\n",
      "  Progress: 2740/10000\n",
      "  Progress: 2760/10000\n",
      "  Progress: 2780/10000\n",
      "  Progress: 2800/10000\n",
      "  Progress: 2820/10000\n",
      "  Progress: 2840/10000\n",
      "  Progress: 2860/10000\n",
      "  Progress: 2880/10000\n",
      "  Progress: 2900/10000\n",
      "  Progress: 2920/10000\n",
      "  Progress: 2940/10000\n",
      "  Progress: 2960/10000\n",
      "  Progress: 2980/10000\n",
      "  Progress: 3000/10000\n",
      "  Progress: 3020/10000\n",
      "  Progress: 3040/10000\n",
      "  Progress: 3060/10000\n",
      "  Progress: 3080/10000\n",
      "  Progress: 3100/10000\n",
      "  Progress: 3120/10000\n",
      "  Progress: 3140/10000\n",
      "  Progress: 3160/10000\n",
      "  Progress: 3180/10000\n",
      "  Progress: 3200/10000\n",
      "  Progress: 3220/10000\n",
      "  Progress: 3240/10000\n",
      "  Progress: 3260/10000\n",
      "  Progress: 3280/10000\n",
      "  Progress: 3300/10000\n",
      "  Progress: 3320/10000\n",
      "  Progress: 3340/10000\n",
      "  Progress: 3360/10000\n",
      "  Progress: 3380/10000\n",
      "  Progress: 3400/10000\n",
      "  Progress: 3420/10000\n",
      "  Progress: 3440/10000\n",
      "  Progress: 3460/10000\n",
      "  Progress: 3480/10000\n",
      "  Progress: 3500/10000\n",
      "  Progress: 3520/10000\n",
      "  Progress: 3540/10000\n",
      "  Progress: 3560/10000\n",
      "  Progress: 3580/10000\n",
      "  Progress: 3600/10000\n",
      "  Progress: 3620/10000\n",
      "  Progress: 3640/10000\n",
      "  Progress: 3660/10000\n",
      "  Progress: 3680/10000\n",
      "  Progress: 3700/10000\n",
      "  Progress: 3720/10000\n",
      "  Progress: 3740/10000\n",
      "  Progress: 3760/10000\n",
      "  Progress: 3780/10000\n",
      "  Progress: 3800/10000\n",
      "  Progress: 3820/10000\n",
      "  Progress: 3840/10000\n",
      "  Progress: 3860/10000\n",
      "  Progress: 3880/10000\n",
      "  Progress: 3900/10000\n",
      "  Progress: 3920/10000\n",
      "  Progress: 3940/10000\n",
      "  Progress: 3960/10000\n",
      "  Progress: 3980/10000\n",
      "  Progress: 4000/10000\n",
      "  Progress: 4020/10000\n",
      "  Progress: 4040/10000\n",
      "  Progress: 4060/10000\n",
      "  Progress: 4080/10000\n",
      "  Progress: 4100/10000\n",
      "  Progress: 4120/10000\n",
      "  Progress: 4140/10000\n",
      "  Progress: 4160/10000\n",
      "  Progress: 4180/10000\n",
      "  Progress: 4200/10000\n",
      "  Progress: 4220/10000\n",
      "  Progress: 4240/10000\n",
      "  Progress: 4260/10000\n",
      "  Progress: 4280/10000\n",
      "  Progress: 4300/10000\n",
      "  Progress: 4320/10000\n",
      "  Progress: 4340/10000\n",
      "  Progress: 4360/10000\n",
      "  Progress: 4380/10000\n",
      "  Progress: 4400/10000\n",
      "  Progress: 4420/10000\n",
      "  Progress: 4440/10000\n",
      "  Progress: 4460/10000\n",
      "  Progress: 4480/10000\n",
      "  Progress: 4500/10000\n",
      "  Progress: 4520/10000\n",
      "  Progress: 4540/10000\n",
      "  Progress: 4560/10000\n",
      "  Progress: 4580/10000\n",
      "  Progress: 4600/10000\n",
      "  Progress: 4620/10000\n",
      "  Progress: 4640/10000\n",
      "  Progress: 4660/10000\n",
      "  Progress: 4680/10000\n",
      "  Progress: 4700/10000\n",
      "  Progress: 4720/10000\n",
      "  Progress: 4740/10000\n",
      "  Progress: 4760/10000\n",
      "  Progress: 4780/10000\n",
      "  Progress: 4800/10000\n",
      "  Progress: 4820/10000\n",
      "  Progress: 4840/10000\n",
      "  Progress: 4860/10000\n",
      "  Progress: 4880/10000\n",
      "  Progress: 4900/10000\n",
      "  Progress: 4920/10000\n",
      "  Progress: 4940/10000\n",
      "  Progress: 4960/10000\n",
      "  Progress: 4980/10000\n",
      "  Progress: 5000/10000\n",
      "  Progress: 5020/10000\n",
      "  Progress: 5040/10000\n",
      "  Progress: 5060/10000\n",
      "  Progress: 5080/10000\n",
      "  Progress: 5100/10000\n",
      "  Progress: 5120/10000\n",
      "  Progress: 5140/10000\n",
      "  Progress: 5160/10000\n",
      "  Progress: 5180/10000\n",
      "  Progress: 5200/10000\n",
      "  Progress: 5220/10000\n",
      "  Progress: 5240/10000\n",
      "  Progress: 5260/10000\n",
      "  Progress: 5280/10000\n",
      "  Progress: 5300/10000\n",
      "  Progress: 5320/10000\n",
      "  Progress: 5340/10000\n",
      "  Progress: 5360/10000\n",
      "  Progress: 5380/10000\n",
      "  Progress: 5400/10000\n",
      "  Progress: 5420/10000\n",
      "  Progress: 5440/10000\n",
      "  Progress: 5460/10000\n",
      "  Progress: 5480/10000\n",
      "  Progress: 5500/10000\n",
      "  Progress: 5520/10000\n",
      "  Progress: 5540/10000\n",
      "  Progress: 5560/10000\n",
      "  Progress: 5580/10000\n",
      "  Progress: 5600/10000\n",
      "  Progress: 5620/10000\n",
      "  Progress: 5640/10000\n",
      "  Progress: 5660/10000\n",
      "  Progress: 5680/10000\n",
      "  Progress: 5700/10000\n",
      "  Progress: 5720/10000\n",
      "  Progress: 5740/10000\n",
      "  Progress: 5760/10000\n",
      "  Progress: 5780/10000\n",
      "  Progress: 5800/10000\n",
      "  Progress: 5820/10000\n",
      "  Progress: 5840/10000\n",
      "  Progress: 5860/10000\n",
      "  Progress: 5880/10000\n",
      "  Progress: 5900/10000\n",
      "  Progress: 5920/10000\n",
      "  Progress: 5940/10000\n",
      "  Progress: 5960/10000\n",
      "  Progress: 5980/10000\n",
      "  Progress: 6000/10000\n",
      "  Progress: 6020/10000\n",
      "  Progress: 6040/10000\n",
      "  Progress: 6060/10000\n",
      "  Progress: 6080/10000\n",
      "  Progress: 6100/10000\n",
      "  Progress: 6120/10000\n",
      "  Progress: 6140/10000\n",
      "  Progress: 6160/10000\n",
      "  Progress: 6180/10000\n",
      "  Progress: 6200/10000\n",
      "  Progress: 6220/10000\n",
      "  Progress: 6240/10000\n",
      "  Progress: 6260/10000\n",
      "  Progress: 6280/10000\n",
      "  Progress: 6300/10000\n",
      "  Progress: 6320/10000\n",
      "  Progress: 6340/10000\n",
      "  Progress: 6360/10000\n",
      "  Progress: 6380/10000\n",
      "  Progress: 6400/10000\n",
      "  Progress: 6420/10000\n",
      "  Progress: 6440/10000\n",
      "  Progress: 6460/10000\n",
      "  Progress: 6480/10000\n",
      "  Progress: 6500/10000\n",
      "  Progress: 6520/10000\n",
      "  Progress: 6540/10000\n",
      "  Progress: 6560/10000\n",
      "  Progress: 6580/10000\n",
      "  Progress: 6600/10000\n",
      "  Progress: 6620/10000\n",
      "  Progress: 6640/10000\n",
      "  Progress: 6660/10000\n",
      "  Progress: 6680/10000\n",
      "  Progress: 6700/10000\n",
      "  Progress: 6720/10000\n",
      "  Progress: 6740/10000\n",
      "  Progress: 6760/10000\n",
      "  Progress: 6780/10000\n",
      "  Progress: 6800/10000\n",
      "  Progress: 6820/10000\n",
      "  Progress: 6840/10000\n",
      "  Progress: 6860/10000\n",
      "  Progress: 6880/10000\n",
      "  Progress: 6900/10000\n",
      "  Progress: 6920/10000\n",
      "  Progress: 6940/10000\n",
      "  Progress: 6960/10000\n",
      "  Progress: 6980/10000\n",
      "  Progress: 7000/10000\n",
      "  Progress: 7020/10000\n",
      "  Progress: 7040/10000\n",
      "  Progress: 7060/10000\n",
      "  Progress: 7080/10000\n",
      "  Progress: 7100/10000\n",
      "  Progress: 7120/10000\n",
      "  Progress: 7140/10000\n",
      "  Progress: 7160/10000\n",
      "  Progress: 7180/10000\n",
      "  Progress: 7200/10000\n",
      "  Progress: 7220/10000\n",
      "  Progress: 7240/10000\n",
      "  Progress: 7260/10000\n",
      "  Progress: 7280/10000\n",
      "  Progress: 7300/10000\n",
      "  Progress: 7320/10000\n",
      "  Progress: 7340/10000\n",
      "  Progress: 7360/10000\n",
      "  Progress: 7380/10000\n",
      "  Progress: 7400/10000\n",
      "  Progress: 7420/10000\n",
      "  Progress: 7440/10000\n",
      "  Progress: 7460/10000\n",
      "  Progress: 7480/10000\n",
      "  Progress: 7500/10000\n",
      "  Progress: 7520/10000\n",
      "  Progress: 7540/10000\n",
      "  Progress: 7560/10000\n",
      "  Progress: 7580/10000\n",
      "  Progress: 7600/10000\n",
      "  Progress: 7620/10000\n",
      "  Progress: 7640/10000\n",
      "  Progress: 7660/10000\n",
      "  Progress: 7680/10000\n",
      "  Progress: 7700/10000\n",
      "  Progress: 7720/10000\n",
      "  Progress: 7740/10000\n",
      "  Progress: 7760/10000\n",
      "  Progress: 7780/10000\n",
      "  Progress: 7800/10000\n",
      "  Progress: 7820/10000\n",
      "  Progress: 7840/10000\n",
      "  Progress: 7860/10000\n",
      "  Progress: 7880/10000\n",
      "  Progress: 7900/10000\n",
      "  Progress: 7920/10000\n",
      "  Progress: 7940/10000\n",
      "  Progress: 7960/10000\n",
      "  Progress: 7980/10000\n",
      "  Progress: 8000/10000\n",
      "  Progress: 8020/10000\n",
      "  Progress: 8040/10000\n",
      "  Progress: 8060/10000\n",
      "  Progress: 8080/10000\n",
      "  Progress: 8100/10000\n",
      "  Progress: 8120/10000\n",
      "  Progress: 8140/10000\n",
      "  Progress: 8160/10000\n",
      "  Progress: 8180/10000\n",
      "  Progress: 8200/10000\n",
      "  Progress: 8220/10000\n",
      "  Progress: 8240/10000\n",
      "  Progress: 8260/10000\n",
      "  Progress: 8280/10000\n",
      "  Progress: 8300/10000\n",
      "  Progress: 8320/10000\n",
      "  Progress: 8340/10000\n",
      "  Progress: 8360/10000\n",
      "  Progress: 8380/10000\n",
      "  Progress: 8400/10000\n",
      "  Progress: 8420/10000\n",
      "  Progress: 8440/10000\n",
      "  Progress: 8460/10000\n",
      "  Progress: 8480/10000\n",
      "  Progress: 8500/10000\n",
      "  Progress: 8520/10000\n",
      "  Progress: 8540/10000\n",
      "  Progress: 8560/10000\n",
      "  Progress: 8580/10000\n",
      "  Progress: 8600/10000\n",
      "  Progress: 8620/10000\n",
      "  Progress: 8640/10000\n",
      "  Progress: 8660/10000\n",
      "  Progress: 8680/10000\n",
      "  Progress: 8700/10000\n",
      "  Progress: 8720/10000\n",
      "  Progress: 8740/10000\n",
      "  Progress: 8760/10000\n",
      "  Progress: 8780/10000\n",
      "  Progress: 8800/10000\n",
      "  Progress: 8820/10000\n",
      "  Progress: 8840/10000\n",
      "  Progress: 8860/10000\n",
      "  Progress: 8880/10000\n",
      "  Progress: 8900/10000\n",
      "  Progress: 8920/10000\n",
      "  Progress: 8940/10000\n",
      "  Progress: 8960/10000\n",
      "  Progress: 8980/10000\n",
      "  Progress: 9000/10000\n",
      "  Progress: 9020/10000\n",
      "  Progress: 9040/10000\n",
      "  Progress: 9060/10000\n",
      "  Progress: 9080/10000\n",
      "  Progress: 9100/10000\n",
      "  Progress: 9120/10000\n",
      "  Progress: 9140/10000\n",
      "  Progress: 9160/10000\n",
      "  Progress: 9180/10000\n",
      "  Progress: 9200/10000\n",
      "  Progress: 9220/10000\n",
      "  Progress: 9240/10000\n",
      "  Progress: 9260/10000\n",
      "  Progress: 9280/10000\n",
      "  Progress: 9300/10000\n",
      "  Progress: 9320/10000\n",
      "  Progress: 9340/10000\n",
      "  Progress: 9360/10000\n",
      "  Progress: 9380/10000\n",
      "  Progress: 9400/10000\n",
      "  Progress: 9420/10000\n",
      "  Progress: 9440/10000\n",
      "  Progress: 9460/10000\n",
      "  Progress: 9480/10000\n",
      "  Progress: 9500/10000\n",
      "  Progress: 9520/10000\n",
      "  Progress: 9540/10000\n",
      "  Progress: 9560/10000\n",
      "  Progress: 9580/10000\n",
      "  Progress: 9600/10000\n",
      "  Progress: 9620/10000\n",
      "  Progress: 9640/10000\n",
      "  Progress: 9660/10000\n",
      "  Progress: 9680/10000\n",
      "  Progress: 9700/10000\n",
      "  Progress: 9720/10000\n",
      "  Progress: 9740/10000\n",
      "  Progress: 9760/10000\n",
      "  Progress: 9780/10000\n",
      "  Progress: 9800/10000\n",
      "  Progress: 9820/10000\n",
      "  Progress: 9840/10000\n",
      "  Progress: 9860/10000\n",
      "  Progress: 9880/10000\n",
      "  Progress: 9900/10000\n",
      "  Progress: 9920/10000\n",
      "  Progress: 9940/10000\n",
      "  Progress: 9960/10000\n",
      "  Progress: 9980/10000\n",
      "  Progress: 10000/10000\n",
      "✓ Buffer filled. Baseline success rate: 32.76%\n",
      "\n",
      "Phase 2: Training for 500 epochs...\n",
      "\n",
      "\n",
      "Evaluating at epoch 1...\n",
      "Epoch    1: Loss=44.1547, Success=32.00%, Best=32.76%, Improve=-0.76%\n",
      "\n",
      "Evaluating at epoch 100...\n",
      "Epoch  100: Loss=43.6390, Success=38.00%, Best=38.00%, Improve=+5.24%\n",
      "\n",
      "Evaluating at epoch 200...\n",
      "Epoch  200: Loss=44.8764, Success=42.00%, Best=42.00%, Improve=+9.24%\n",
      "\n",
      "Evaluating at epoch 300...\n",
      "Epoch  300: Loss=46.4777, Success=35.00%, Best=42.00%, Improve=+2.24%\n",
      "\n",
      "Evaluating at epoch 400...\n",
      "Epoch  400: Loss=50.1707, Success=36.00%, Best=42.00%, Improve=+3.24%\n",
      "\n",
      "Evaluating at epoch 500...\n",
      "Epoch  500: Loss=47.4443, Success=35.00%, Best=42.00%, Improve=+2.24%\n",
      "\n",
      "================================================================================\n",
      "Training Complete!\n",
      "  Best success rate: 42.00%\n",
      "  Baseline: 32.76%\n",
      "  Improvement: +9.24%\n",
      "================================================================================\n",
      "\n",
      "✓ Training complete. Best success rate: 42.00%\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:44:50.957344Z",
     "start_time": "2025-11-02T14:37:46.673340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "Simple GFlowNet Training with Variance Targeting\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import numpy as np\n",
    "\n",
    "from gfn_environments.single_color_ramp import BlenderTerrainAPI\n",
    "from gfn_environments.single_color_ramp import (\n",
    "    ColorRampGFlowNet,\n",
    "    State,\n",
    "    ActionRegistry,\n",
    "    ReplayBuffer,\n",
    "    sample_trajectory_with_heightmaps,\n",
    "    load_blend_single_color_ramp\n",
    ")\n",
    "\n",
    "\n",
    "def train_variance_targeting_gfn(\n",
    "    target_variance_min: float = 0.3,\n",
    "    target_variance_max: float = 0.7,\n",
    "    num_epochs: int = 1000,\n",
    "    batch_size: int = 32,\n",
    "    buffer_capacity: int = 1000,\n",
    "    learning_rate: float = 1e-3,\n",
    "    initial_samples: int = 100,\n",
    "    eval_interval: int = 50,\n",
    "    eval_samples: int = 20\n",
    "):\n",
    "    \"\"\"Train GFlowNet to generate terrains with variance in target range\"\"\"\n",
    "\n",
    "    # Initialize\n",
    "    load_blend_single_color_ramp()\n",
    "    buffer = ReplayBuffer(capacity=buffer_capacity)\n",
    "    gfn = ColorRampGFlowNet(hidden_dim=128)\n",
    "    optimizer = optim.Adam(gfn.parameters(), lr=learning_rate)\n",
    "    blender_api = BlenderTerrainAPI()\n",
    "\n",
    "    # Log config\n",
    "    mlflow.log_params({\n",
    "        'target_variance_min': target_variance_min,\n",
    "        'target_variance_max': target_variance_max,\n",
    "        'num_epochs': num_epochs,\n",
    "        'batch_size': batch_size,\n",
    "        'buffer_capacity': buffer_capacity,\n",
    "        'learning_rate': learning_rate,\n",
    "        'initial_samples': initial_samples,\n",
    "    })\n",
    "\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Training for variance range: [{target_variance_min:.3f}, {target_variance_max:.3f}]\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PHASE 1: Fill Buffer\n",
    "    # ========================================================================\n",
    "\n",
    "    print(f\"Phase 1: Filling buffer with {initial_samples} samples...\")\n",
    "\n",
    "    for i in range(initial_samples):\n",
    "        trajectory, final_state, heightmaps = sample_trajectory_with_heightmaps(\n",
    "            gfn, blender_api, max_steps=20\n",
    "        )\n",
    "\n",
    "        traj_id = buffer.add_trajectory(trajectory, final_state, heightmaps)\n",
    "        variance = heightmaps[-1].var().item()\n",
    "\n",
    "        # Compute reward immediately\n",
    "        if target_variance_min <= variance <= target_variance_max:\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            reward = 0.0\n",
    "\n",
    "        buffer.add_reward(traj_id, 'variance', variance)\n",
    "        buffer.add_reward(traj_id, 'reward', reward)\n",
    "\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"  Progress: {i + 1}/{initial_samples}\")\n",
    "\n",
    "    # Compute baseline\n",
    "    baseline_variances = [buffer.rewards[r.id]['variance'] for r in buffer.records]\n",
    "    baseline_in_range = sum(1 for v in baseline_variances\n",
    "                           if target_variance_min <= v <= target_variance_max)\n",
    "    baseline_success_rate = baseline_in_range / len(baseline_variances)\n",
    "\n",
    "    mlflow.log_metrics({\n",
    "        'buffer/size': len(buffer),\n",
    "        'buffer/baseline_success_rate': baseline_success_rate,\n",
    "        'buffer/avg_variance': np.mean(baseline_variances),\n",
    "    }, step=0)\n",
    "\n",
    "    print(f\"✓ Buffer filled. Baseline success rate: {baseline_success_rate:.2%}\\n\")\n",
    "\n",
    "    # ========================================================================\n",
    "    # PHASE 2: Training Loop\n",
    "    # ========================================================================\n",
    "\n",
    "    print(f\"Phase 2: Training for {num_epochs} epochs...\\n\")\n",
    "\n",
    "    best_success_rate = baseline_success_rate\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Sample new trajectories and add to buffer (ON-POLICY)\n",
    "        new_variances = []\n",
    "        for _ in range(5):  # Add 5 new samples per epoch\n",
    "            trajectory, final_state, heightmaps = sample_trajectory_with_heightmaps(\n",
    "                gfn, blender_api, max_steps=20\n",
    "            )\n",
    "\n",
    "            traj_id = buffer.add_trajectory(trajectory, final_state, heightmaps)\n",
    "            variance = heightmaps[-1].var().item()\n",
    "            new_variances.append(variance)\n",
    "\n",
    "            # Compute reward\n",
    "            if target_variance_min <= variance <= target_variance_max:\n",
    "                reward = 1.0\n",
    "            else:\n",
    "                distance = min(abs(variance - target_variance_min),\n",
    "                              abs(variance - target_variance_max))\n",
    "                reward = max(0.1, np.exp(-distance * 3))\n",
    "\n",
    "            buffer.add_reward(traj_id, 'variance', variance)\n",
    "            buffer.add_reward(traj_id, 'reward', reward)\n",
    "\n",
    "        # Sample batch from buffer\n",
    "        import random\n",
    "        all_ids = [record.id for record in buffer.records]\n",
    "        batch_ids = random.sample(all_ids, min(batch_size, len(all_ids)))\n",
    "\n",
    "        # SINGLE OPTIMIZER STEP FOR ENTIRE BATCH\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = 0.0\n",
    "\n",
    "        for traj_id in batch_ids:\n",
    "            trajectory = buffer.get_trajectory(traj_id)\n",
    "            if trajectory is None:\n",
    "                continue\n",
    "\n",
    "            reward = buffer.rewards[traj_id].get('reward', 0.5)\n",
    "\n",
    "            # Forward pass through trajectory\n",
    "            traj_loss = 0.0\n",
    "            state = State()\n",
    "\n",
    "            for step in trajectory:\n",
    "                # Get policy logits\n",
    "                state_tensor = state.to_state_tensor().unsqueeze(0)\n",
    "                logits = gfn.policy(state_tensor).squeeze(0)\n",
    "\n",
    "                # Apply action mask\n",
    "                mask = state.to_action_mask()\n",
    "                masked_logits = torch.where(mask, logits, torch.tensor(-1e9))\n",
    "                log_probs = torch.nn.functional.log_softmax(masked_logits, dim=0)\n",
    "\n",
    "                # Get the action that was taken\n",
    "                target_action_idx = step['action_idx']\n",
    "\n",
    "                # Loss: negative log likelihood weighted by reward\n",
    "                step_loss = -log_probs[target_action_idx] * reward\n",
    "                traj_loss += step_loss\n",
    "\n",
    "                # Move to next state\n",
    "                state = state.apply_action(step['action_name'], step['value_idx'])\n",
    "\n",
    "            batch_loss += traj_loss\n",
    "\n",
    "        # Single backprop for entire batch\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss = batch_loss.item() / len(batch_ids)\n",
    "\n",
    "        # Log training metrics\n",
    "        new_in_range = sum(1 for v in new_variances\n",
    "                          if target_variance_min <= v <= target_variance_max)\n",
    "        new_success_rate = new_in_range / len(new_variances) if new_variances else 0\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            'train/loss': avg_loss,\n",
    "            'train/new_success_rate': new_success_rate,\n",
    "            'train/avg_new_variance': np.mean(new_variances) if new_variances else 0,\n",
    "        }, step=epoch)\n",
    "\n",
    "        # Evaluation\n",
    "        if (epoch + 1) % eval_interval == 0 or epoch == 0:\n",
    "            print(f\"\\nEvaluating at epoch {epoch + 1}...\")\n",
    "\n",
    "            eval_variances = []\n",
    "            for _ in range(eval_samples):\n",
    "                trajectory, final_state, heightmaps = sample_trajectory_with_heightmaps(\n",
    "                    gfn, blender_api, max_steps=20\n",
    "                )\n",
    "                variance = heightmaps[-1].var().item()\n",
    "                eval_variances.append(variance)\n",
    "\n",
    "            in_range = sum(1 for v in eval_variances\n",
    "                          if target_variance_min <= v <= target_variance_max)\n",
    "            success_rate = in_range / len(eval_variances)\n",
    "            best_success_rate = max(best_success_rate, success_rate)\n",
    "\n",
    "            improvement = success_rate - baseline_success_rate\n",
    "\n",
    "            mlflow.log_metrics({\n",
    "                'eval/success_rate': success_rate,\n",
    "                'eval/best_success_rate': best_success_rate,\n",
    "                'eval/improvement': improvement,\n",
    "                'eval/avg_variance': np.mean(eval_variances),\n",
    "                'eval/std_variance': np.std(eval_variances),\n",
    "            }, step=epoch)\n",
    "\n",
    "            print(f\"Epoch {epoch+1:4d}: Loss={avg_loss:.4f}, \"\n",
    "                  f\"NewSuccess={new_success_rate:.2%}, \"\n",
    "                  f\"EvalSuccess={success_rate:.2%}, Best={best_success_rate:.2%}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"Training Complete!\")\n",
    "    print(f\"  Best success rate: {best_success_rate:.2%}\")\n",
    "    print(f\"  Baseline: {baseline_success_rate:.2%}\")\n",
    "    print(f\"  Improvement: {best_success_rate - baseline_success_rate:+.2%}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    return gfn, buffer, best_success_rate\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mlflow.set_experiment(\"gflownet_variance_targeting\")\n",
    "\n",
    "    with mlflow.start_run(run_name=\"simple_training\"):\n",
    "        trained_gfn, replay_buffer, best_rate = train_variance_targeting_gfn(\n",
    "            target_variance_min=0.3,\n",
    "            target_variance_max=0.7,\n",
    "            num_epochs=1000,\n",
    "            batch_size=32,\n",
    "            learning_rate=1e-3,\n",
    "            initial_samples=10000,\n",
    "            eval_interval=200,\n",
    "            eval_samples=50\n",
    "        )\n",
    "\n",
    "        print(f\"\\n✓ Training complete. Best success rate: {best_rate:.2%}\")"
   ],
   "id": "8707f7a578796e78",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read blend: \"/home/jpleona/jpleona_c/bpygfn/gfn_environments/single_color_ramp.blend\"\n",
      "✓ Loaded template: /home/jpleona/jpleona_c/bpygfn/gfn_environments/single_color_ramp.blend\n",
      "Initialized GFlowNet:\n",
      "  Input dimension:  49\n",
      "  Output dimension: 46\n",
      "  Hidden dimension: 128\n",
      "Read blend: \"/home/jpleona/jpleona_c/bpygfn/gfn_environments/single_color_ramp.blend\"\n",
      "✓ Loaded template: /home/jpleona/jpleona_c/bpygfn/gfn_environments/single_color_ramp.blend\n",
      "================================================================================\n",
      "Training for variance range: [0.300, 0.700]\n",
      "================================================================================\n",
      "\n",
      "Phase 1: Filling buffer with 10000 samples...\n",
      "  Progress: 20/10000\n",
      "  Progress: 40/10000\n",
      "  Progress: 60/10000\n",
      "  Progress: 80/10000\n",
      "  Progress: 100/10000\n",
      "  Progress: 120/10000\n",
      "  Progress: 140/10000\n",
      "  Progress: 160/10000\n",
      "  Progress: 180/10000\n",
      "  Progress: 200/10000\n",
      "  Progress: 220/10000\n",
      "  Progress: 240/10000\n",
      "  Progress: 260/10000\n",
      "  Progress: 280/10000\n",
      "  Progress: 300/10000\n",
      "  Progress: 320/10000\n",
      "  Progress: 340/10000\n",
      "  Progress: 360/10000\n",
      "  Progress: 380/10000\n",
      "  Progress: 400/10000\n",
      "  Progress: 420/10000\n",
      "  Progress: 440/10000\n",
      "  Progress: 460/10000\n",
      "  Progress: 480/10000\n",
      "  Progress: 500/10000\n",
      "  Progress: 520/10000\n",
      "  Progress: 540/10000\n",
      "  Progress: 560/10000\n",
      "  Progress: 580/10000\n",
      "  Progress: 600/10000\n",
      "  Progress: 620/10000\n",
      "  Progress: 640/10000\n",
      "  Progress: 660/10000\n",
      "  Progress: 680/10000\n",
      "  Progress: 700/10000\n",
      "  Progress: 720/10000\n",
      "  Progress: 740/10000\n",
      "  Progress: 760/10000\n",
      "  Progress: 780/10000\n",
      "  Progress: 800/10000\n",
      "  Progress: 820/10000\n",
      "  Progress: 840/10000\n",
      "  Progress: 860/10000\n",
      "  Progress: 880/10000\n",
      "  Progress: 900/10000\n",
      "  Progress: 920/10000\n",
      "  Progress: 940/10000\n",
      "  Progress: 960/10000\n",
      "  Progress: 980/10000\n",
      "  Progress: 1000/10000\n",
      "  Progress: 1020/10000\n",
      "  Progress: 1040/10000\n",
      "  Progress: 1060/10000\n",
      "  Progress: 1080/10000\n",
      "  Progress: 1100/10000\n",
      "  Progress: 1120/10000\n",
      "  Progress: 1140/10000\n",
      "  Progress: 1160/10000\n",
      "  Progress: 1180/10000\n",
      "  Progress: 1200/10000\n",
      "  Progress: 1220/10000\n",
      "  Progress: 1240/10000\n",
      "  Progress: 1260/10000\n",
      "  Progress: 1280/10000\n",
      "  Progress: 1300/10000\n",
      "  Progress: 1320/10000\n",
      "  Progress: 1340/10000\n",
      "  Progress: 1360/10000\n",
      "  Progress: 1380/10000\n",
      "  Progress: 1400/10000\n",
      "  Progress: 1420/10000\n",
      "  Progress: 1440/10000\n",
      "  Progress: 1460/10000\n",
      "  Progress: 1480/10000\n",
      "  Progress: 1500/10000\n",
      "  Progress: 1520/10000\n",
      "  Progress: 1540/10000\n",
      "  Progress: 1560/10000\n",
      "  Progress: 1580/10000\n",
      "  Progress: 1600/10000\n",
      "  Progress: 1620/10000\n",
      "  Progress: 1640/10000\n",
      "  Progress: 1660/10000\n",
      "  Progress: 1680/10000\n",
      "  Progress: 1700/10000\n",
      "  Progress: 1720/10000\n",
      "  Progress: 1740/10000\n",
      "  Progress: 1760/10000\n",
      "  Progress: 1780/10000\n",
      "  Progress: 1800/10000\n",
      "  Progress: 1820/10000\n",
      "  Progress: 1840/10000\n",
      "  Progress: 1860/10000\n",
      "  Progress: 1880/10000\n",
      "  Progress: 1900/10000\n",
      "  Progress: 1920/10000\n",
      "  Progress: 1940/10000\n",
      "  Progress: 1960/10000\n",
      "  Progress: 1980/10000\n",
      "  Progress: 2000/10000\n",
      "  Progress: 2020/10000\n",
      "  Progress: 2040/10000\n",
      "  Progress: 2060/10000\n",
      "  Progress: 2080/10000\n",
      "  Progress: 2100/10000\n",
      "  Progress: 2120/10000\n",
      "  Progress: 2140/10000\n",
      "  Progress: 2160/10000\n",
      "  Progress: 2180/10000\n",
      "  Progress: 2200/10000\n",
      "  Progress: 2220/10000\n",
      "  Progress: 2240/10000\n",
      "  Progress: 2260/10000\n",
      "  Progress: 2280/10000\n",
      "  Progress: 2300/10000\n",
      "  Progress: 2320/10000\n",
      "  Progress: 2340/10000\n",
      "  Progress: 2360/10000\n",
      "  Progress: 2380/10000\n",
      "  Progress: 2400/10000\n",
      "  Progress: 2420/10000\n",
      "  Progress: 2440/10000\n",
      "  Progress: 2460/10000\n",
      "  Progress: 2480/10000\n",
      "  Progress: 2500/10000\n",
      "  Progress: 2520/10000\n",
      "  Progress: 2540/10000\n",
      "  Progress: 2560/10000\n",
      "  Progress: 2580/10000\n",
      "  Progress: 2600/10000\n",
      "  Progress: 2620/10000\n",
      "  Progress: 2640/10000\n",
      "  Progress: 2660/10000\n",
      "  Progress: 2680/10000\n",
      "  Progress: 2700/10000\n",
      "  Progress: 2720/10000\n",
      "  Progress: 2740/10000\n",
      "  Progress: 2760/10000\n",
      "  Progress: 2780/10000\n",
      "  Progress: 2800/10000\n",
      "  Progress: 2820/10000\n",
      "  Progress: 2840/10000\n",
      "  Progress: 2860/10000\n",
      "  Progress: 2880/10000\n",
      "  Progress: 2900/10000\n",
      "  Progress: 2920/10000\n",
      "  Progress: 2940/10000\n",
      "  Progress: 2960/10000\n",
      "  Progress: 2980/10000\n",
      "  Progress: 3000/10000\n",
      "  Progress: 3020/10000\n",
      "  Progress: 3040/10000\n",
      "  Progress: 3060/10000\n",
      "  Progress: 3080/10000\n",
      "  Progress: 3100/10000\n",
      "  Progress: 3120/10000\n",
      "  Progress: 3140/10000\n",
      "  Progress: 3160/10000\n",
      "  Progress: 3180/10000\n",
      "  Progress: 3200/10000\n",
      "  Progress: 3220/10000\n",
      "  Progress: 3240/10000\n",
      "  Progress: 3260/10000\n",
      "  Progress: 3280/10000\n",
      "  Progress: 3300/10000\n",
      "  Progress: 3320/10000\n",
      "  Progress: 3340/10000\n",
      "  Progress: 3360/10000\n",
      "  Progress: 3380/10000\n",
      "  Progress: 3400/10000\n",
      "  Progress: 3420/10000\n",
      "  Progress: 3440/10000\n",
      "  Progress: 3460/10000\n",
      "  Progress: 3480/10000\n",
      "  Progress: 3500/10000\n",
      "  Progress: 3520/10000\n",
      "  Progress: 3540/10000\n",
      "  Progress: 3560/10000\n",
      "  Progress: 3580/10000\n",
      "  Progress: 3600/10000\n",
      "  Progress: 3620/10000\n",
      "  Progress: 3640/10000\n",
      "  Progress: 3660/10000\n",
      "  Progress: 3680/10000\n",
      "  Progress: 3700/10000\n",
      "  Progress: 3720/10000\n",
      "  Progress: 3740/10000\n",
      "  Progress: 3760/10000\n",
      "  Progress: 3780/10000\n",
      "  Progress: 3800/10000\n",
      "  Progress: 3820/10000\n",
      "  Progress: 3840/10000\n",
      "  Progress: 3860/10000\n",
      "  Progress: 3880/10000\n",
      "  Progress: 3900/10000\n",
      "  Progress: 3920/10000\n",
      "  Progress: 3940/10000\n",
      "  Progress: 3960/10000\n",
      "  Progress: 3980/10000\n",
      "  Progress: 4000/10000\n",
      "  Progress: 4020/10000\n",
      "  Progress: 4040/10000\n",
      "  Progress: 4060/10000\n",
      "  Progress: 4080/10000\n",
      "  Progress: 4100/10000\n",
      "  Progress: 4120/10000\n",
      "  Progress: 4140/10000\n",
      "  Progress: 4160/10000\n",
      "  Progress: 4180/10000\n",
      "  Progress: 4200/10000\n",
      "  Progress: 4220/10000\n",
      "  Progress: 4240/10000\n",
      "  Progress: 4260/10000\n",
      "  Progress: 4280/10000\n",
      "  Progress: 4300/10000\n",
      "  Progress: 4320/10000\n",
      "  Progress: 4340/10000\n",
      "  Progress: 4360/10000\n",
      "  Progress: 4380/10000\n",
      "  Progress: 4400/10000\n",
      "  Progress: 4420/10000\n",
      "  Progress: 4440/10000\n",
      "  Progress: 4460/10000\n",
      "  Progress: 4480/10000\n",
      "  Progress: 4500/10000\n",
      "  Progress: 4520/10000\n",
      "  Progress: 4540/10000\n",
      "  Progress: 4560/10000\n",
      "  Progress: 4580/10000\n",
      "  Progress: 4600/10000\n",
      "  Progress: 4620/10000\n",
      "  Progress: 4640/10000\n",
      "  Progress: 4660/10000\n",
      "  Progress: 4680/10000\n",
      "  Progress: 4700/10000\n",
      "  Progress: 4720/10000\n",
      "  Progress: 4740/10000\n",
      "  Progress: 4760/10000\n",
      "  Progress: 4780/10000\n",
      "  Progress: 4800/10000\n",
      "  Progress: 4820/10000\n",
      "  Progress: 4840/10000\n",
      "  Progress: 4860/10000\n",
      "  Progress: 4880/10000\n",
      "  Progress: 4900/10000\n",
      "  Progress: 4920/10000\n",
      "  Progress: 4940/10000\n",
      "  Progress: 4960/10000\n",
      "  Progress: 4980/10000\n",
      "  Progress: 5000/10000\n",
      "  Progress: 5020/10000\n",
      "  Progress: 5040/10000\n",
      "  Progress: 5060/10000\n",
      "  Progress: 5080/10000\n",
      "  Progress: 5100/10000\n",
      "  Progress: 5120/10000\n",
      "  Progress: 5140/10000\n",
      "  Progress: 5160/10000\n",
      "  Progress: 5180/10000\n",
      "  Progress: 5200/10000\n",
      "  Progress: 5220/10000\n",
      "  Progress: 5240/10000\n",
      "  Progress: 5260/10000\n",
      "  Progress: 5280/10000\n",
      "  Progress: 5300/10000\n",
      "  Progress: 5320/10000\n",
      "  Progress: 5340/10000\n",
      "  Progress: 5360/10000\n",
      "  Progress: 5380/10000\n",
      "  Progress: 5400/10000\n",
      "  Progress: 5420/10000\n",
      "  Progress: 5440/10000\n",
      "  Progress: 5460/10000\n",
      "  Progress: 5480/10000\n",
      "  Progress: 5500/10000\n",
      "  Progress: 5520/10000\n",
      "  Progress: 5540/10000\n",
      "  Progress: 5560/10000\n",
      "  Progress: 5580/10000\n",
      "  Progress: 5600/10000\n",
      "  Progress: 5620/10000\n",
      "  Progress: 5640/10000\n",
      "  Progress: 5660/10000\n",
      "  Progress: 5680/10000\n",
      "  Progress: 5700/10000\n",
      "  Progress: 5720/10000\n",
      "  Progress: 5740/10000\n",
      "  Progress: 5760/10000\n",
      "  Progress: 5780/10000\n",
      "  Progress: 5800/10000\n",
      "  Progress: 5820/10000\n",
      "  Progress: 5840/10000\n",
      "  Progress: 5860/10000\n",
      "  Progress: 5880/10000\n",
      "  Progress: 5900/10000\n",
      "  Progress: 5920/10000\n",
      "  Progress: 5940/10000\n",
      "  Progress: 5960/10000\n",
      "  Progress: 5980/10000\n",
      "  Progress: 6000/10000\n",
      "  Progress: 6020/10000\n",
      "  Progress: 6040/10000\n",
      "  Progress: 6060/10000\n",
      "  Progress: 6080/10000\n",
      "  Progress: 6100/10000\n",
      "  Progress: 6120/10000\n",
      "  Progress: 6140/10000\n",
      "  Progress: 6160/10000\n",
      "  Progress: 6180/10000\n",
      "  Progress: 6200/10000\n",
      "  Progress: 6220/10000\n",
      "  Progress: 6240/10000\n",
      "  Progress: 6260/10000\n",
      "  Progress: 6280/10000\n",
      "  Progress: 6300/10000\n",
      "  Progress: 6320/10000\n",
      "  Progress: 6340/10000\n",
      "  Progress: 6360/10000\n",
      "  Progress: 6380/10000\n",
      "  Progress: 6400/10000\n",
      "  Progress: 6420/10000\n",
      "  Progress: 6440/10000\n",
      "  Progress: 6460/10000\n",
      "  Progress: 6480/10000\n",
      "  Progress: 6500/10000\n",
      "  Progress: 6520/10000\n",
      "  Progress: 6540/10000\n",
      "  Progress: 6560/10000\n",
      "  Progress: 6580/10000\n",
      "  Progress: 6600/10000\n",
      "  Progress: 6620/10000\n",
      "  Progress: 6640/10000\n",
      "  Progress: 6660/10000\n",
      "  Progress: 6680/10000\n",
      "  Progress: 6700/10000\n",
      "  Progress: 6720/10000\n",
      "  Progress: 6740/10000\n",
      "  Progress: 6760/10000\n",
      "  Progress: 6780/10000\n",
      "  Progress: 6800/10000\n",
      "  Progress: 6820/10000\n",
      "  Progress: 6840/10000\n",
      "  Progress: 6860/10000\n",
      "  Progress: 6880/10000\n",
      "  Progress: 6900/10000\n",
      "  Progress: 6920/10000\n",
      "  Progress: 6940/10000\n",
      "  Progress: 6960/10000\n",
      "  Progress: 6980/10000\n",
      "  Progress: 7000/10000\n",
      "  Progress: 7020/10000\n",
      "  Progress: 7040/10000\n",
      "  Progress: 7060/10000\n",
      "  Progress: 7080/10000\n",
      "  Progress: 7100/10000\n",
      "  Progress: 7120/10000\n",
      "  Progress: 7140/10000\n",
      "  Progress: 7160/10000\n",
      "  Progress: 7180/10000\n",
      "  Progress: 7200/10000\n",
      "  Progress: 7220/10000\n",
      "  Progress: 7240/10000\n",
      "  Progress: 7260/10000\n",
      "  Progress: 7280/10000\n",
      "  Progress: 7300/10000\n",
      "  Progress: 7320/10000\n",
      "  Progress: 7340/10000\n",
      "  Progress: 7360/10000\n",
      "  Progress: 7380/10000\n",
      "  Progress: 7400/10000\n",
      "  Progress: 7420/10000\n",
      "  Progress: 7440/10000\n",
      "  Progress: 7460/10000\n",
      "  Progress: 7480/10000\n",
      "  Progress: 7500/10000\n",
      "  Progress: 7520/10000\n",
      "  Progress: 7540/10000\n",
      "  Progress: 7560/10000\n",
      "  Progress: 7580/10000\n",
      "  Progress: 7600/10000\n",
      "  Progress: 7620/10000\n",
      "  Progress: 7640/10000\n",
      "  Progress: 7660/10000\n",
      "  Progress: 7680/10000\n",
      "  Progress: 7700/10000\n",
      "  Progress: 7720/10000\n",
      "  Progress: 7740/10000\n",
      "  Progress: 7760/10000\n",
      "  Progress: 7780/10000\n",
      "  Progress: 7800/10000\n",
      "  Progress: 7820/10000\n",
      "  Progress: 7840/10000\n",
      "  Progress: 7860/10000\n",
      "  Progress: 7880/10000\n",
      "  Progress: 7900/10000\n",
      "  Progress: 7920/10000\n",
      "  Progress: 7940/10000\n",
      "  Progress: 7960/10000\n",
      "  Progress: 7980/10000\n",
      "  Progress: 8000/10000\n",
      "  Progress: 8020/10000\n",
      "  Progress: 8040/10000\n",
      "  Progress: 8060/10000\n",
      "  Progress: 8080/10000\n",
      "  Progress: 8100/10000\n",
      "  Progress: 8120/10000\n",
      "  Progress: 8140/10000\n",
      "  Progress: 8160/10000\n",
      "  Progress: 8180/10000\n",
      "  Progress: 8200/10000\n",
      "  Progress: 8220/10000\n",
      "  Progress: 8240/10000\n",
      "  Progress: 8260/10000\n",
      "  Progress: 8280/10000\n",
      "  Progress: 8300/10000\n",
      "  Progress: 8320/10000\n",
      "  Progress: 8340/10000\n",
      "  Progress: 8360/10000\n",
      "  Progress: 8380/10000\n",
      "  Progress: 8400/10000\n",
      "  Progress: 8420/10000\n",
      "  Progress: 8440/10000\n",
      "  Progress: 8460/10000\n",
      "  Progress: 8480/10000\n",
      "  Progress: 8500/10000\n",
      "  Progress: 8520/10000\n",
      "  Progress: 8540/10000\n",
      "  Progress: 8560/10000\n",
      "  Progress: 8580/10000\n",
      "  Progress: 8600/10000\n",
      "  Progress: 8620/10000\n",
      "  Progress: 8640/10000\n",
      "  Progress: 8660/10000\n",
      "  Progress: 8680/10000\n",
      "  Progress: 8700/10000\n",
      "  Progress: 8720/10000\n",
      "  Progress: 8740/10000\n",
      "  Progress: 8760/10000\n",
      "  Progress: 8780/10000\n",
      "  Progress: 8800/10000\n",
      "  Progress: 8820/10000\n",
      "  Progress: 8840/10000\n",
      "  Progress: 8860/10000\n",
      "  Progress: 8880/10000\n",
      "  Progress: 8900/10000\n",
      "  Progress: 8920/10000\n",
      "  Progress: 8940/10000\n",
      "  Progress: 8960/10000\n",
      "  Progress: 8980/10000\n",
      "  Progress: 9000/10000\n",
      "  Progress: 9020/10000\n",
      "  Progress: 9040/10000\n",
      "  Progress: 9060/10000\n",
      "  Progress: 9080/10000\n",
      "  Progress: 9100/10000\n",
      "  Progress: 9120/10000\n",
      "  Progress: 9140/10000\n",
      "  Progress: 9160/10000\n",
      "  Progress: 9180/10000\n",
      "  Progress: 9200/10000\n",
      "  Progress: 9220/10000\n",
      "  Progress: 9240/10000\n",
      "  Progress: 9260/10000\n",
      "  Progress: 9280/10000\n",
      "  Progress: 9300/10000\n",
      "  Progress: 9320/10000\n",
      "  Progress: 9340/10000\n",
      "  Progress: 9360/10000\n",
      "  Progress: 9380/10000\n",
      "  Progress: 9400/10000\n",
      "  Progress: 9420/10000\n",
      "  Progress: 9440/10000\n",
      "  Progress: 9460/10000\n",
      "  Progress: 9480/10000\n",
      "  Progress: 9500/10000\n",
      "  Progress: 9520/10000\n",
      "  Progress: 9540/10000\n",
      "  Progress: 9560/10000\n",
      "  Progress: 9580/10000\n",
      "  Progress: 9600/10000\n",
      "  Progress: 9620/10000\n",
      "  Progress: 9640/10000\n",
      "  Progress: 9660/10000\n",
      "  Progress: 9680/10000\n",
      "  Progress: 9700/10000\n",
      "  Progress: 9720/10000\n",
      "  Progress: 9740/10000\n",
      "  Progress: 9760/10000\n",
      "  Progress: 9780/10000\n",
      "  Progress: 9800/10000\n",
      "  Progress: 9820/10000\n",
      "  Progress: 9840/10000\n",
      "  Progress: 9860/10000\n",
      "  Progress: 9880/10000\n",
      "  Progress: 9900/10000\n",
      "  Progress: 9920/10000\n",
      "  Progress: 9940/10000\n",
      "  Progress: 9960/10000\n",
      "  Progress: 9980/10000\n",
      "  Progress: 10000/10000\n",
      "✓ Buffer filled. Baseline success rate: 32.30%\n",
      "\n",
      "Phase 2: Training for 1000 epochs...\n",
      "\n",
      "\n",
      "Evaluating at epoch 1...\n",
      "Epoch    1: Loss=16.0558, NewSuccess=20.00%, EvalSuccess=32.00%, Best=32.30%\n",
      "\n",
      "Evaluating at epoch 200...\n",
      "Epoch  200: Loss=47.2313, NewSuccess=40.00%, EvalSuccess=44.00%, Best=44.00%\n",
      "\n",
      "Evaluating at epoch 400...\n",
      "Epoch  400: Loss=50.2828, NewSuccess=60.00%, EvalSuccess=42.00%, Best=44.00%\n",
      "\n",
      "Evaluating at epoch 600...\n",
      "Epoch  600: Loss=53.3674, NewSuccess=100.00%, EvalSuccess=52.00%, Best=52.00%\n",
      "\n",
      "Evaluating at epoch 800...\n",
      "Epoch  800: Loss=57.9596, NewSuccess=20.00%, EvalSuccess=54.00%, Best=54.00%\n",
      "\n",
      "Evaluating at epoch 1000...\n",
      "Epoch 1000: Loss=53.0745, NewSuccess=20.00%, EvalSuccess=46.00%, Best=54.00%\n",
      "\n",
      "================================================================================\n",
      "Training Complete!\n",
      "  Best success rate: 54.00%\n",
      "  Baseline: 32.30%\n",
      "  Improvement: +21.70%\n",
      "================================================================================\n",
      "\n",
      "✓ Training complete. Best success rate: 54.00%\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
