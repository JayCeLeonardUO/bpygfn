{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "680ed921-54f2-4e86-bc10-01bc092ec965",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Peaks Probability Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ae9c5f-86c9-468b-a7e4-7205f555e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class ColorRampPoint:\n",
    "    \"\"\"A single control point in the color ramp\"\"\"\n",
    "    position: float  # 0.0 to 1.0\n",
    "    value: float     # height multiplier\n",
    "\n",
    "@dataclass \n",
    "class GeometryComposition:\n",
    "    \"\"\"Represents a complete geometry node composition\"\"\"\n",
    "    noise_scale: float\n",
    "    color_ramp_points: List[ColorRampPoint]\n",
    "    position_strength: float\n",
    "\n",
    "class Peak3DVisualizer:\n",
    "    \"\"\"3D visualization of peak detection for geometry node height fields\"\"\"\n",
    "    \n",
    "    def __init__(self, grid_size=32, threshold=0.3):\n",
    "        self.grid_size = grid_size\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def generate_height_field(self, composition: GeometryComposition) -> np.ndarray:\n",
    "        \"\"\"Generate height field from geometry node composition\"\"\"\n",
    "        # Create noise field\n",
    "        x = np.linspace(0, composition.noise_scale, self.grid_size)\n",
    "        y = np.linspace(0, composition.noise_scale, self.grid_size)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        \n",
    "        # Simple noise (using sine waves for reproducibility)\n",
    "        noise = (np.sin(X) * np.cos(Y) + \n",
    "                np.sin(2*X) * np.cos(3*Y) + \n",
    "                np.sin(3*X) * np.cos(2*Y)) / 3.0\n",
    "        \n",
    "        # Normalize to 0-1\n",
    "        noise = (noise - noise.min()) / (noise.max() - noise.min())\n",
    "        \n",
    "        # Apply color ramp transformation\n",
    "        height_field = self.apply_color_ramp(noise, composition.color_ramp_points)\n",
    "        \n",
    "        # Apply position strength\n",
    "        height_field *= composition.position_strength\n",
    "        \n",
    "        return height_field\n",
    "    \n",
    "    def apply_color_ramp(self, noise_field: np.ndarray, ramp_points: List[ColorRampPoint]) -> np.ndarray:\n",
    "        \"\"\"Apply color ramp transformation to noise field\"\"\"\n",
    "        # Sort points by position\n",
    "        points = sorted(ramp_points, key=lambda p: p.position)\n",
    "        \n",
    "        result = np.zeros_like(noise_field)\n",
    "        \n",
    "        for i in range(len(noise_field)):\n",
    "            for j in range(len(noise_field[0])):\n",
    "                noise_val = noise_field[i, j]\n",
    "                \n",
    "                # Find interpolation range\n",
    "                if noise_val <= points[0].position:\n",
    "                    result[i, j] = points[0].value\n",
    "                elif noise_val >= points[-1].position:\n",
    "                    result[i, j] = points[-1].value\n",
    "                else:\n",
    "                    # Linear interpolation between points\n",
    "                    for k in range(len(points) - 1):\n",
    "                        if points[k].position <= noise_val <= points[k+1].position:\n",
    "                            t = (noise_val - points[k].position) / (points[k+1].position - points[k].position)\n",
    "                            result[i, j] = points[k].value + t * (points[k+1].value - points[k].value)\n",
    "                            break\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def count_peaks(self, height_field: np.ndarray) -> int:\n",
    "        \"\"\"Count distinct peaks/islands using simple flood fill\"\"\"\n",
    "        # Threshold the height field\n",
    "        binary = height_field > self.threshold\n",
    "        \n",
    "        # Connected component labeling (simple flood fill)\n",
    "        visited = np.zeros_like(binary, dtype=bool)\n",
    "        peak_count = 0\n",
    "        \n",
    "        for i in range(binary.shape[0]):\n",
    "            for j in range(binary.shape[1]):\n",
    "                if binary[i, j] and not visited[i, j]:\n",
    "                    # Found a new island, flood fill it\n",
    "                    self._flood_fill(binary, visited, i, j)\n",
    "                    peak_count += 1\n",
    "        \n",
    "        return peak_count\n",
    "    \n",
    "    def _flood_fill(self, binary: np.ndarray, visited: np.ndarray, start_i: int, start_j: int):\n",
    "        \"\"\"Flood fill for connected component labeling\"\"\"\n",
    "        stack = [(start_i, start_j)]\n",
    "        \n",
    "        while stack:\n",
    "            i, j = stack.pop()\n",
    "            if (i < 0 or i >= binary.shape[0] or \n",
    "                j < 0 or j >= binary.shape[1] or \n",
    "                visited[i, j] or not binary[i, j]):\n",
    "                continue\n",
    "            \n",
    "            visited[i, j] = True\n",
    "            \n",
    "            # Add neighbors\n",
    "            for di, dj in [(-1,0), (1,0), (0,-1), (0,1)]:\n",
    "                stack.append((i + di, j + dj))\n",
    "    \n",
    "    def create_3d_surface_plot(self, composition: GeometryComposition, title_suffix=\"\"):\n",
    "        \"\"\"Create 3D surface plot showing height field and peak detection\"\"\"\n",
    "        \n",
    "        height_field = self.generate_height_field(composition)\n",
    "        peak_count = self.count_peaks(height_field)\n",
    "        \n",
    "        # Create coordinate meshes\n",
    "        x = np.arange(self.grid_size)\n",
    "        y = np.arange(self.grid_size)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        \n",
    "        # Create binary threshold for coloring\n",
    "        binary = height_field > self.threshold\n",
    "        \n",
    "        # Create the main 3D surface\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        # Add the height field surface\n",
    "        fig.add_trace(go.Surface(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            z=height_field,\n",
    "            colorscale='Earth',\n",
    "            name='Height Field',\n",
    "            showscale=True,\n",
    "            colorbar=dict(title=\"Height\", x=1.0),\n",
    "            hovertemplate=\"X: %{x}<br>Y: %{y}<br>Height: %{z:.3f}<extra></extra>\"\n",
    "        ))\n",
    "        \n",
    "        # Add threshold plane\n",
    "        threshold_z = np.full_like(height_field, self.threshold)\n",
    "        fig.add_trace(go.Surface(\n",
    "            x=X,\n",
    "            y=Y,\n",
    "            z=threshold_z,\n",
    "            colorscale=[[0, 'rgba(255,0,0,0.3)'], [1, 'rgba(255,0,0,0.3)']],\n",
    "            name=f'Threshold = {self.threshold}',\n",
    "            showscale=False,\n",
    "            hovertemplate=\"Threshold Plane<br>Z = %{z}<extra></extra>\"\n",
    "        ))\n",
    "        \n",
    "        # Add markers for peak regions\n",
    "        peak_x, peak_y, peak_z = [], [], []\n",
    "        for i in range(self.grid_size):\n",
    "            for j in range(self.grid_size):\n",
    "                if binary[i, j]:  # Above threshold\n",
    "                    peak_x.append(i)\n",
    "                    peak_y.append(j)\n",
    "                    peak_z.append(height_field[i, j])\n",
    "        \n",
    "        if peak_x:  # Only add if there are peaks\n",
    "            fig.add_trace(go.Scatter3d(\n",
    "                x=peak_x,\n",
    "                y=peak_y,\n",
    "                z=peak_z,\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    size=3,\n",
    "                    color='red',\n",
    "                    opacity=0.8\n",
    "                ),\n",
    "                name='Peak Points',\n",
    "                hovertemplate=\"Peak Point<br>X: %{x}<br>Y: %{y}<br>Height: %{z:.3f}<extra></extra>\"\n",
    "            ))\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f\"3D Height Field - {peak_count} Peak(s) Detected {title_suffix}\",\n",
    "            scene=dict(\n",
    "                xaxis_title='X',\n",
    "                yaxis_title='Y',\n",
    "                zaxis_title='Height',\n",
    "                camera=dict(\n",
    "                    eye=dict(x=1.5, y=1.5, z=1.5)\n",
    "                )\n",
    "            ),\n",
    "            width=800,\n",
    "            height=700\n",
    "        )\n",
    "        \n",
    "        return fig, peak_count\n",
    "    \n",
    "    def create_multi_threshold_comparison(self, composition: GeometryComposition):\n",
    "        \"\"\"Show how different thresholds affect peak detection\"\"\"\n",
    "        \n",
    "        height_field = self.generate_height_field(composition)\n",
    "        \n",
    "        # Test different thresholds\n",
    "        thresholds = [0.1, 0.3, 0.5, 0.7]\n",
    "        \n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            specs=[[{'type': 'surface'}, {'type': 'surface'}],\n",
    "                   [{'type': 'surface'}, {'type': 'surface'}]],\n",
    "            subplot_titles=[f'Threshold = {t}' for t in thresholds]\n",
    "        )\n",
    "        \n",
    "        # Create coordinate meshes\n",
    "        x = np.arange(self.grid_size)\n",
    "        y = np.arange(self.grid_size)\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        \n",
    "        positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "        \n",
    "        for i, (threshold, pos) in enumerate(zip(thresholds, positions)):\n",
    "            # Count peaks with this threshold\n",
    "            original_threshold = self.threshold\n",
    "            self.threshold = threshold\n",
    "            peak_count = self.count_peaks(height_field)\n",
    "            self.threshold = original_threshold\n",
    "            \n",
    "            # Create binary mask\n",
    "            binary = height_field > threshold\n",
    "            \n",
    "            # Add surface\n",
    "            fig.add_trace(\n",
    "                go.Surface(\n",
    "                    x=X,\n",
    "                    y=Y,\n",
    "                    z=height_field,\n",
    "                    colorscale='Earth',\n",
    "                    showscale=False,\n",
    "                    name=f'Threshold {threshold}'\n",
    "                ),\n",
    "                row=pos[0], col=pos[1]\n",
    "            )\n",
    "            \n",
    "            # Add threshold plane\n",
    "            threshold_z = np.full_like(height_field, threshold)\n",
    "            fig.add_trace(\n",
    "                go.Surface(\n",
    "                    x=X,\n",
    "                    y=Y,\n",
    "                    z=threshold_z,\n",
    "                    colorscale=[[0, 'rgba(255,0,0,0.3)'], [1, 'rgba(255,0,0,0.3)']],\n",
    "                    showscale=False,\n",
    "                    name=f'Plane {threshold}'\n",
    "                ),\n",
    "                row=pos[0], col=pos[1]\n",
    "            )\n",
    "            \n",
    "            # Update subplot title to include peak count\n",
    "            fig.layout.annotations[i].text = f'Threshold = {threshold}<br>{peak_count} Peaks'\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=\"Peak Detection at Different Thresholds\",\n",
    "            height=800,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def visualize_color_ramp_effect(self, base_noise_scale=4.0):\n",
    "        \"\"\"Show how different color ramp configurations create different peak patterns\"\"\"\n",
    "        \n",
    "        # Create different color ramp configurations\n",
    "        configurations = [\n",
    "            {\n",
    "                'name': 'Flat (No Peaks)',\n",
    "                'points': [ColorRampPoint(0.0, 0.1), ColorRampPoint(1.0, 0.2)]\n",
    "            },\n",
    "            {\n",
    "                'name': 'Single Peak',\n",
    "                'points': [ColorRampPoint(0.0, 0.1), ColorRampPoint(0.5, 0.8), ColorRampPoint(1.0, 0.1)]\n",
    "            },\n",
    "            {\n",
    "                'name': 'Two Peaks',\n",
    "                'points': [ColorRampPoint(0.0, 0.1), ColorRampPoint(0.3, 0.8), \n",
    "                          ColorRampPoint(0.5, 0.2), ColorRampPoint(0.7, 0.9), ColorRampPoint(1.0, 0.1)]\n",
    "            },\n",
    "            {\n",
    "                'name': 'Many Small Peaks',\n",
    "                'points': [ColorRampPoint(0.0, 0.4), ColorRampPoint(0.2, 0.8), ColorRampPoint(0.4, 0.3),\n",
    "                          ColorRampPoint(0.6, 0.9), ColorRampPoint(0.8, 0.2), ColorRampPoint(1.0, 0.7)]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Create 2x2 subplot\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=2,\n",
    "            specs=[[{'type': 'surface'}, {'type': 'surface'}],\n",
    "                   [{'type': 'surface'}, {'type': 'surface'}]],\n",
    "            subplot_titles=[config['name'] for config in configurations]\n",
    "        )\n",
    "        \n",
    "        positions = [(1, 1), (1, 2), (2, 1), (2, 2)]\n",
    "        \n",
    "        for i, (config, pos) in enumerate(zip(configurations, positions)):\n",
    "            # Create composition\n",
    "            composition = GeometryComposition(\n",
    "                noise_scale=base_noise_scale,\n",
    "                color_ramp_points=config['points'],\n",
    "                position_strength=1.0\n",
    "            )\n",
    "            \n",
    "            # Generate height field and count peaks\n",
    "            height_field = self.generate_height_field(composition)\n",
    "            peak_count = self.count_peaks(height_field)\n",
    "            \n",
    "            # Create coordinate meshes\n",
    "            x = np.arange(self.grid_size)\n",
    "            y = np.arange(self.grid_size)\n",
    "            X, Y = np.meshgrid(x, y)\n",
    "            \n",
    "            # Add surface\n",
    "            fig.add_trace(\n",
    "                go.Surface(\n",
    "                    x=X,\n",
    "                    y=Y,\n",
    "                    z=height_field,\n",
    "                    colorscale='Earth',\n",
    "                    showscale=False,\n",
    "                    name=config['name']\n",
    "                ),\n",
    "                row=pos[0], col=pos[1]\n",
    "            )\n",
    "            \n",
    "            # Add threshold plane\n",
    "            threshold_z = np.full_like(height_field, self.threshold)\n",
    "            fig.add_trace(\n",
    "                go.Surface(\n",
    "                    x=X,\n",
    "                    y=Y,\n",
    "                    z=threshold_z,\n",
    "                    colorscale=[[0, 'rgba(255,0,0,0.3)'], [1, 'rgba(255,0,0,0.3)']],\n",
    "                    showscale=False,\n",
    "                    name=f'Threshold {config[\"name\"]}'\n",
    "                ),\n",
    "                row=pos[0], col=pos[1]\n",
    "            )\n",
    "            \n",
    "            # Update subtitle with peak count\n",
    "            fig.layout.annotations[i].text = f'{config[\"name\"]}<br>{peak_count} Peaks Detected'\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=\"How Color Ramp Configuration Affects Peak Formation\",\n",
    "            height=800,\n",
    "            showlegend=False\n",
    "        )\n",
    "        \n",
    "        return fig\n",
    "\n",
    "def generate_random_composition() -> GeometryComposition:\n",
    "    \"\"\"Generate a random geometry composition\"\"\"\n",
    "    # Random noise scale\n",
    "    noise_scale = random.uniform(3.0, 6.0)\n",
    "    \n",
    "    # Random color ramp points (2-4 points)\n",
    "    num_points = random.randint(2, 4)\n",
    "    positions = sorted([random.random() for _ in range(num_points)])\n",
    "    positions[0] = 0.0  # Ensure start point\n",
    "    positions[-1] = 1.0  # Ensure end point\n",
    "    \n",
    "    ramp_points = [ColorRampPoint(pos, random.uniform(0.0, 1.0)) \n",
    "                  for pos in positions]\n",
    "    \n",
    "    # Random position strength\n",
    "    position_strength = random.uniform(0.5, 1.5)\n",
    "    \n",
    "    return GeometryComposition(noise_scale, ramp_points, position_strength)\n",
    "\n",
    "def demo_3d_peak_detection():\n",
    "    \"\"\"Demonstrate 3D peak detection visualization\"\"\"\n",
    "    \n",
    "    print(\"3D PEAK DETECTION VISUALIZATION\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    visualizer = Peak3DVisualizer(grid_size=32, threshold=0.3)\n",
    "    \n",
    "    # Demo 1: Single random composition in detail\n",
    "    print(\"\\n1. Random Composition - 3D View\")\n",
    "    composition = generate_random_composition()\n",
    "    fig1, peak_count = visualizer.create_3d_surface_plot(composition, \"(Random)\")\n",
    "    fig1.show()\n",
    "    print(f\"   Detected {peak_count} peaks\")\n",
    "    \n",
    "    # Demo 2: Threshold comparison\n",
    "    print(\"\\n2. Threshold Sensitivity Analysis\")\n",
    "    fig2 = visualizer.create_multi_threshold_comparison(composition)\n",
    "    fig2.show()\n",
    "    print(\"   See how different thresholds change peak detection\")\n",
    "    \n",
    "    # Demo 3: Color ramp effect demonstration\n",
    "    print(\"\\n3. Color Ramp Configuration Effects\")\n",
    "    fig3 = visualizer.visualize_color_ramp_effect()\n",
    "    fig3.show()\n",
    "    print(\"   Compare different color ramp strategies\")\n",
    "    \n",
    "    # Demo 4: Multiple random compositions\n",
    "    print(\"\\n4. Multiple Random Compositions\")\n",
    "    for i in range(3):\n",
    "        comp = generate_random_composition()\n",
    "        fig, peaks = visualizer.create_3d_surface_plot(comp, f\"(Example {i+1})\")\n",
    "        fig.show()\n",
    "        print(f\"   Example {i+1}: {peaks} peaks\")\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ Key observations:\")\n",
    "    print(\"   - Red plane = threshold level\")\n",
    "    print(\"   - Red dots = points above threshold (peaks)\")\n",
    "    print(\"   - Connected red regions = single peak\")\n",
    "    print(\"   - Separate red regions = multiple peaks\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fcf811-b803-43af-ae7d-2375ede50b52",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41f496de-d014-44a0-bda6-23386352581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D PEAK DETECTION VISUALIZATION\n",
      "========================================\n",
      "\n",
      "1. Random Composition - 3D View\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorbar": {
          "title": {
           "text": "Height"
          },
          "x": 1
         },
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "hovertemplate": "X: %{x}<br>Y: %{y}<br>Height: %{z:.3f}<extra></extra>",
         "name": "Height Field",
         "showscale": true,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "hovertemplate": "Threshold Plane<br>Z = %{z}<extra></extra>",
         "name": "Threshold = 0.3",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8=",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "hovertemplate": "Peak Point<br>X: %{x}<br>Y: %{y}<br>Height: %{z:.3f}<extra></extra>",
         "marker": {
          "color": "red",
          "opacity": 0.8,
          "size": 3
         },
         "mode": "markers",
         "name": "Peak Points",
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31
         ],
         "y": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "z": [
          0.8268657214712237,
          0.9788827794642867,
          0.8243732095953841,
          0.6999603757026457,
          0.6161412087799982,
          0.578623766121233,
          0.5877535591849748,
          0.6386332425388125,
          0.7219104092438648,
          0.8251182593166344,
          0.9343804197021287,
          0.9520495932846376,
          0.860063315589651,
          0.7974302518166358,
          0.7680054694435449,
          0.770619833450669,
          0.7995568334105245,
          0.845649590387523,
          0.8978255950581836,
          0.9448663599927468,
          0.9771225856339528,
          0.9879361516820792,
          0.9745664558166304,
          0.9384934962771294,
          0.885062748471599,
          0.8225339383895613,
          0.7606833004335904,
          0.7091742597546303,
          0.6759453243765751,
          0.6658614581800614,
          0.679836692565458,
          0.7145667440117497,
          0.8268657214712237,
          0.9858169556916679,
          0.8376058459681978,
          0.7182894646289207,
          0.6379287608631639,
          0.6019710524348694,
          0.6107000190295007,
          0.6593552593476976,
          0.7388967176678071,
          0.8373022844198721,
          0.9412158503100314,
          0.9504194634764391,
          0.8638431543278371,
          0.8056711621445348,
          0.7794797905352351,
          0.7839866401877112,
          0.8135219363717838,
          0.8590994829828957,
          0.9099196962089444,
          0.9550788035563552,
          0.985232673076713,
          0.9939742550766172,
          0.9787285245601907,
          0.9410414795214952,
          0.8862296265635753,
          0.8224505042919172,
          0.7593396226191107,
          0.7064225581029024,
          0.6715437582840778,
          0.6595511704964578,
          0.6714384719569138,
          0.7040797880228685,
          0.8268657214712237,
          0.9856439059494573,
          0.8758795378727828,
          0.771284456333121,
          0.7008887734446166,
          0.6693866456424175,
          0.6768884978019398,
          0.719039659744953,
          0.7877159321211931,
          0.8721947910831787,
          0.9606371300861005,
          0.9460429163086882,
          0.8750126113877144,
          0.8295910440076182,
          0.8125580112002249,
          0.8223198789635672,
          0.8533634051643818,
          0.8972489607318356,
          0.943990074699894,
          0.9836137249948175,
          0.9859647293765534,
          0.9834151281885711,
          0.9899768254308309,
          0.9478480387665331,
          0.8893203145323743,
          0.8222301507858731,
          0.7557775399176563,
          0.6990610824216189,
          0.6596283329132338,
          0.6422593914771285,
          0.6481678702288971,
          0.6747426554715348,
          0.8268657214712237,
          0.9512918406533611,
          0.9350973579140518,
          0.8532161757183839,
          0.7981152118717776,
          0.7733265792631752,
          0.7787107781841329,
          0.8105721571710223,
          0.8622438178135392,
          0.9250573293842,
          0.9895602595872938,
          0.9403592841055173,
          0.8930506473918282,
          0.8668600278690031,
          0.8633666838056707,
          0.8805486213060226,
          0.913204144756941,
          0.9538170878231006,
          0.9937360000021073,
          0.9707593965558452,
          0.9575744533875876,
          0.9630930444983632,
          0.9885533773752125,
          0.9565465431740117,
          0.8931769510329951,
          0.8219574495089982,
          0.7513216470474662,
          0.6896157005152334,
          0.6438471271346502,
          0.618630518484296,
          0.6154858547856537,
          0.63259430956143,
          0.8268657214712237,
          0.9083939240167778,
          0.9821965623263675,
          0.9553285928169001,
          0.9190639888327331,
          0.9022885731124579,
          0.904587906177018,
          0.923152244413912,
          0.9532149811635218,
          0.9887588825035057,
          0.9662701521004331,
          0.935443294262573,
          0.9170565826152135,
          0.9138485276189772,
          0.9259653176159143,
          0.9509588500115702,
          0.984157442524041,
          0.975404448028999,
          0.9479532025242864,
          0.9306990249258842,
          0.9282741805238203,
          0.9434219976019829,
          0.976573933603943,
          0.9636555136736222,
          0.896098660873335,
          0.8217565800431359,
          0.7479180131541323,
          0.6818031209976582,
          0.6295811439576094,
          0.5955367493169547,
          0.5815029904416162,
          0.5866410396489481,
          0.8268657214712237,
          0.8613760837535492,
          0.892692027172838,
          0.9181168394455819,
          0.9358735760060171,
          0.94538688911458,
          0.9473805700549968,
          0.943773807603754,
          0.9373888624522597,
          0.931510916094098,
          0.9293632186623423,
          0.93357407755946,
          0.945714707090396,
          0.9659780608529798,
          0.9930496755035809,
          0.971030097153129,
          0.9426814980601939,
          0.9182124479064506,
          0.9017580306329404,
          0.8969537835671709,
          0.9064214100130603,
          0.9313711215515027,
          0.9713769844336272,
          0.9651984215474685,
          0.8961478973793302,
          0.8217688842966713,
          0.7477840675542871,
          0.6798706524304468,
          0.6230074477229839,
          0.5809131105549611,
          0.5556483282095572,
          0.5474323700754252,
          0.8268657214712237,
          0.814944470406883,
          0.8044446245173907,
          0.7967409124319189,
          0.793109389843028,
          0.7946663416182792,
          0.8022971096838963,
          0.8165774596224366,
          0.8376938167767192,
          0.8653718572883001,
          0.8988248937002706,
          0.9367337716060254,
          0.9772683568037664,
          0.9764877589368797,
          0.9415512187422176,
          0.9111251018815574,
          0.8876575982978923,
          0.8733613223583702,
          0.870016896696108,
          0.8787971656287272,
          0.9001311201251782,
          0.9336237126227673,
          0.978042762246576,
          0.9574335012079697,
          0.8915108980378312,
          0.8221264618684768,
          0.7529966116471433,
          0.6878186633375895,
          0.6299944423280207,
          0.582381361861903,
          0.5470936376518576,
          0.5253708476509704,
          0.8268657214712237,
          0.7735302639691096,
          0.725924746350685,
          0.6892039145862858,
          0.6674366656751443,
          0.6632164411782392,
          0.6774341856141182,
          0.7092354117565118,
          0.756160590597807,
          0.8144463278537297,
          0.8794464102173529,
          0.946119122412994,
          0.9842935604963072,
          0.9339141587899112,
          0.8936366438697237,
          0.8656265801868173,
          0.8509760859871117,
          0.8497580637362249,
          0.8611825680139626,
          0.8838220591098617,
          0.9158657128011085,
          0.955362523248241,
          0.9916830561903346,
          0.937580201250091,
          0.8808560183831559,
          0.822925931122505,
          0.7650822056930023,
          0.7086264366962418,
          0.6549994853875465,
          0.6058726067333584,
          0.5631701590165062,
          0.5290061556145671,
          0.8268657214712237,
          0.7407830277568684,
          0.6640874947316245,
          0.6051164684419802,
          0.5702368881281082,
          0.5631661189939976,
          0.5846146977059877,
          0.6322893964685894,
          0.7012482901175426,
          0.7845544828611578,
          0.8741378778606367,
          0.9617498052547291,
          0.9568459086235781,
          0.9001877602457784,
          0.861046895523283,
          0.840888109566748,
          0.8391572862378928,
          0.8535976168419712,
          0.8807603428569758,
          0.9166252300661957,
          0.9572340229751607,
          0.9929841095856147,
          0.9475494780539832,
          0.904427570547664,
          0.8636330773259839,
          0.8242065264508354,
          0.7846749038354675,
          0.7436035362646285,
          0.7001411843858791,
          0.6544613366596883,
          0.608018677893287,
          0.5635682871410526,
          0.8268657214712237,
          0.7191768696549784,
          0.6236171568880523,
          0.550877360271233,
          0.5089560373283557,
          0.5022498193902766,
          0.5311012215905796,
          0.5918560187200536,
          0.6774143340760445,
          0.7781944314645135,
          0.883374699660277,
          0.9822447250455107,
          0.9337065886861721,
          0.8788153247575717,
          0.8476911373375117,
          0.8407315633405869,
          0.855522597722973,
          0.8874124939549828,
          0.9303575394621686,
          0.9779080160326585,
          0.9653892538377231,
          0.9205548097646783,
          0.8848717519923244,
          0.8587255051817121,
          0.8402646381565517,
          0.8259361298813754,
          0.8112974136874873,
          0.7919721801382653,
          0.7645954917782383,
          0.7275953550104275,
          0.6816822754891023,
          0.6299619699578642,
          0.8268657214712237,
          0.7097776224840516,
          0.6064831889332087,
          0.529059225860398,
          0.4863757435867483,
          0.4830288266049554,
          0.5188344061914802,
          0.5889445690666605,
          0.6845634989229923,
          0.7941592677797535,
          0.9050016498647179,
          0.9885490511838484,
          0.9175900619213676,
          0.8722783238988943,
          0.8554081367971157,
          0.8660183938841146,
          0.8997462968341167,
          0.949637629471021,
          0.9840848676956825,
          0.9211949480139335,
          0.8674285967011486,
          0.8286295953902739,
          0.8074885976369918,
          0.8032902251392254,
          0.8121952966118041,
          0.8280077231246925,
          0.8433044562430311,
          0.8507537280082224,
          0.8444192977514187,
          0.8208504653694999,
          0.7797889309816907,
          0.7243796869631521,
          0.8268657214712237,
          0.7121968623305057,
          0.6118572761256349,
          0.5383052606055175,
          0.5005111747015241,
          0.5028132823997998,
          0.544399700089802,
          0.6194831278233273,
          0.7181394305590653,
          0.8276898832465899,
          0.9344327309424876,
          0.9698657994569855,
          0.9111256380777588,
          0.881866312963793,
          0.883857023708566,
          0.9146175950760632,
          0.9679116940685313,
          0.9536972030436682,
          0.8762213775798146,
          0.8065002452949532,
          0.7540033619527488,
          0.7250494692260367,
          0.7219564354782751,
          0.7427963210333999,
          0.7817854184098592,
          0.830247250892494,
          0.8780038332451614,
          0.9149887927347967,
          0.9328440076356252,
          0.9262637928125259,
          0.893887010014453,
          0.8386026275606345,
          0.8268657214712237,
          0.7247329859717895,
          0.6363915094395377,
          0.5737360877043872,
          0.5451329848213082,
          0.5542795372105457,
          0.5997137035736978,
          0.6750406563475826,
          0.7698429979122762,
          0.8711454829245474,
          0.9652276978690146,
          0.9571683911280429,
          0.916622930950314,
          0.9076306629070091,
          0.9306744862216203,
          0.9817669456728408,
          0.9334456467408595,
          0.8439039633089406,
          0.7566797481028726,
          0.6842094981068785,
          0.6366080804787018,
          0.6202402885594015,
          0.6368360362964913,
          0.6832733852333989,
          0.7520584663405084,
          0.8324322205336453,
          0.9119447816354517,
          0.9782718822139468,
          0.973906055888857,
          0.9628758671365817,
          0.9816895849377422,
          0.9609602025361585,
          0.8268657214712237,
          0.7446743305518327,
          0.6748089113589134,
          0.6277967647064489,
          0.6108257057994351,
          0.6266823036977517,
          0.6733222483280653,
          0.7441359774443511,
          0.8288736817291886,
          0.9150997532467692,
          0.9899709913140192,
          0.9548576600020469,
          0.935823130469889,
          0.9484540826757655,
          0.9918668383949146,
          0.9249168808649997,
          0.8304532700937719,
          0.7304723638164136,
          0.6386981547313649,
          0.5679522104703708,
          0.5283594425282253,
          0.5259186585157655,
          0.5616395869798251,
          0.6313690791491852,
          0.7263328296655386,
          0.834318765405398,
          0.9413383225284571,
          0.9625874828645254,
          0.9033452167814446,
          0.8756155767926507,
          0.8825344390337417,
          0.9225537845566526,
          0.8268657214712237,
          0.7687179295199285,
          0.7207162113384423,
          0.6914154198213937,
          0.6864232439055088,
          0.7074809208483934,
          0.7521190107977794,
          0.8139435744356203,
          0.8835167803008702,
          0.9497094458267811,
          0.991695019094556,
          0.9668480104411099,
          0.9696636965736211,
          0.9896915697185318,
          0.9231412809629599,
          0.8329204453993867,
          0.7295893065760891,
          0.6260593224666335,
          0.535889679060732,
          0.471457330017443,
          0.4422533306286566,
          0.4535429075497391,
          0.5055780541333847,
          0.5934761642509756,
          0.7077867721329238,
          0.8356736006959633,
          0.9625540866783499,
          0.9260322465312651,
          0.8505572062645017,
          0.8083578787515253,
          0.8032348705674817,
          0.834325443109137,
          0.8268657214712237,
          0.7934428842825774,
          0.7675205739672148,
          0.7553052120874555,
          0.7606135280136797,
          0.7841449652813245,
          0.8232376339776617,
          0.872152299794727,
          0.922850908847346,
          0.966162456740906,
          0.9931702710178641,
          0.9959562523715073,
          0.9721374064582052,
          0.9190813461083639,
          0.8408816483475027,
          0.7448138821217911,
          0.6412172267524912,
          0.5422534063691061,
          0.4603674040892033,
          0.4066557119845711,
          0.3893641365652277,
          0.4127226305575064,
          0.4762810795220031,
          0.5748433304265281,
          0.6990161612127223,
          0.8363064905804679,
          0.9726254760615748,
          0.9079289356735348,
          0.8227050963041713,
          0.7699981126823312,
          0.7539401633705138,
          0.7743483988502863,
          0.8268657214712237,
          0.8157714462568065,
          0.809320700606236,
          0.811225557155863,
          0.8234854116547154,
          0.8458838204314184,
          0.8758496243043615,
          0.90871384217926,
          0.9383338576376168,
          0.9579999729801544,
          0.9614947294291017,
          0.944149103160584,
          0.9037357966704169,
          0.8410591787868258,
          0.7601414885547481,
          0.6679602289585831,
          0.5737545357919173,
          0.48797987404846843,
          0.4210419535814911,
          0.381974873577622,
          0.37724020061858504,
          0.40981106735421496,
          0.47866995026087383,
          0.5787952458822071,
          0.7016473690867253,
          0.8360986465040953,
          0.9696918996555834,
          0.911485107117911,
          0.8244230107129258,
          0.7664397475388441,
          0.7415996209571436,
          0.7503222972781439,
          0.8268657214712237,
          0.8333544645285068,
          0.8416497365989539,
          0.8530287938445485,
          0.8678040232007994,
          0.8850602492529583,
          0.9026173897042069,
          0.9172357235636485,
          0.9250426364271149,
          0.9221237743248264,
          0.9051934416780719,
          0.8722430977439078,
          0.8230655013306946,
          0.7595658902787239,
          0.6857988445137122,
          0.6077065004207035,
          0.5325754442211589,
          0.468270065925347,
          0.4223336481512434,
          0.40107014774291033,
          0.40872625397896445,
          0.4468836962148185,
          0.5141469985301205,
          0.6061751298338293,
          0.7160616522964434,
          0.8350229241746334,
          0.9533137644071952,
          0.9375257345258293,
          0.8570550506394383,
          0.7996488380050562,
          0.7688833333268212,
          0.7656495224861647,
          0.8268657214712237,
          0.8448302421013548,
          0.861971516819898,
          0.8773529577952701,
          0.8898437255796291,
          0.8980970360014823,
          0.9006040377640047,
          0.895826006657038,
          0.882392924628674,
          0.8593430678699202,
          0.8263681752972967,
          0.7840237987535572,
          0.7338655178457526,
          0.678478928396269,
          0.6213838719592211,
          0.566809649331174,
          0.5193557527281168,
          0.4835694777996053,
          0.4634852240126428,
          0.46217835707069765,
          0.4813878870181101,
          0.5212565020551526,
          0.5802242479646316,
          0.655094816165738,
          0.7412731730233817,
          0.8331527262864545,
          0.9246120520502086,
          0.9842519718702288,
          0.9183053999408158,
          0.8672060741817237,
          0.8336519040654808,
          0.8188442262794404,
          0.8268657214712237,
          0.8499252018242939,
          0.8698692689436361,
          0.8838749427013564,
          0.8896743306931565,
          0.885761168463358,
          0.8715213572019801,
          0.8472762476155883,
          0.8142371590001692,
          0.7743792561210845,
          0.73025125885536,
          0.684743546020953,
          0.6408403672612744,
          0.6013818258416909,
          0.5688581969193133,
          0.5452535505141264,
          0.5319484154732447,
          0.5296833929994075,
          0.5385782833350126,
          0.5581953887210437,
          0.587631914683422,
          0.6256251845246975,
          0.6706556994657586,
          0.7210365389816555,
          0.7749825171403686,
          0.830658009800232,
          0.8862075031461005,
          0.9397768284940453,
          0.9895350967376492,
          0.9624316721617662,
          0.9290611959621029,
          0.9035957792702435,
          0.8268657214712237,
          0.8493882646355376,
          0.8669114853259409,
          0.8751032667110599,
          0.8708765735842997,
          0.852800935608255,
          0.8212932983676179,
          0.7785642043174259,
          0.728328642589007,
          0.6753228222613578,
          0.6246941574083382,
          0.5813483178791194,
          0.5493420464835248,
          0.5314029675897992,
          0.5286389381168568,
          0.5404723078879207,
          0.5648026320983884,
          0.5983694169666618,
          0.6372588797018669,
          0.6774793269425202,
          0.7155212819711864,
          0.7488220444484103,
          0.7760693610397826,
          0.7973031128081802,
          0.8138038725683285,
          0.8277885366103099,
          0.8419614863413591,
          0.8589908353146047,
          0.8809902433718941,
          0.9090859679864942,
          0.943136389528703,
          0.9816489721859425,
          0.8268657214712237,
          0.8447750960222998,
          0.8562266969686754,
          0.8557565725530907,
          0.8397455420582751,
          0.8070046925230979,
          0.759010556578253,
          0.6997549004919121,
          0.6352288789524414,
          0.5726134073918083,
          0.5192895815871906,
          0.4818088826058326,
          0.46496905712860553,
          0.4711270646696052,
          0.4998473594816369,
          0.54793668602636,
          0.60986215055941,
          0.6784952665031896,
          0.7460785937693267,
          0.8052800166024837,
          0.8501871035594039,
          0.87710216524945,
          0.8850264391995125,
          0.8757653840704921,
          0.8536402329255549,
          0.8248462540370683,
          0.7965478108399866,
          0.7758373075847355,
          0.7687042422155659,
          0.7791591670599078,
          0.8086355812627759,
          0.8557537146427457,
          0.8268657214712237,
          0.8381199085134587,
          0.841860606937938,
          0.8318333077052232,
          0.8041139716312484,
          0.7578325847003864,
          0.6954385661068141,
          0.6224640783464452,
          0.5468141251378406,
          0.4776813297333144,
          0.4242385844106892,
          0.394296401748657,
          0.3931188902664539,
          0.42257169131531386,
          0.4807297480650707,
          0.5620087673545417,
          0.6578106668804116,
          0.7576005434020018,
          0.8502710427947242,
          0.925608216886027,
          0.9756569987526574,
          0.9957966777711671,
          0.98537560479802,
          0.9478144577455141,
          0.8901604011083668,
          0.8221502033804602,
          0.7549082571176376,
          0.6994559866668306,
          0.665235257176063,
          0.6588464584864072,
          0.683172200435546,
          0.7370041838184127,
          0.8268657214712237,
          0.8315482576824748,
          0.8280195360760222,
          0.8095213291725576,
          0.7719806595398063,
          0.7148325191848363,
          0.6413040464904806,
          0.5581097564636288,
          0.4745937826939097,
          0.4014367826695238,
          0.34911042202697906,
          0.32630173683012786,
          0.33853738317544907,
          0.387212518136583,
          0.4691742011381713,
          0.5769323674512409,
          0.699483368620256,
          0.8236442027018733,
          0.935722166325371,
          0.971843367156711,
          0.9234248156918603,
          0.9105357579664138,
          0.9334869089704988,
          0.9880220040167346,
          0.9193170734980003,
          0.8199984187192829,
          0.721661156147134,
          0.6383985011759337,
          0.582356984555273,
          0.5621768968139771,
          0.5819005440109951,
          0.6404916051489216,
          0.8268657214712237,
          0.8268920212656361,
          0.8183191108483956,
          0.7941173634030358,
          0.7501552159055537,
          0.6860806709927876,
          0.6056153514957568,
          0.5162068458807108,
          0.42807971391766414,
          0.35281496374049093,
          0.30165915189637954,
          0.3049104897693753,
          0.36603567401377884,
          0.46323490809837614,
          0.5878085931184837,
          0.7272406756236609,
          0.8666930628123386,
          0.9908645480461284,
          0.9151938427676971,
          0.8649582943974079,
          0.8556076967010919,
          0.8872653500516425,
          0.9549359300518354,
          0.937838942600082,
          0.8186317434069611,
          0.7005395940387531,
          0.5995824036912294,
          0.5296052793094111,
          0.5005338579502152,
          0.517148235279802,
          0.5785347038465732,
          0.8268657214712237,
          0.8253664482114271,
          0.8151545360938546,
          0.7891224253508127,
          0.743125389254784,
          0.676880819957995,
          0.5942650797705661,
          0.5029524841584248,
          0.41343815378133275,
          0.3375782940326262,
          0.359594627081274,
          0.46157684983486663,
          0.5914097035616928,
          0.736106306120194,
          0.880314733885094,
          0.9854562699393741,
          0.8973948479832085,
          0.8466197665887313,
          0.8383990554231778,
          0.8727958738750508,
          0.9445837937152458,
          0.9436324945475577,
          0.8182042900154128,
          0.6939326941481925,
          0.587436753123054,
          0.5130900858478594,
          0.4812188808431924,
          0.49683416958113696,
          0.5590625107021967,
          0.8268657214712237,
          0.827359054219279,
          0.8192891275908413,
          0.7956511577901391,
          0.7523181522374974,
          0.6889168348534681,
          0.6091208050109173,
          0.5203070354173943,
          0.43261565253237805,
          0.35754164228486507,
          0.30625788220554917,
          0.30814307319453416,
          0.3680520667150033,
          0.46376827546701593,
          0.58670950007677,
          0.7245060389220991,
          0.8624796514515418,
          0.9854842515357284,
          0.9207110714165615,
          0.8706456917623,
          0.8609465501353558,
          0.8917554716523503,
          0.9581488712206222,
          0.9360406707067422,
          0.8187644248850124,
          0.7025903060410069,
          0.6033519256062615,
          0.5347300825955262,
          0.5065259456022562,
          0.5234479446566154,
          0.5845700535915028,
          0.8268657214712237,
          0.8323627359203066,
          0.829723967184925,
          0.8122447768899033,
          0.7758657925190728,
          0.7199845233692201,
          0.6477375650321123,
          0.5657037140874722,
          0.4830631368903263,
          0.41032798546131116,
          0.3578239840716643,
          0.33414124216170576,
          0.34478019270717597,
          0.39119382731251756,
          0.47037361862291316,
          0.5750511490462061,
          0.6945010622872617,
          0.8158456929590941,
          0.9256896767429907,
          0.9821761215409054,
          0.9341064738573902,
          0.9205821123346113,
          0.9419472367100008,
          0.9940810021409268,
          0.9159242669634178,
          0.8202487842565016,
          0.7255300719567562,
          0.645506452271913,
          0.5920117552723513,
          0.5734499876529476,
          0.5937283959658581,
          0.6517892644487561,
          0.8268657214712237,
          0.8390633373786813,
          0.8438685516645211,
          0.8351159709643543,
          0.8089121642919074,
          0.7643427271985705,
          0.7037343230367068,
          0.6324288175965038,
          0.558097259661835,
          0.48968840193407,
          0.4361601309323877,
          0.40517487497373333,
          0.4019470437538497,
          0.42841071996303626,
          0.4828318750569039,
          0.5599274483088731,
          0.6514824084166215,
          0.74738545005615,
          0.8369442290370107,
          0.9103004914508155,
          0.9597499032395055,
          0.9807831287108519,
          0.9727021946585089,
          0.9387242400087127,
          0.8855553149016442,
          0.8224901121081017,
          0.7601591533960423,
          0.7090938295109163,
          0.6783049618473967,
          0.6740686776442155,
          0.6990846314239495,
          0.7521199910691666,
          0.8268657214712237,
          0.8455682689100898,
          0.8579864158781534,
          0.858788634400826,
          0.8444130666667615,
          0.8136314422259416,
          0.767779123772559,
          0.7106175881532778,
          0.647847743365953,
          0.5863420074703556,
          0.5332030274665055,
          0.49478164234112376,
          0.47579269165124666,
          0.47865368149836396,
          0.5031400528467868,
          0.5464062600960313,
          0.6033703439028208,
          0.6674084438208169,
          0.7312619780522035,
          0.7880301948448316,
          0.8321087166752164,
          0.8599422670674124,
          0.8704859299991281,
          0.8653103583799049,
          0.8483365315441563,
          0.8252378848859069,
          0.8025945314966093,
          0.7869192503871909,
          0.7836929973291034,
          0.796546351604539,
          0.8267027344493819,
          0.872762325770479,
          0.8268657214712237,
          0.8497411024865485,
          0.8678476162797719,
          0.8770352565855569,
          0.8743102040218691,
          0.8582201872263056,
          0.8290381182480924,
          0.7887216061362777,
          0.7406562221369271,
          0.6892193791511289,
          0.6392254042282539,
          0.5953275823336877,
          0.5614575895338183,
          0.5403762536968506,
          0.5333929760222689,
          0.5402868223214243,
          0.5594337205378299,
          0.5881154259037283,
          0.62296098460568,
          0.6604538193918637,
          0.697429697388101,
          0.7314937475206927,
          0.7612978636042212,
          0.7866412937670716,
          0.8083838392660064,
          0.8281890049267593,
          0.8481396272821449,
          0.8702873265978711,
          0.8962068776855853,
          0.9266258701698897,
          0.9611889357991478,
          0.9943505011604532,
          0.8268657214712237,
          0.849590522753105,
          0.8694878148874723,
          0.8839688816504759,
          0.8909011736603799,
          0.8887850574299668,
          0.8768748992740835,
          0.8552350739314013,
          0.8247279299327277,
          0.7869372639094575,
          0.7440367311336046,
          0.698617227132189,
          0.6534901680749857,
          0.6114845542145532,
          0.5752547443699316,
          0.5471132553100199,
          0.5288990708846295,
          0.521887465519137,
          0.5267428184452719,
          0.5435118781768876,
          0.5716518728244371,
          0.6100860201423115,
          0.657278440921628,
          0.7113210918429592,
          0.770026813863442,
          0.8310245324616831,
          0.891854597563622,
          0.9500637972481891,
          0.9899172293061462,
          0.9482378658691674,
          0.9146851775277524,
          0.8905956350602708
         ]
        }
       ],
       "layout": {
        "height": 700,
        "scene": {
         "camera": {
          "eye": {
           "x": 1.5,
           "y": 1.5,
           "z": 1.5
          }
         },
         "xaxis": {
          "title": {
           "text": "X"
          }
         },
         "yaxis": {
          "title": {
           "text": "Y"
          }
         },
         "zaxis": {
          "title": {
           "text": "Height"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Height Field - 1 Peak(s) Detected (Random)"
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Detected 1 peaks\n",
      "\n",
      "2. Threshold Sensitivity Analysis\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "name": "Threshold 0.1",
         "scene": "scene",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "name": "Plane 0.1",
         "scene": "scene",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "name": "Threshold 0.3",
         "scene": "scene2",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "name": "Plane 0.3",
         "scene": "scene2",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "name": "Threshold 0.5",
         "scene": "scene3",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "name": "Plane 0.5",
         "scene": "scene3",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "name": "Threshold 0.7",
         "scene": "scene4",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "name": "Plane 0.7",
         "scene": "scene4",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Threshold = 0.1<br>1 Peaks",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Threshold = 0.3<br>1 Peaks",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Threshold = 0.5<br>1 Peaks",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Threshold = 0.7<br>2 Peaks",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "scene": {
         "domain": {
          "x": [
           0,
           0.45
          ],
          "y": [
           0.625,
           1
          ]
         }
        },
        "scene2": {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0.625,
           1
          ]
         }
        },
        "scene3": {
         "domain": {
          "x": [
           0,
           0.45
          ],
          "y": [
           0,
           0.375
          ]
         }
        },
        "scene4": {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0,
           0.375
          ]
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Peak Detection at Different Thresholds"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   See how different thresholds change peak detection\n",
      "\n",
      "3. Color Ramp Configuration Effects\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "name": "Flat (No Peaks)",
         "scene": "scene",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "name": "Threshold Flat (No Peaks)",
         "scene": "scene",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "name": "Single Peak",
         "scene": "scene2",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "name": "Threshold Single Peak",
         "scene": "scene2",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "name": "Two Peaks",
         "scene": "scene3",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "name": "Threshold Two Peaks",
         "scene": "scene3",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "name": "Many Small Peaks",
         "scene": "scene4",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "name": "Threshold Many Small Peaks",
         "scene": "scene4",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        }
       ],
       "layout": {
        "annotations": [
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Flat (No Peaks)<br>0 Peaks Detected",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Single Peak<br>1 Peaks Detected",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 1,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Two Peaks<br>2 Peaks Detected",
          "x": 0.225,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         },
         {
          "font": {
           "size": 16
          },
          "showarrow": false,
          "text": "Many Small Peaks<br>3 Peaks Detected",
          "x": 0.775,
          "xanchor": "center",
          "xref": "paper",
          "y": 0.375,
          "yanchor": "bottom",
          "yref": "paper"
         }
        ],
        "height": 800,
        "scene": {
         "domain": {
          "x": [
           0,
           0.45
          ],
          "y": [
           0.625,
           1
          ]
         }
        },
        "scene2": {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0.625,
           1
          ]
         }
        },
        "scene3": {
         "domain": {
          "x": [
           0,
           0.45
          ],
          "y": [
           0,
           0.375
          ]
         }
        },
        "scene4": {
         "domain": {
          "x": [
           0.55,
           1
          ],
          "y": [
           0,
           0.375
          ]
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "How Color Ramp Configuration Affects Peak Formation"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Compare different color ramp strategies\n",
      "\n",
      "4. Multiple Random Compositions\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorbar": {
          "title": {
           "text": "Height"
          },
          "x": 1
         },
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "hovertemplate": "X: %{x}<br>Y: %{y}<br>Height: %{z:.3f}<extra></extra>",
         "name": "Height Field",
         "showscale": true,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "hovertemplate": "Threshold Plane<br>Z = %{z}<extra></extra>",
         "name": "Threshold = 0.3",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "hovertemplate": "Peak Point<br>X: %{x}<br>Y: %{y}<br>Height: %{z:.3f}<extra></extra>",
         "marker": {
          "color": "red",
          "opacity": 0.8,
          "size": 3
         },
         "mode": "markers",
         "name": "Peak Points",
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          0,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31
         ],
         "y": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31
         ],
         "z": [
          0.8587464871576711,
          0.7444167776472633,
          0.6394024532452092,
          0.5520485833925445,
          0.4888702971449919,
          0.45390141205283485,
          0.44832420750013313,
          0.4704199948596727,
          0.5158423381532086,
          0.5781769691799347,
          0.6497191591109329,
          0.7223745319515352,
          0.7885759686143955,
          0.8421088911546785,
          0.8787497923903175,
          0.8966467738625382,
          0.8964030933865256,
          0.8808613202701883,
          0.8546221586495139,
          0.8233638742532754,
          0.7930516788871926,
          0.7691385781675203,
          0.755858657521507,
          0.7557007221402194,
          0.7691263147265174,
          0.7945644371077177,
          0.8286797786909831,
          0.8668763479882157,
          0.9039684666835651,
          0.9349298470364941,
          0.9556215752748123,
          0.9634024969586455,
          0.8587464871576711,
          0.7484483905526421,
          0.6471450597319424,
          0.5628913243394903,
          0.5019695902338894,
          0.4682594916135382,
          0.462880400530407,
          0.48414521534730204,
          0.5278271263069608,
          0.587704328011156,
          0.6563153272771517,
          0.7258334465444493,
          0.7889561992306175,
          0.8397049069983394,
          0.8740421960036765,
          0.8902382792405308,
          0.8889483037482251,
          0.8729986408207921,
          0.8469154542170019,
          0.8162598649795577,
          0.7868567803724871,
          0.7640162353492567,
          0.751845534626765,
          0.7527377330321774,
          0.7670987038351265,
          0.7933441657409369,
          0.8281634434154915,
          0.8670127463680499,
          0.9047716033278536,
          0.9364754115917878,
          0.9580274244342544,
          0.9667961022848385,
          0.8587464871576711,
          0.7601690481300729,
          0.6696506968670386,
          0.5943995847998805,
          0.5400199154423514,
          0.5099431165752768,
          0.5051075349524535,
          0.5239214679591879,
          0.5625107852747561,
          0.6152188444132923,
          0.6752969059259774,
          0.7357013446487839,
          0.7899022397932298,
          0.8326077703472091,
          0.8603201961756083,
          0.8716606232928453,
          0.8674285689854501,
          0.8503950035169716,
          0.8248600414078494,
          0.7960348161916052,
          0.7693278514378645,
          0.7496269356061562,
          0.7406668655371766,
          0.7445615887814556,
          0.7615577717532679,
          0.7900383590454787,
          0.8267728300604299,
          0.8673795737632847,
          0.9069389823963152,
          0.9406768421831945,
          0.9646287347219008,
          0.9761985568114835,
          0.8587464871576711,
          0.7784960806708076,
          0.7048300670380557,
          0.643623281992265,
          0.5994141632339609,
          0.5749334242400008,
          0.5708424092481782,
          0.5857102093854483,
          0.6162301198581939,
          0.6576475555950003,
          0.7043465584480372,
          0.7505235343958746,
          0.7908670699668543,
          0.8211627448484957,
          0.838751731134658,
          0.8427904035026559,
          0.8342828937673745,
          0.8158864643999753,
          0.7915173207907124,
          0.7658086389161817,
          0.7434902120368254,
          0.7287680856113697,
          0.7247817919565307,
          0.7332064512155303,
          0.7540483875376147,
          0.785658348668264,
          0.8249589700255007,
          0.8678561973002002,
          0.9097813113345592,
          0.9462938414910368,
          0.9736680327324118,
          0.9893875898040951,
          0.8587464871576711,
          0.8017533849373366,
          0.7494496405714737,
          0.7059989800145853,
          0.6745766358313292,
          0.6570244113868333,
          0.6536645246922124,
          0.6632938428088089,
          0.6833582793607368,
          0.7102853558160004,
          0.7399338734353462,
          0.7681056247375826,
          0.7910567914775394,
          0.8059470064599766,
          0.8111719440482817,
          0.8065397705544413,
          0.7932710494568214,
          0.7738233919805316,
          0.7515636112225431,
          0.7303287496861482,
          0.713930831339585,
          0.7056668975202921,
          0.7078950111265487,
          0.7217285766651034,
          0.7468865614695409,
          0.7817178400585657,
          0.82339630676906,
          0.8682622690436819,
          0.9122675462581044,
          0.9514688821994843,
          0.9825083098370114,
          1.0030207190669538,
          0.8587464871576711,
          0.8278485043129763,
          0.7994746316432283,
          0.7758371879875013,
          0.7585642294740359,
          0.7485008262444011,
          0.7456093353149154,
          0.7489815821548412,
          0.7569618957912985,
          0.7673660681121655,
          0.7777692441141318,
          0.7858269921355411,
          0.7895894427742696,
          0.7877689738355114,
          0.7799273998160646,
          0.7665583396024952,
          0.7490532046298448,
          0.7295535130854426,
          0.7107062478073353,
          0.6953510166664023,
          0.6861763619807688,
          0.6853866366184204,
          0.694419905655848,
          0.7137514442110823,
          0.7428072870795813,
          0.7799991639969284,
          0.8228776144568964,
          0.868385881941197,
          0.9131850631252791,
          0.9540124067311483,
          0.9880306625938599,
          1.0131274599617928,
          0.8587464871576711,
          0.8544915482904479,
          0.8504928823380368,
          0.8469243047544199,
          0.8438085139204824,
          0.8409741221999231,
          0.8380467057215676,
          0.8344774363410732,
          0.8296075116553533,
          0.8227613648477462,
          0.8133572039885515,
          0.801020393724529,
          0.7856839741572131,
          0.7676614101610917,
          0.74767942544244,
          0.7268631974836496,
          0.7066717574921969,
          0.6887874876019681,
          0.6749693992498431,
          0.6668846946124977,
          0.6659363475952383,
          0.6731056658180684,
          0.6888278212375861,
          0.7129152378477325,
          0.7445388296755544,
          0.7822709387666531,
          0.8241871328859057,
          0.8680175589896572,
          0.9113330626926208,
          0.951747416415754,
          0.9871152023081003,
          1.015705380925417,
          0.8587464871576711,
          0.8794311267889017,
          0.8981714731808847,
          0.9131705123938519,
          0.9229135297996145,
          0.9262797855876602,
          0.922621982956736,
          0.9118076998886637,
          0.8942204791430136,
          0.8707219160086386,
          0.8425794746395001,
          0.8113675628158513,
          0.7788513363979468,
          0.7468636248700694,
          0.7171852220830706,
          0.6914376450406562,
          0.6709955093093382,
          0.6569231664194118,
          0.6499375098892347,
          0.6503962062583687,
          0.6583083412736682,
          0.6733628215364217,
          0.6949689817616005,
          0.7223037571230728,
          0.7543604241903266,
          0.7899951354351703,
          0.8279690449806918,
          0.8669854839009192,
          0.9057231277305301,
          0.942867177422234,
          0.977141083763739,
          1.0073412074982249,
          0.8587464871576711,
          0.9006807686593228,
          0.9386945800454313,
          0.9692302490353601,
          0.98941838666507,
          0.9973329187748275,
          0.9921503744141854,
          0.9741987573994012,
          0.9448934663260861,
          0.9065699805782929,
          0.862233981767406,
          0.8152579834806895,
          0.7690584622999055,
          0.7267884073650103,
          0.6910771022382481,
          0.6638422692038847,
          0.6461903113942493,
          0.6384094632669023,
          0.640049551662833,
          0.6500721248884905,
          0.6670471089093952,
          0.6893677737423745,
          0.7154551040976144,
          0.7439256665329673,
          0.7737032913540476,
          0.8040634832912971,
          0.8346092945313174,
          0.8651871482330843,
          0.8957595213785277,
          0.926257393222109,
          0.9564381662452273,
          0.9857740097877254,
          0.8587464871576711,
          0.9167107087109504,
          0.9691338631886512,
          1.0110258818536866,
          1.0384387747966632,
          1.0488447926088098,
          1.0413616779965447,
          1.016802570252035,
          0.977548138496781,
          0.9272586206352785,
          0.8704612639177758,
          0.8120621158650881,
          0.7568386529081107,
          0.7089705303688895,
          0.6716597795665815,
          0.6468798670946535,
          0.6352766798557167,
          0.6362257422137583,
          0.648031115331337,
          0.6682347687756135,
          0.6939927544485904,
          0.7224677213219782,
          0.751186942950671,
          0.778321044462147,
          0.8028501775976523,
          0.8245999845942216,
          0.8441473059810695,
          0.8626129753946291,
          0.8813739982784353,
          0.9017380378671876,
          0.9246280884833626,
          0.9503238772243499,
          0.8587464871576711,
          0.9265842768682873,
          0.9877111401679162,
          1.0361173308027412,
          1.0671166471227413,
          1.0778204260859703,
          1.06741102123847,
          1.037186085924273,
          0.9903716931158024,
          0.9317290798556983,
          0.867003415575632,
          0.8022806590425221,
          0.7433282172574176,
          0.6949956581369512,
          0.6607431710829872,
          0.6423489303613559,
          0.6398240710545713,
          0.6515384154727821,
          0.6745345302125063,
          0.7049852678908063,
          0.7387333655906635,
          0.771842911745025,
          0.8010925576430761,
          0.8243491485605918,
          0.8407768143950232,
          0.8508583924848784,
          0.856230590163557,
          0.8593584417932213,
          0.8630953439984269,
          0.8701896674332618,
          0.8828058030731518,
          0.9021256482229147,
          0.8587464871576711,
          0.9300248681804791,
          0.9939262128050536,
          1.0438791623838428,
          1.0748307127190437,
          1.0837839649326921,
          1.0700998388251033,
          1.0355296711758448,
          0.983977490845496,
          0.9210226235387092,
          0.8532612976672038,
          0.7875467404158817,
          0.7302183942781545,
          0.6864110554704785,
          0.6595239798610332,
          0.6509096902767622,
          0.659814879168345,
          0.683574805609615,
          0.7180317390919131,
          0.7581210724453036,
          0.7985489836908687,
          0.8344753470170445,
          0.8621161671763156,
          0.8791910028961262,
          0.8851612098925389,
          0.88123180308859,
          0.8701199336958124,
          0.8556226333296482,
          0.8420419031994792,
          0.8335432613733705,
          0.833532265353336,
          0.8441312573977516,
          0.8587464871576711,
          0.9274077894832122,
          0.9885388866810477,
          1.0354697874094327,
          1.063149152347617,
          1.0687114489823746,
          1.0517863585531442,
          1.014514988657885,
          0.9612726681935236,
          0.8981332530261921,
          0.8321406885245642,
          0.7704763302771814,
          0.719622476542888,
          0.6846222961184248,
          0.6685239168647732,
          0.6720734280551259,
          0.6936907880308568,
          0.7297279007438788,
          0.7749736890290054,
          0.823341060442693,
          0.8686488823848945,
          0.9054010976886654,
          0.9294662301608276,
          0.9385735729077068,
          0.9325656770669556,
          0.91337746018385,
          0.8847465247229683,
          0.8516928772185629,
          0.819835014621973,
          0.7946297426573775,
          0.7806325933944914,
          0.7808731430406395,
          0.8587464871576711,
          0.919680159078366,
          0.9734114787074023,
          1.013602051926833,
          1.0355366248602025,
          1.0366854900247442,
          1.0170021074895714,
          0.9789202045548575,
          0.9270512275325097,
          0.8676194932312883,
          0.8077042704773845,
          0.7543814215110809,
          0.7138692968019513,
          0.6907828401459338,
          0.6875864259746003,
          0.7043114732851011,
          0.7385723663309443,
          0.7858776486011273,
          0.8401973239228001,
          0.8947158209794216,
          0.9426775814791096,
          0.9782210776384539,
          0.9970987075713124,
          0.997194244059656,
          0.9787745667961186,
          0.9444452074530243,
          0.8988157493775726,
          0.8479168640601518,
          0.7984413458184165,
          0.7569031699868873,
          0.7288186888335448,
          0.7180113549969801,
          0.8587464871576711,
          0.9082204097276119,
          0.9512343734547551,
          0.9821477307453943,
          0.9968564761401311,
          0.9933191985854295,
          0.9718258748494069,
          0.934975474980419,
          0.8873643317904052,
          0.835023012639439,
          0.784670619992473,
          0.742878195895046,
          0.715244406860845,
          0.7056855105895522,
          0.7159278802367259,
          0.7452667519111648,
          0.7906223701386746,
          0.8468883075470401,
          0.9075308858627633,
          0.9653677200024092,
          1.0134312393041458,
          1.0458123375154875,
          1.058381392979566,
          1.0492985452842158,
          1.0192505410266268,
          0.9713845758229689,
          0.9109463265168813,
          0.8446653019500527,
          0.7799613571990415,
          0.7240679650240986,
          0.6831779638536354,
          0.6617147674754134,
          0.8587464871576711,
          0.8946558109066802,
          0.9251705150053295,
          0.9456274348749487,
          0.9527326254972119,
          0.9450234486347492,
          0.9230949577122445,
          0.8895600600897697,
          0.848746335439823,
          0.8061655474978403,
          0.7678206932655198,
          0.739436307093809,
          0.7257080665154707,
          0.7296662157728696,
          0.7522340732801375,
          0.7920395055796574,
          0.8455065686969507,
          0.907220279505586,
          0.9705238741009596,
          1.0282790616238349,
          1.0736992442553432,
          1.1011559939993507,
          1.1068614804748211,
          1.0893437842856402,
          1.0496564152295738,
          0.9912949503190853,
          0.9198286954279081,
          0.842289418720609,
          0.7663883629525817,
          0.6996533780175771,
          0.6485876189918327,
          0.6179486618083704,
          0.8587464871576711,
          0.8806609718424195,
          0.8984635305980326,
          0.9086499737483856,
          0.90885108528869,
          0.8982090599260223,
          0.8775519651433495,
          0.8493407313054656,
          0.8173922041868474,
          0.7864105589714891,
          0.761384275824432,
          0.7469237857799227,
          0.7466235388655387,
          0.7625304895317976,
          0.7947889846792983,
          0.8415111913346338,
          0.8988950259966201,
          0.9615813493818303,
          1.0232126608397192,
          1.0771302948717538,
          1.1171293083144855,
          1.1381820788770982,
          1.1370441741716149,
          1.1126690545666087,
          1.0663801272995053,
          1.0017769636723663,
          0.9243837377294961,
          0.8410783877713277,
          0.7593669740484926,
          0.6865860739668697,
          0.6291246025366201,
          0.5917541383624854,
          0.8587464871576711,
          0.8677619882540615,
          0.8740574575426963,
          0.8753698181391398,
          0.8702866653194513,
          0.8585216592035416,
          0.8410317869583448,
          0.81995718451995,
          0.7983873461348597,
          0.7799804191523453,
          0.7684819918714263,
          0.7672038250246437,
          0.7785295370942089,
          0.8035124354270707,
          0.8416206298576495,
          0.8906674368104412,
          0.9469429271368649,
          1.005537973659419,
          1.0608283068549618,
          1.1070658244235148,
          1.1390102402927456,
          1.1525278907123921,
          1.1450869792237337,
          1.1160895212945634,
          1.0669984912312658,
          1.0012420399512088,
          0.9239023737874825,
          0.8412218973176053,
          0.7599805376730591,
          0.6868132312624917,
          0.6275435601461794,
          0.5866076338220352,
          0.8587464871576711,
          0.8571695789452937,
          0.8542734492099002,
          0.8490275129965713,
          0.840935537351746,
          0.8302011947843538,
          0.8177868554317524,
          0.8053532725379937,
          0.7950838713854886,
          0.7894131615026929,
          0.790692326938061,
          0.8008345529646969,
          0.8209868558663173,
          0.8512734846398041,
          0.8906484818536714,
          0.936882570698549,
          0.9866936448656481,
          1.0360126919783517,
          1.080360108054061,
          1.1152931413521756,
          1.1368754179657057,
          1.1421154052193463,
          1.1293228394290535,
          1.0983404046400576,
          1.0506213839397263,
          0.9891410694840369,
          0.918148419239954,
          0.8427825871839698,
          0.7685943852611035,
          0.7010236305315035,
          0.6448883958701767,
          0.6039408153658161,
          0.8587464871576711,
          0.8496604189794944,
          0.8405807515914139,
          0.8316262425351143,
          0.8231196821772413,
          0.8156411304669453,
          0.8100304204547312,
          0.8073339309524731,
          0.8086988051918352,
          0.8152257693124891,
          0.827798421885893,
          0.8469114097047885,
          0.8725216272592707,
          0.9039451789396499,
          0.9398184164768583,
          0.9781343860469175,
          1.0163572958198799,
          1.0516081848724408,
          1.080905985308372,
          1.1014407357533567,
          1.1108507710722044,
          1.1074739378867164,
          1.0905445551967727,
          1.0603128313856767,
          1.0180712412685171,
          0.9660820976795009,
          0.9074111198927586,
          0.8456819948605244,
          0.7847755699826803,
          0.7285034054972297,
          0.6802882423752432,
          0.6428831784525014,
          0.8587464871576711,
          0.8455194533570362,
          0.8334867196871507,
          0.8237797607845488,
          0.8174066992477039,
          0.8151964022561462,
          0.8177495560350284,
          0.8253990718036218,
          0.8381820972086516,
          0.8558256999330965,
          0.8777479133513464,
          0.903075261994832,
          0.9306771145885023,
          0.9592162693892331,
          0.9872141136262369,
          1.0131275943120308,
          1.035434188306437,
          1.0527201707437364,
          1.0637668553272663,
          1.067629204995454,
          1.0637013481093418,
          1.0517641092894188,
          1.0320106602167871,
          1.0050477570277996,
          0.971871661781093,
          0.9338196195889065,
          0.8924995348834032,
          0.8497021091126917,
          0.8073010266448462,
          0.7671476882439655,
          0.7309674103003112,
          0.7002638952588364,
          0.8587464871576711,
          0.8445480840296392,
          0.8325552699811786,
          0.8247448446586924,
          0.8226608694210468,
          0.8272575437751761,
          0.8388055195013041,
          0.8568710139531115,
          0.8803688137389513,
          0.9076819473192561,
          0.9368334270104369,
          0.9656898771168131,
          0.9921737148262835,
          1.014460177396448,
          1.0311379005019903,
          1.0413166212652358,
          1.0446722855142532,
          1.0414275467311334,
          1.0322734060830765,
          1.018244614914314,
          1.0005666183669548,
          0.9804946559653331,
          0.9591658386775587,
          0.9374826073935706,
          0.9160412847137624,
          0.8951130807411459,
          0.8746777265999988,
          0.854502807965153,
          0.8342557601047399,
          0.8136311419712657,
          0.7924737803244629,
          0.7708789223290218,
          0.8587464871576711,
          0.8461347533460093,
          0.8365468678160078,
          0.832628063281429,
          0.8363121704169123,
          0.8485749194600483,
          0.8693031283653673,
          0.897295501473833,
          0.9303947910372214,
          0.9657351527407816,
          1.0000745956964292,
          1.0301721828009003,
          1.053164322816103,
          1.066894751594838,
          1.0701585858442417,
          1.062831432245492,
          1.0458686436433227,
          1.0211757009161728,
          0.9913664173893082,
          0.9594392889426125,
          0.9284121828158238,
          0.9009604695503777,
          0.8791030629270862,
          0.8639747310537055,
          0.8557122368626111,
          0.8534676935978885,
          0.8555467280534638,
          0.8596535765663602,
          0.863211999962391,
          0.8637215226659349,
          0.8591041319525909,
          0.8479977532243398,
          0.8587464871576711,
          0.8493766402411814,
          0.843657953648309,
          0.8447348900574814,
          0.8548027747518827,
          0.8747858949721654,
          0.9041774488983466,
          0.9410625348193874,
          0.982322581952949,
          1.023996977107294,
          1.0617579322946549,
          1.0914403055334538,
          1.1095609101617379,
          1.1137627291825958,
          1.1031283032875516,
          1.078322317290549,
          1.0415441527793883,
          0.9962943720026056,
          0.946981910478486,
          0.8984183862642992,
          0.8552599694260845,
          0.8214639636513266,
          0.7998257942242066,
          0.7916526309662582,
          0.7966135383704315,
          0.8127848160125296,
          0.8368856482374835,
          0.8646761862314669,
          0.891470536791947,
          0.9127032231683544,
          0.924481208594624,
          0.9240553214278561,
          0.8587464871576711,
          0.8532349067872755,
          0.8518254978581711,
          0.8580117015098252,
          0.8741487647723616,
          0.9010728578114965,
          0.9379194150477651,
          0.9821662640611022,
          1.029898728544785,
          1.0762657366803252,
          1.1160715348644503,
          1.144429946982326,
          1.1573994507665277,
          1.152518780790725,
          1.1291741845281744,
          1.088749495519072,
          1.0345364217327706,
          0.971411682550727,
          0.9053162888894875,
          0.842596829582113,
          0.7892860736955648,
          0.7504083543690607,
          0.7293930247337663,
          0.7276669882795647,
          0.7444763564858612,
          0.7769601866015511,
          0.8204692677266467,
          0.8690936769567641,
          0.9163378589211127,
          0.9558643164383763,
          0.9822187786534886,
          0.9914519327998274,
          0.8587464871576711,
          0.8567019520487879,
          0.859054637735156,
          0.8695201528508641,
          0.8905410511485692,
          0.9228643324830451,
          0.9653452862245759,
          1.0150063752233582,
          1.0673474012559023,
          1.116871020771183,
          1.157759808874718,
          1.1846209944200532,
          1.1932052503475323,
          1.18100779185057,
          1.1476733517758952,
          1.0951497951121798,
          1.027565405227334,
          0.9508385422043291,
          0.8720613220560083,
          0.7987271477647927,
          0.7378918574981119,
          0.6953674541148477,
          0.6750446562401291,
          0.6784261274187775,
          0.7044278802023505,
          0.7494749198847773,
          0.80788245951284,
          0.872480185753254,
          0.935408168356545,
          0.9889925737813255,
          1.026599836039927,
          1.0433705047871646,
          0.8587464871576711,
          0.8589579279112667,
          0.8637250265333002,
          0.8768801304431492,
          0.9009054432878474,
          0.9364869126015873,
          0.9823101368293571,
          1.035128786979731,
          1.090101213413019,
          1.141356405972305,
          1.1827206116197924,
          1.2085144418777565,
          1.2143199496841757,
          1.1976192824828864,
          1.158220948201576,
          1.0984147651298377,
          1.0228291909038902,
          0.9380009750276359,
          0.8517025226669591,
          0.7721026400530415,
          0.7068577092775716,
          0.6622401390888231,
          0.6424078865279877,
          0.6489032311615527,
          0.6804426290215534,
          0.7330255095727523,
          0.8003523727117061,
          0.8745060018110564,
          0.9468184347646622,
          1.0088242881486666,
          1.0531907715262767,
          1.0745174984937493,
          0.8587464871576711,
          0.8594954800587705,
          0.8648348697665659,
          0.8786223211479041,
          0.9033479446193664,
          0.9396828686031518,
          0.986273389943821,
          1.0398116040088508,
          1.0953780530766708,
          1.1470168995794585,
          1.1884738137914108,
          1.214004976571379,
          1.2191551061820138,
          1.2014046051613316,
          1.1606006071861128,
          1.0991121581636984,
          1.0216829261906653,
          0.9349916721809742,
          0.8469667242581187,
          0.765931459552999,
          0.6996795025503807,
          0.6545882838811764,
          0.6348764761712805,
          0.642094929617101,
          0.674913920071353,
          0.7292349812022968,
          0.798617453610779,
          0.8749727297440074,
          0.9494474779736611,
          1.0133947142937605,
          1.0593211609115398,
          1.0817021467584245,
          0.8587464871576711,
          0.8581960655455108,
          0.8621501876274765,
          0.8744037603474134,
          0.8974268202093322,
          0.9319261482687959,
          0.9766437506274993,
          1.0284221100565678,
          1.082532068704034,
          1.1332254662334522,
          1.174445449347482,
          1.2006063560309923,
          1.2073449266289669,
          1.1921466352154282,
          1.1547649974606813,
          1.097376138572407,
          1.024442753807559,
          0.942296993041646,
          0.8584864226712811,
          0.7809568092781741,
          0.7171663721347841,
          0.6732357534097358,
          0.6532350118260011,
          0.6586937380189847,
          0.6883946929549403,
          0.7384782414546045,
          0.8028482605284806,
          0.8738345473643598,
          0.9430363314485904,
          1.0022499805200515,
          1.0443739792942879,
          1.0641869627033664,
          0.8587464871576711,
          0.8553477015172245,
          0.856239524139286,
          0.8650579456873188,
          0.8842158347940277,
          0.9144958025286828,
          0.9548593233355942,
          1.0024996486739368,
          1.0531351120432915,
          1.1015087480824133,
          1.1420335580011367,
          1.1695035769824764,
          1.179781557251131,
          1.1703757862985167,
          1.1408311661736585,
          1.0928816941780752,
          1.0303402496580927,
          0.9587336058390632,
          0.8847219352992097,
          0.8153689129313935,
          0.7573475281161574,
          0.7161755294551542,
          0.6955719084385954,
          0.6970122286472707,
          0.7195375218129237,
          0.7598416581772284,
          0.812629138789481,
          0.8712031250938114,
          0.9282160973262538,
          0.9764961339611495,
          1.009852777109922,
          1.0237688861214036,
          0.8587464871576711,
          0.8516017894627106,
          0.8483895107619203,
          0.8524729202313152,
          0.8661503967672868,
          0.8902973277466644,
          0.9241926523965467,
          0.9655539151927425,
          1.0107785017965387,
          1.0553627276241566,
          1.0944478623215033,
          1.1234258117159062,
          1.1385290897060043,
          1.13733092828319,
          1.1190917827938718,
          1.0849068477394619,
          1.0376332803993893,
          0.9816026996823618,
          0.9221508988499476,
          0.8650193471895814,
          0.8156991692261734,
          0.7787958827434628,
          0.7574912871153752,
          0.7531677154340923,
          0.7652407259802766,
          0.7912215126775617,
          0.8270028562755868,
          0.8673356433677412,
          0.906440098282527,
          0.9386796805392337,
          0.9592180641417254,
          0.9645816498698984,
          0.8587464871576711,
          0.8478747477606094,
          0.8404124606018184,
          0.839313378646118,
          0.8466767221037517,
          0.863455067699004,
          0.8893056607010439,
          0.9226041605711732,
          0.9606197826079881,
          0.999830853587671,
          1.03634241084342,
          1.0663547807953435,
          1.0866256389160385,
          1.0948686756611608,
          1.0900396039237419,
          1.0724739176651337,
          1.043858878783106,
          1.007042460191374,
          0.9657019281752026,
          0.9239119611657713,
          0.8856645636884859,
          0.8543990244940487,
          0.8325990467796038,
          0.8215060758607606,
          0.8209837499925215,
          0.8295500218948584,
          0.8445730848152648,
          0.8626072805378922,
          0.8798281055545902,
          0.8925133503547152,
          0.89751178187633,
          0.8926422980403614
         ]
        }
       ],
       "layout": {
        "height": 700,
        "scene": {
         "camera": {
          "eye": {
           "x": 1.5,
           "y": 1.5,
           "z": 1.5
          }
         },
         "xaxis": {
          "title": {
           "text": "X"
          }
         },
         "yaxis": {
          "title": {
           "text": "Y"
          }
         },
         "zaxis": {
          "title": {
           "text": "Height"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Height Field - 1 Peak(s) Detected (Example 1)"
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Example 1: 1 peaks\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorbar": {
          "title": {
           "text": "Height"
          },
          "x": 1
         },
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "hovertemplate": "X: %{x}<br>Y: %{y}<br>Height: %{z:.3f}<extra></extra>",
         "name": "Height Field",
         "showscale": true,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "hovertemplate": "Threshold Plane<br>Z = %{z}<extra></extra>",
         "name": "Threshold = 0.3",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "hovertemplate": "Peak Point<br>X: %{x}<br>Y: %{y}<br>Height: %{z:.3f}<extra></extra>",
         "marker": {
          "color": "red",
          "opacity": 0.8,
          "size": 3
         },
         "mode": "markers",
         "name": "Peak Points",
         "type": "scatter3d",
         "x": [
          0,
          0,
          0,
          1,
          1,
          1,
          2,
          2,
          2,
          2,
          3,
          3,
          3,
          3,
          3,
          3,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          8,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          9,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          10,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          11,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          12,
          13,
          13,
          13,
          13,
          13,
          13,
          13,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          14,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          15,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          16,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          17,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          18,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          19,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          20,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          21,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          22,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          23,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          24,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          25,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          26,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          27,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          28,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          29,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          30,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31,
          31
         ],
         "y": [
          22,
          23,
          24,
          22,
          23,
          24,
          22,
          23,
          24,
          25,
          22,
          23,
          24,
          25,
          26,
          27,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          2,
          3,
          4,
          5,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          2,
          3,
          4,
          5,
          6,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          1,
          2,
          3,
          4,
          5,
          6,
          26,
          27,
          28,
          29,
          30,
          31,
          1,
          2,
          3,
          4,
          5,
          6,
          27,
          28,
          29,
          30,
          31,
          2,
          3,
          4,
          5,
          15,
          16,
          17,
          18,
          28,
          29,
          30,
          31,
          3,
          14,
          15,
          16,
          17,
          18,
          29,
          30,
          31,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          31,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          22,
          23,
          24,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          21,
          22,
          23,
          24,
          25,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          21,
          22,
          23,
          24,
          25,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          21,
          22,
          23,
          24,
          25,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          22,
          23,
          24,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          30,
          31,
          2,
          3,
          4,
          14,
          15,
          16,
          17,
          18,
          29,
          30,
          31,
          2,
          3,
          4,
          5,
          15,
          16,
          17,
          18,
          28,
          29,
          30,
          31,
          1,
          2,
          3,
          4,
          5,
          6,
          27,
          28,
          29,
          30,
          31
         ],
         "z": [
          0.30211998027340037,
          0.3143944250490385,
          0.3030438671741818,
          0.3057892964698225,
          0.32033509225914913,
          0.3115522573764452,
          0.31503504325431236,
          0.3356983213358255,
          0.3340730913024736,
          0.31300840468884567,
          0.32504543498315575,
          0.3537518886796443,
          0.362352115385429,
          0.3522482696811986,
          0.3288300293643547,
          0.3002091154819743,
          0.3292702770742222,
          0.3652702532723494,
          0.3849846016873249,
          0.3881590943779195,
          0.37721709321776614,
          0.3566308127396214,
          0.3319120375928752,
          0.30844300952245357,
          0.3212545256097322,
          0.3610289056302731,
          0.3903650074784369,
          0.40742460526294766,
          0.4114149161735524,
          0.4026579266080898,
          0.3825601041327249,
          0.35348110378435277,
          0.3185094536417857,
          0.31642642815843497,
          0.3455964818173578,
          0.3523506879432254,
          0.33536353312660927,
          0.33441753948923103,
          0.3697938332409811,
          0.3995885263899222,
          0.419889393949432,
          0.42672066950743914,
          0.41700472239109965,
          0.38950418612123905,
          0.34550743051120375,
          0.3614070934772656,
          0.4023777753231349,
          0.4106941648839421,
          0.3853213961824255,
          0.33108573967223665,
          0.32000344325695085,
          0.35981035593351063,
          0.39635310271154484,
          0.4216100500005412,
          0.42801572911825886,
          0.4104125174720205,
          0.3676214062734904,
          0.30324007235316497,
          0.3047093493302364,
          0.37883149658206433,
          0.42255411819621613,
          0.428226013379099,
          0.3954892188653573,
          0.33117577612133087,
          0.34136402684881506,
          0.38600730451945825,
          0.41270067915962877,
          0.4124232762363167,
          0.3810937333704249,
          0.32090728990254774,
          0.30039183355968213,
          0.36969998880043364,
          0.4079261534811834,
          0.4077640396640698,
          0.36979386030125977,
          0.3022545115083861,
          0.3247354399882659,
          0.3728889958740843,
          0.3945126396130438,
          0.38258457824524783,
          0.33720143437760197,
          0.33968235701896116,
          0.3665464396469124,
          0.35918298170927504,
          0.31917306683315155,
          0.33891998827789055,
          0.3735580541668063,
          0.37370775258785616,
          0.3391737882594002,
          0.31455600766259084,
          0.3583630861688023,
          0.3696076316309696,
          0.34602188347582746,
          0.3106215000362916,
          0.363174557096878,
          0.4211490285635162,
          0.46104344405334075,
          0.4319232557807998,
          0.3789331843128472,
          0.30786377631273526,
          0.34093836256821225,
          0.3412788442004308,
          0.35463195974622946,
          0.42644933869698487,
          0.5718122683561239,
          0.624755491056434,
          0.5218679690238937,
          0.3976304860284947,
          0.3044283593277624,
          0.31829444622387276,
          0.33113701832321457,
          0.3998575476659129,
          0.49932193890764714,
          0.627048125387569,
          0.6313589106254834,
          0.4997670446662454,
          0.39025813049114677,
          0.3190207416866741,
          0.3702499187070714,
          0.4155709526675985,
          0.46628648045600857,
          0.5155053510378529,
          0.47270752716458353,
          0.4138335967271637,
          0.35633941371807204,
          0.30145422957795126,
          0.3362173277043931,
          0.36657813951952434,
          0.38948665244621605,
          0.4025620049886555,
          0.4042869533901797,
          0.39410226604213805,
          0.3724067691154616,
          0.3404788702624294,
          0.30034032455709064,
          0.3080736513836925,
          0.3483912886870868,
          0.38045966352569216,
          0.3994651602641709,
          0.40299379913271527,
          0.39140739211263453,
          0.36762242521676797,
          0.33635531703198224,
          0.3030138239462817,
          0.33408614843589196,
          0.38683357708346355,
          0.4296866462887722,
          0.49044853785245107,
          0.4902040954798599,
          0.4284927487155512,
          0.3818361235856866,
          0.32189566259911606,
          0.33135467633289034,
          0.39503849529758034,
          0.4930133601091347,
          0.6598174766183974,
          0.720140354483077,
          0.651029832589719,
          0.45392364472021635,
          0.3681701316279053,
          0.33977884194758073,
          0.35814885041951605,
          0.3406862044864533,
          0.3011816027063161,
          0.3652251477040188,
          0.43544566443226,
          0.6647347182570793,
          0.8279760738205715,
          0.8634809536987007,
          0.7479291378252301,
          0.48647073417439346,
          0.35739277975596573,
          0.31702745490371004,
          0.3836386032286446,
          0.41354339226393716,
          0.399411473119891,
          0.34254266638653563,
          0.30842890651950094,
          0.37456630196838264,
          0.46164290711350975,
          0.7112587249491922,
          0.8731725277008147,
          0.901651801236217,
          0.7733267457883486,
          0.4943786743112552,
          0.3542598557903608,
          0.32396020030483574,
          0.3954861690440423,
          0.42852753592932497,
          0.4153323517644355,
          0.3571451775111289,
          0.3570410503657661,
          0.4257391718939362,
          0.623695937427432,
          0.7879858052980533,
          0.829585983443452,
          0.7252369475990381,
          0.4791877698071357,
          0.36008442285797776,
          0.31090317226088754,
          0.373175781505676,
          0.40031763184278635,
          0.38537101166899296,
          0.32968308252095463,
          0.3170367748464525,
          0.37774815505923787,
          0.4355032537410041,
          0.5863788353014706,
          0.6568306441806017,
          0.6074195947760156,
          0.44043800952889806,
          0.3724034677422753,
          0.3207448961365573,
          0.3341506264856605,
          0.3153165744982688,
          0.31297539005490443,
          0.36289202433349804,
          0.4053381447681356,
          0.4322171695768842,
          0.43814763237827176,
          0.42166959634914586,
          0.3856039065882407,
          0.3364806355783546,
          0.32227721618070054,
          0.3560842165904686,
          0.3805528396626279,
          0.3928921945476991,
          0.3923622450363122,
          0.3802132160025504,
          0.35922465985500907,
          0.33296631130214704,
          0.3049595294501159,
          0.31551409790686286,
          0.35296280744496655,
          0.38556186512479707,
          0.4093747342382866,
          0.4210024258449715,
          0.41805028618123224,
          0.39950573450463145,
          0.3659618457290756,
          0.31964149890071414,
          0.30217785175086653,
          0.360237635455413,
          0.4139294908312466,
          0.49234189803258355,
          0.5674557780340846,
          0.5388817758880289,
          0.4307275753677407,
          0.3695442290807942,
          0.3150854269883247,
          0.3888304718763851,
          0.4790167845502904,
          0.6277840822345451,
          0.6472437142414719,
          0.5223319316722278,
          0.3954662342650121,
          0.3027824150757776,
          0.3352856663107149,
          0.4099791103077629,
          0.5218759170968297,
          0.5895108305530132,
          0.49948157814581157,
          0.394460343147847,
          0.30314228149039363,
          0.31215052635836477,
          0.3275724613537897,
          0.31136971034231664,
          0.32872948719528927,
          0.3167626769980812,
          0.3383020847981049,
          0.39801388356279127,
          0.4264280380717841,
          0.4163740313900706,
          0.3685005427785379,
          0.3247861800352723,
          0.35153660387449387,
          0.344528938002823,
          0.3507525276147259,
          0.3815823873688881,
          0.37647116636079864,
          0.33669611558596124,
          0.30991483536657355,
          0.3468461063590633,
          0.35165837245401094,
          0.3237722985375483,
          0.3341683469090224,
          0.37134660626125654,
          0.3752904190158207,
          0.34446445806748477,
          0.3031367029422585,
          0.3751173752425267,
          0.4158164835167378,
          0.41771041495217526,
          0.3810708853377664,
          0.3137757532462518,
          0.3460013644367267,
          0.38758841452522075,
          0.40215761657326443,
          0.3835756952254955,
          0.33264237483386744
         ]
        }
       ],
       "layout": {
        "height": 700,
        "scene": {
         "camera": {
          "eye": {
           "x": 1.5,
           "y": 1.5,
           "z": 1.5
          }
         },
         "xaxis": {
          "title": {
           "text": "X"
          }
         },
         "yaxis": {
          "title": {
           "text": "Y"
          }
         },
         "zaxis": {
          "title": {
           "text": "Height"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Height Field - 6 Peak(s) Detected (Example 2)"
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Example 2: 6 peaks\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "colorbar": {
          "title": {
           "text": "Height"
          },
          "x": 1
         },
         "colorscale": [
          [
           0,
           "rgb(161, 105, 40)"
          ],
          [
           0.16666666666666666,
           "rgb(189, 146, 90)"
          ],
          [
           0.3333333333333333,
           "rgb(214, 189, 141)"
          ],
          [
           0.5,
           "rgb(237, 234, 194)"
          ],
          [
           0.6666666666666666,
           "rgb(181, 200, 184)"
          ],
          [
           0.8333333333333334,
           "rgb(121, 167, 172)"
          ],
          [
           1,
           "rgb(40, 135, 161)"
          ]
         ],
         "hovertemplate": "X: %{x}<br>Y: %{y}<br>Height: %{z:.3f}<extra></extra>",
         "name": "Height Field",
         "showscale": true,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8",
          "shape": "32, 32"
         }
        },
        {
         "colorscale": [
          [
           0,
           "rgba(255,0,0,0.3)"
          ],
          [
           1,
           "rgba(255,0,0,0.3)"
          ]
         ],
         "hovertemplate": "Threshold Plane<br>Z = %{z}<extra></extra>",
         "name": "Threshold = 0.3",
         "showscale": false,
         "type": "surface",
         "x": {
          "bdata": "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHwABAgMEBQYHCAkKCwwNDg8QERITFBUWFxgZGhscHR4fAAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8AAQIDBAUGBwgJCgsMDQ4PEBESExQVFhcYGRobHB0eHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkJCQkKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLCwsLDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwMDAwNDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ0NDQ4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODg4ODw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8PDw8QEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBAQEBEREREREREREREREREREREREREREREREREREREREREREhISEhISEhISEhISEhISEhISEhISEhISEhISEhISEhITExMTExMTExMTExMTExMTExMTExMTExMTExMTExMTExQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFBQUFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUVFRUWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhYWFhcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXFxcXGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgYGBgZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRkZGRoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGhoaGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxsbGxscHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHBwcHB0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHR0dHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHx8fHw==",
          "dtype": "i1",
          "shape": "32, 32"
         },
         "z": {
          "bdata": "MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8zMzMzMzPTPzMzMzMzM9M/MzMzMzMz0z8=",
          "dtype": "f8",
          "shape": "32, 32"
         }
        }
       ],
       "layout": {
        "height": 700,
        "scene": {
         "camera": {
          "eye": {
           "x": 1.5,
           "y": 1.5,
           "z": 1.5
          }
         },
         "xaxis": {
          "title": {
           "text": "X"
          }
         },
         "yaxis": {
          "title": {
           "text": "Y"
          }
         },
         "zaxis": {
          "title": {
           "text": "Height"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D Height Field - 0 Peak(s) Detected (Example 3)"
        },
        "width": 800
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Example 3: 0 peaks\n",
      "\n",
      "ðŸŽ¯ Key observations:\n",
      "   - Red plane = threshold level\n",
      "   - Red dots = points above threshold (peaks)\n",
      "   - Connected red regions = single peak\n",
      "   - Separate red regions = multiple peaks\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo_3d_peak_detection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de861a-98bb-4afb-a3d3-4c4cdcdb99a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Blender figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53470535-f3f5-4a16-bfbd-051be3b89546",
   "metadata": {},
   "source": [
    "### blender color ramp setup function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7f038-fa60-4912-8966-c76e7d51ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_color_ramp(save_dir, color_ramp_blender_config):\n",
    "    \"\"\"\n",
    "    Test color ramp functionality in Blender.\n",
    "\n",
    "    Can be run with: pytest -s tests/test_blender.py::test_color_ramp\n",
    "\n",
    "    Args:\n",
    "        save_dir: Directory to save the Blender file for visual inspection\n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    import bpy\n",
    "    import os\n",
    "    print(\"Starting color ramp test...\")\n",
    "\n",
    "    def create_connected_nodes(node_group, node_configs):\n",
    "        nodes = node_group.nodes\n",
    "        links = node_group.links\n",
    "        created_nodes = {}\n",
    "        print(f\"Creating {len(node_configs['nodes'])} nodes...\")\n",
    "        for name, node_type in node_configs[\"nodes\"]:\n",
    "            created_nodes[name] = nodes.new(node_type)\n",
    "            print(f\"  - Created {node_type} node named '{name}'\")\n",
    "\n",
    "        print(f\"Creating {len(node_configs['connections'])} connections...\")\n",
    "        for from_node, from_out, to_node, to_in in node_configs[\"connections\"]:\n",
    "            links.new(\n",
    "                created_nodes[from_node].outputs[from_out],\n",
    "                created_nodes[to_node].inputs[to_in],\n",
    "            )\n",
    "            print(f\"  - Connected {from_node}.{from_out} â†’ {to_node}.{to_in}\")\n",
    "        return created_nodes\n",
    "\n",
    "    # Clear existing mesh objects\n",
    "    print(\"Clearing existing mesh objects...\")\n",
    "    bpy.ops.object.select_all(action=\"SELECT\")\n",
    "    bpy.ops.object.delete(use_global=False)\n",
    "\n",
    "    # Clear existing node groups\n",
    "    print(f\"Clearing {len(bpy.data.node_groups)} existing node groups...\")\n",
    "    for node_group in bpy.data.node_groups:\n",
    "        print(f\"  - Removing node group: {node_group.name}\")\n",
    "        bpy.data.node_groups.remove(node_group)\n",
    "\n",
    "    # Create geometry node group\n",
    "    print(\"Creating new geometry node group: TestColorRampGroup\")\n",
    "    node_group = bpy.data.node_groups.new(\"TestColorRampGroup\", \"GeometryNodeTree\")\n",
    "    # Add group input and output nodes\n",
    "    print(\"Adding group input and output nodes...\")\n",
    "    group_input = node_group.nodes.new(\"NodeGroupInput\")\n",
    "    group_output = node_group.nodes.new(\"NodeGroupOutput\")\n",
    "    print(f\"  - Created {group_input.name}\")\n",
    "    print(f\"  - Created {group_output.name}\")\n",
    "\n",
    "    # Set up the interface for the node group (Blender 4.4 specific)\n",
    "    print(\"Setting up node group interface for Blender 4.4...\")\n",
    "    try:\n",
    "        # In Blender 4.4, we use the interface system\n",
    "        if hasattr(node_group, \"interface\"):\n",
    "            # Add input socket for geometry\n",
    "            in_socket = node_group.interface.new_socket(\n",
    "                name=\"Geometry\", in_out=\"INPUT\", socket_type=\"NodeSocketGeometry\"\n",
    "            )\n",
    "            print(f\"  - Added input socket: {in_socket.name}\")\n",
    "\n",
    "            # Add output socket for geometry\n",
    "            out_socket = node_group.interface.new_socket(\n",
    "                name=\"Geometry\", in_out=\"OUTPUT\", socket_type=\"NodeSocketGeometry\"\n",
    "            )\n",
    "            print(f\"  - Added output socket: {out_socket.name}\")\n",
    "        else:\n",
    "            print(\n",
    "                \"  - Warning: node_group.interface not found. This is unexpected for Blender 4.4\"\n",
    "            )\n",
    "    except Exception as e:\n",
    "        print(f\"  - Error setting up node group interface: {e}\")\n",
    "        print(\"  - This may result in red connections in the node editor\")\n",
    "\n",
    "    # Create node configuration\n",
    "    print(\"Setting up node configuration...\")\n",
    "    config = color_ramp_blender_config\n",
    "\n",
    "    # Create and connect nodes\n",
    "    print(\"Creating and connecting nodes according to configuration...\")\n",
    "    created_nodes = create_connected_nodes(node_group, config)\n",
    "\n",
    "    # Connect to group input/output\n",
    "    print(\"Connecting to group input/output...\")\n",
    "    node_group.links.new(\n",
    "        group_input.outputs[0], created_nodes[\"set_pos\"].inputs[\"Geometry\"]\n",
    "    )\n",
    "    print(\"  - Connected Group Input â†’ Set Position.Geometry\")\n",
    "\n",
    "    node_group.links.new(\n",
    "        created_nodes[\"set_pos\"].outputs[\"Geometry\"], group_output.inputs[0]\n",
    "    )\n",
    "    print(\"  - Connected Set Position.Geometry â†’ Group Output\")\n",
    "\n",
    "    # Test: Check that we have the expected number of connections\n",
    "    print(f\"Checking connections: found {len(node_group.links)} links\")\n",
    "    assert len(node_group.links) == 7, f\"Expected 7 links, got {len(node_group.links)}\"\n",
    "\n",
    "    # Test: Verify specific connections exist\n",
    "    print(\"Verifying specific connections...\")\n",
    "    link_pairs = []\n",
    "    for link in node_group.links:\n",
    "        link_pair = (link.from_node.name, link.to_node.name)\n",
    "        link_pairs.append(link_pair)\n",
    "        print(f\"  - Found connection: {link_pair[0]} â†’ {link_pair[1]}\")\n",
    "\n",
    "    expected_connections = [\n",
    "        (\"Group Input\", \"Set Position\"),\n",
    "        (\"Noise Texture\", \"Combine XYZ\"),\n",
    "        (\"Combine XYZ\", \"ColorRamp\"),\n",
    "        (\"ColorRamp\", \"Set Position\"),\n",
    "        (\"Set Position\", \"Group Output\"),\n",
    "    ]\n",
    "\n",
    "    # Test: Check color ramp has default color stops\n",
    "    color_ramp_node = created_nodes[\"ramp\"]\n",
    "    print(\n",
    "        f\"Checking color ramp: found {len(color_ramp_node.color_ramp.elements)} color stops\"\n",
    "    )\n",
    "    assert len(color_ramp_node.color_ramp.elements) >= 2, (\n",
    "        \"Color ramp should have at least 2 color stops\"\n",
    "    )\n",
    "\n",
    "    # Test: Verify we can modify color ramp\n",
    "    print(\"Modifying color ramp elements...\")\n",
    "    print(\n",
    "        f\"  - Original first stop color: {color_ramp_node.color_ramp.elements[0].color[:]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  - Original second stop color: {color_ramp_node.color_ramp.elements[1].color[:]}\"\n",
    "    )\n",
    "\n",
    "    color_ramp_node.color_ramp.elements[0].color = (1, 0, 0, 1)  # Red\n",
    "    color_ramp_node.color_ramp.elements[1].color = (0, 0, 1, 1)  # Blue\n",
    "\n",
    "    print(\n",
    "        f\"  - Modified first stop color to red: {color_ramp_node.color_ramp.elements[0].color[:]}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  - Modified second stop color to blue: {color_ramp_node.color_ramp.elements[1].color[:]}\"\n",
    "    )\n",
    "\n",
    "    assert color_ramp_node.color_ramp.elements[0].color[0] == 1.0, (\n",
    "        \"First color stop should be red\"\n",
    "    )\n",
    "    assert color_ramp_node.color_ramp.elements[1].color[2] == 1.0, (\n",
    "        \"Second color stop should be blue\"\n",
    "    )\n",
    "\n",
    "    # Create a demonstration object to apply the node group to\n",
    "    print(\"\\nCreating a demonstration object...\")\n",
    "    bpy.ops.mesh.primitive_uv_sphere_add(radius=1.0, location=(0, 0, 0))\n",
    "    sphere = bpy.context.active_object\n",
    "\n",
    "    # Add a geometry nodes modifier to the sphere\n",
    "\n",
    "    print(\"Adding geometry nodes modifier to the sphere...\")\n",
    "    geo_mod = sphere.modifiers.new(\"GeometryNodes\", \"NODES\")\n",
    "\n",
    "    # Attempt to assign the node group to the modifier\n",
    "    try:\n",
    "        geo_mod.node_group = node_group\n",
    "        print(\n",
    "            f\"  - Successfully added geometry nodes modifier with node group: {node_group.name}\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  - Note: Could not assign node group to modifier: {e}\")\n",
    "        print(\n",
    "            \"  - This is expected in some Blender versions and won't affect the test \"\n",
    "            \"results\"\n",
    "        )\n",
    "\n",
    "    # Save the Blender file\n",
    "    test_name = \"color_ramp_test\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "    # First save to the current directory (overwriting any existing file)\n",
    "    current_path = os.path.join(save_dir[\"current\"], f\"{test_name}.blend\")\n",
    "    print(f\"\\nSaving current Blender file to: {current_path}\")\n",
    "    bpy.ops.wm.save_as_mainfile(filepath=current_path)\n",
    "    print(f\"File saved successfully at: {current_path}\")\n",
    "\n",
    "    # Then save to the history directory with timestamp\n",
    "    history_path = os.path.join(save_dir[\"history\"], f\"{test_name}_{timestamp}.blend\")\n",
    "    print(f\"Saving history Blender file to: {history_path}\")\n",
    "    bpy.ops.wm.save_as_mainfile(filepath=history_path)\n",
    "    print(f\"History file saved successfully at: {history_path}\")\n",
    "\n",
    "    print(\"âœ… Color ramp test passed!\")\n",
    "    print(f\"Created node group with {len(node_group.links)} connections\")\n",
    "    print(f\"Color ramp has {len(color_ramp_node.color_ramp.elements)} color stops\")\n",
    "\n",
    "    # Print additional details about node structure\n",
    "    print(\"\\nFinal Node Group Structure:\")\n",
    "    print(f\"Total nodes: {len(node_group.nodes)}\")\n",
    "    for i, node in enumerate(node_group.nodes):\n",
    "        print(f\"  {i + 1}. {node.name} ({node.bl_idname})\")\n",
    "        print(f\"     - Inputs: {len(node.inputs)}\")\n",
    "        print(f\"     - Outputs: {len(node.outputs)}\")\n",
    "\n",
    "    # Print details about the color ramp configuration\n",
    "    print(\"\\nColor Ramp Configuration:\")\n",
    "    for i, element in enumerate(color_ramp_node.color_ramp.elements):\n",
    "        print(f\"  Stop {i + 1}: Position={element.position}, Color={element.color[:]}\")\n",
    "\n",
    "    # Print information about the created demonstration object\n",
    "    print(\"\\nDemonstration Object:\")\n",
    "    print(f\"  Name: {sphere.name}\")\n",
    "    print(f\"  Type: {sphere.type}\")\n",
    "\n",
    "    print(\"\\nTest completed successfully!\")\n",
    "    # return {\n",
    "    #     \"current_file\": current_path,\n",
    "    #     \"history_file\": history_path,\n",
    "    #     \"test_name\": test_name,\n",
    "    # }\n",
    "\n",
    "\n",
    "def save_dir():\n",
    "    import os\n",
    "    import datetime\n",
    "    from pathlib import Path\n",
    "    \"\"\"Fixture to provide directories for saving Blender test files.\n",
    "\n",
    "    Returns a dictionary with:\n",
    "    - 'current': Directory for the most recent test run (overwritten each time)\n",
    "    - 'history': Directory for keeping history of all test runs\n",
    "\n",
    "    Checks for BLENDERTESTSAVEDIR environment variable first, otherwise\n",
    "    defaults to ./tests directory.\n",
    "    \"\"\"\n",
    "    if \"BLENDERTESTSAVEDIR\" in os.environ and os.environ[\"BLENDERTESTSAVEDIR\"]:\n",
    "        base_dir = os.environ[\"BLENDERTESTSAVEDIR\"]\n",
    "    else:\n",
    "        base_dir = \"./tests\"\n",
    "\n",
    "    # Create the base directory\n",
    "    Path(base_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create the history directory\n",
    "    history_dir = os.path.join(base_dir, \"run_history\")\n",
    "    Path(history_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"Using save directories:\")\n",
    "    print(f\"  - Current run: {base_dir}\")\n",
    "    print(f\"  - Run history: {history_dir}\")\n",
    "\n",
    "    return {\"current\": base_dir, \"history\": history_dir}\n",
    "# @aerial Color ramp configuration for Blender\n",
    "def color_ramp_blender_config():\n",
    "    return {\n",
    "        \"nodes\": [\n",
    "            (\"noise\", \"ShaderNodeTexNoise\"),\n",
    "            (\"combine\", \"ShaderNodeCombineXYZ\"),\n",
    "            (\"ramp\", \"ShaderNodeValToRGB\"),\n",
    "            (\"set_pos\", \"GeometryNodeSetPosition\"),\n",
    "        ],\n",
    "        \"connections\": [\n",
    "            (\"noise\", \"Fac\", \"combine\", \"X\"),\n",
    "            (\"noise\", \"Fac\", \"combine\", \"Y\"),\n",
    "            (\"noise\", \"Fac\", \"combine\", \"Z\"),\n",
    "            (\"combine\", \"Vector\", \"ramp\", \"Fac\"),\n",
    "            (\"ramp\", \"Color\", \"set_pos\", \"Offset\"),\n",
    "        ],\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b632c2d2-c624-4e77-9edd-810daa3b32ec",
   "metadata": {},
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468b25a3-d84d-472b-9304-0b9a95f6ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_color_ramp(save_dir(), color_ramp_blender_config())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e6e5eb-2c82-4a2d-9098-5c7552a61be1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Color ramp + nois widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbee2d52-7fe2-4cf7-ba3d-a4227ff9d75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTo use this Color Ramp Noise Explorer widget:\\n\\nREQUIRED packages:\\n    pip install ipywidgets matplotlib numpy scipy opensimplex\\n\\nUSAGE in Jupyter notebook:\\n    widget = create_color_ramp_explorer()\\n    display(widget)\\n\\nThe widget will automatically use opensimplex for high-quality noise generation,\\nwith built-in fallback functions if opensimplex is not available.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from scipy.interpolate import interp1d\n",
    "from opensimplex import OpenSimplex\n",
    "\n",
    "# Initialize opensimplex generator\n",
    "opensimplex = OpenSimplex(seed=42)\n",
    "\n",
    "class ColorRampNoiseExplorer:\n",
    "    \"\"\"Interactive widget for exploring how color ramps affect noise functions.\"\"\"\n",
    "    \n",
    "    def __init__(self, width=400, height=400):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.fig_size = (12, 8)\n",
    "        \n",
    "        # Initialize noise parameters\n",
    "        self.scale = 10.0\n",
    "        self.octaves = 4\n",
    "        self.persistence = 0.5\n",
    "        self.lacunarity = 2.0\n",
    "        self.time_offset = 0.0\n",
    "        self.noise_type = 'perlin'\n",
    "        \n",
    "        # Initialize color ramp\n",
    "        self.color_stops = [\n",
    "            {'position': 0.0, 'color': [0, 0, 0, 1]},      # Black\n",
    "            {'position': 1.0, 'color': [1, 1, 1, 1]}       # White\n",
    "        ]\n",
    "        \n",
    "        # Generate coordinate grids\n",
    "        self.x = np.linspace(0, 1, self.width)\n",
    "        self.y = np.linspace(0, 1, self.height)\n",
    "        self.X, self.Y = np.meshgrid(self.x, self.y)\n",
    "        \n",
    "        self.setup_widgets()\n",
    "        self.setup_output()\n",
    "        \n",
    "    def setup_widgets(self):\n",
    "        \"\"\"Create all the interactive widgets.\"\"\"\n",
    "        \n",
    "        # Noise parameter widgets\n",
    "        self.scale_slider = widgets.FloatSlider(\n",
    "            value=self.scale, min=0.1, max=50.0, step=0.5,\n",
    "            description='Scale:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.octaves_slider = widgets.IntSlider(\n",
    "            value=self.octaves, min=1, max=8, step=1,\n",
    "            description='Octaves:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.persistence_slider = widgets.FloatSlider(\n",
    "            value=self.persistence, min=0.1, max=1.0, step=0.05,\n",
    "            description='Persistence:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.lacunarity_slider = widgets.FloatSlider(\n",
    "            value=self.lacunarity, min=1.0, max=4.0, step=0.1,\n",
    "            description='Lacunarity:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.time_offset_slider = widgets.FloatSlider(\n",
    "            value=self.time_offset, min=0.0, max=10.0, step=0.1,\n",
    "            description='Time Offset:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.noise_type_dropdown = widgets.Dropdown(\n",
    "            options=['perlin', 'simplex', 'ridge', 'cellular'],\n",
    "            value=self.noise_type,\n",
    "            description='Noise Type:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Color ramp widgets\n",
    "        self.color_preset_dropdown = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('Black to White', 'bw'),\n",
    "                ('Fire', 'fire'),\n",
    "                ('Ocean', 'ocean'),\n",
    "                ('Rainbow', 'rainbow'),\n",
    "                ('Terrain', 'terrain'),\n",
    "                ('Sunset', 'sunset'),\n",
    "                ('Ice', 'ice'),\n",
    "                ('Custom', 'custom')\n",
    "            ],\n",
    "            value='bw',\n",
    "            description='Color Preset:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Color stop editing widgets\n",
    "        self.stop_position_slider = widgets.FloatSlider(\n",
    "            value=0.0, min=0.0, max=1.0, step=0.01,\n",
    "            description='Stop Position:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.stop_color_picker = widgets.ColorPicker(\n",
    "            value='#000000',\n",
    "            description='Stop Color:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.stop_index_slider = widgets.IntSlider(\n",
    "            value=0, min=0, max=len(self.color_stops)-1, step=1,\n",
    "            description='Edit Stop:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.add_stop_button = widgets.Button(\n",
    "            description='Add Color Stop',\n",
    "            button_style='success'\n",
    "        )\n",
    "        \n",
    "        self.remove_stop_button = widgets.Button(\n",
    "            description='Remove Stop',\n",
    "            button_style='danger'\n",
    "        )\n",
    "        \n",
    "        # Animation widgets\n",
    "        self.animate_button = widgets.Button(\n",
    "            description='Start Animation',\n",
    "            button_style='info'\n",
    "        )\n",
    "        \n",
    "        self.animation_speed_slider = widgets.FloatSlider(\n",
    "            value=0.1, min=0.01, max=0.5, step=0.01,\n",
    "            description='Anim Speed:', style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Analysis widgets\n",
    "        self.show_histogram = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Show Histogram'\n",
    "        )\n",
    "        \n",
    "        self.show_stats = widgets.Checkbox(\n",
    "            value=False,\n",
    "            description='Show Statistics'\n",
    "        )\n",
    "        \n",
    "        # Set up event handlers\n",
    "        self.setup_event_handlers()\n",
    "        \n",
    "    def setup_event_handlers(self):\n",
    "        \"\"\"Connect widget events to update functions.\"\"\"\n",
    "        \n",
    "        # Noise parameter updates\n",
    "        self.scale_slider.observe(self.update_noise, names='value')\n",
    "        self.octaves_slider.observe(self.update_noise, names='value')\n",
    "        self.persistence_slider.observe(self.update_noise, names='value')\n",
    "        self.lacunarity_slider.observe(self.update_noise, names='value')\n",
    "        self.time_offset_slider.observe(self.update_noise, names='value')\n",
    "        self.noise_type_dropdown.observe(self.update_noise, names='value')\n",
    "        \n",
    "        # Color ramp updates\n",
    "        self.color_preset_dropdown.observe(self.update_color_preset, names='value')\n",
    "        self.stop_position_slider.observe(self.update_color_stop, names='value')\n",
    "        self.stop_color_picker.observe(self.update_color_stop, names='value')\n",
    "        self.stop_index_slider.observe(self.select_color_stop, names='value')\n",
    "        \n",
    "        # Button events\n",
    "        self.add_stop_button.on_click(self.add_color_stop)\n",
    "        self.remove_stop_button.on_click(self.remove_color_stop)\n",
    "        self.animate_button.on_click(self.toggle_animation)\n",
    "        \n",
    "        # Analysis updates\n",
    "        self.show_histogram.observe(self.update_display, names='value')\n",
    "        self.show_stats.observe(self.update_display, names='value')\n",
    "        \n",
    "    def setup_output(self):\n",
    "        \"\"\"Create the output widget for displaying the visualization.\"\"\"\n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "    def generate_noise(self):\n",
    "        \"\"\"Generate noise based on current parameters.\"\"\"\n",
    "        \n",
    "        # Scale coordinates\n",
    "        scaled_X = self.X * self.scale_slider.value / 10.0\n",
    "        scaled_Y = self.Y * self.scale_slider.value / 10.0\n",
    "        \n",
    "        # Add time offset for animation\n",
    "        time_offset = self.time_offset_slider.value\n",
    "        noise_array = np.zeros((self.height, self.width))\n",
    "        \n",
    "        if self.noise_type_dropdown.value in ['perlin', 'simplex']:\n",
    "            # Both use opensimplex but with different parameters\n",
    "            for i in range(self.height):\n",
    "                for j in range(self.width):\n",
    "                    # Combine multiple octaves manually for fractal noise\n",
    "                    value = 0.0\n",
    "                    amplitude = 1.0\n",
    "                    frequency = 1.0\n",
    "                    max_value = 0.0\n",
    "                    \n",
    "                    for octave in range(self.octaves_slider.value):\n",
    "                        sample_x = scaled_X[i, j] * frequency\n",
    "                        sample_y = scaled_Y[i, j] * frequency\n",
    "                        sample_z = time_offset * frequency\n",
    "                        \n",
    "                        # Add slight offset for perlin vs simplex difference\n",
    "                        if self.noise_type_dropdown.value == 'perlin':\n",
    "                            octave_value = opensimplex.noise3(sample_x, sample_y, sample_z)\n",
    "                        else:  # simplex\n",
    "                            octave_value = opensimplex.noise3(sample_x + 100, sample_y + 100, sample_z)\n",
    "                        \n",
    "                        value += octave_value * amplitude\n",
    "                        max_value += amplitude\n",
    "                        \n",
    "                        amplitude *= self.persistence_slider.value\n",
    "                        frequency *= self.lacunarity_slider.value\n",
    "                    \n",
    "                    noise_array[i, j] = value / max_value if max_value != 0 else 0\n",
    "        \n",
    "        elif self.noise_type_dropdown.value == 'ridge':\n",
    "            # Ridge noise - absolute value inverted\n",
    "            for i in range(self.height):\n",
    "                for j in range(self.width):\n",
    "                    sample_x = scaled_X[i, j]\n",
    "                    sample_y = scaled_Y[i, j]\n",
    "                    sample_z = time_offset\n",
    "                    \n",
    "                    # Generate fractal noise first\n",
    "                    value = 0.0\n",
    "                    amplitude = 1.0\n",
    "                    frequency = 1.0\n",
    "                    max_value = 0.0\n",
    "                    \n",
    "                    for octave in range(self.octaves_slider.value):\n",
    "                        octave_value = opensimplex.noise3(\n",
    "                            sample_x * frequency, \n",
    "                            sample_y * frequency, \n",
    "                            sample_z * frequency\n",
    "                        )\n",
    "                        value += octave_value * amplitude\n",
    "                        max_value += amplitude\n",
    "                        amplitude *= self.persistence_slider.value\n",
    "                        frequency *= self.lacunarity_slider.value\n",
    "                    \n",
    "                    final_value = value / max_value if max_value != 0 else 0\n",
    "                    noise_array[i, j] = 1.0 - abs(final_value)\n",
    "        \n",
    "        elif self.noise_type_dropdown.value == 'cellular':\n",
    "            # Cellular noise using thresholding\n",
    "            for i in range(self.height):\n",
    "                for j in range(self.width):\n",
    "                    sample_x = scaled_X[i, j] * 2  # Higher frequency for cellular\n",
    "                    sample_y = scaled_Y[i, j] * 2\n",
    "                    sample_z = time_offset\n",
    "                    \n",
    "                    val = opensimplex.noise3(sample_x, sample_y, sample_z)\n",
    "                    noise_array[i, j] = 1.0 if val > 0.1 else 0.0\n",
    "        \n",
    "        # Normalize to [0, 1]\n",
    "        noise_array = (noise_array + 1.0) / 2.0\n",
    "        noise_array = np.clip(noise_array, 0, 1)\n",
    "        \n",
    "        return noise_array\n",
    "    \n",
    "    def create_colormap(self):\n",
    "        \"\"\"Create a matplotlib colormap from color stops.\"\"\"\n",
    "        \n",
    "        # Sort color stops by position\n",
    "        sorted_stops = sorted(self.color_stops, key=lambda x: x['position'])\n",
    "        \n",
    "        # Ensure we have stops at 0.0 and 1.0\n",
    "        positions = [stop['position'] for stop in sorted_stops]\n",
    "        colors = [stop['color'][:3] for stop in sorted_stops]  # RGB only\n",
    "        \n",
    "        # Add stop at 0.0 if missing\n",
    "        if positions[0] > 0.0:\n",
    "            positions.insert(0, 0.0)\n",
    "            colors.insert(0, colors[0])  # Use first color\n",
    "        \n",
    "        # Add stop at 1.0 if missing\n",
    "        if positions[-1] < 1.0:\n",
    "            positions.append(1.0)\n",
    "            colors.append(colors[-1])  # Use last color\n",
    "        \n",
    "        # Create colormap\n",
    "        cmap = LinearSegmentedColormap.from_list('custom', list(zip(positions, colors)))\n",
    "        return cmap\n",
    "    \n",
    "    def hex_to_rgb(self, hex_color):\n",
    "        \"\"\"Convert hex color to RGB tuple.\"\"\"\n",
    "        hex_color = hex_color.lstrip('#')\n",
    "        return [int(hex_color[i:i+2], 16) / 255.0 for i in (0, 2, 4)]\n",
    "    \n",
    "    def calculate_statistics(self, noise_array):\n",
    "        \"\"\"Calculate noise statistics.\"\"\"\n",
    "        stats = {\n",
    "            'mean': np.mean(noise_array),\n",
    "            'std': np.std(noise_array),\n",
    "            'min': np.min(noise_array),\n",
    "            'max': np.max(noise_array),\n",
    "            'range': np.max(noise_array) - np.min(noise_array)\n",
    "        }\n",
    "        return stats\n",
    "    \n",
    "    def update_noise(self, change=None):\n",
    "        \"\"\"Update noise parameters and regenerate visualization.\"\"\"\n",
    "        self.update_display()\n",
    "    \n",
    "    def update_color_preset(self, change=None):\n",
    "        \"\"\"Update color stops based on selected preset.\"\"\"\n",
    "        preset = self.color_preset_dropdown.value\n",
    "        \n",
    "        presets = {\n",
    "            'bw': [\n",
    "                {'position': 0.0, 'color': [0, 0, 0, 1]},\n",
    "                {'position': 1.0, 'color': [1, 1, 1, 1]}\n",
    "            ],\n",
    "            'fire': [\n",
    "                {'position': 0.0, 'color': [0, 0, 0, 1]},\n",
    "                {'position': 0.3, 'color': [0.5, 0, 0, 1]},\n",
    "                {'position': 0.6, 'color': [1, 0.5, 0, 1]},\n",
    "                {'position': 1.0, 'color': [1, 1, 0, 1]}\n",
    "            ],\n",
    "            'ocean': [\n",
    "                {'position': 0.0, 'color': [0, 0, 0.3, 1]},\n",
    "                {'position': 0.5, 'color': [0, 0.3, 0.8, 1]},\n",
    "                {'position': 1.0, 'color': [0.7, 0.9, 1, 1]}\n",
    "            ],\n",
    "            'rainbow': [\n",
    "                {'position': 0.0, 'color': [1, 0, 0, 1]},\n",
    "                {'position': 0.2, 'color': [1, 0.5, 0, 1]},\n",
    "                {'position': 0.4, 'color': [1, 1, 0, 1]},\n",
    "                {'position': 0.6, 'color': [0, 1, 0, 1]},\n",
    "                {'position': 0.8, 'color': [0, 0, 1, 1]},\n",
    "                {'position': 1.0, 'color': [0.5, 0, 1, 1]}\n",
    "            ],\n",
    "            'terrain': [\n",
    "                {'position': 0.0, 'color': [0, 0, 0.5, 1]},\n",
    "                {'position': 0.3, 'color': [0, 0.5, 0, 1]},\n",
    "                {'position': 0.6, 'color': [0.5, 0.3, 0, 1]},\n",
    "                {'position': 0.8, 'color': [0.8, 0.8, 0.8, 1]},\n",
    "                {'position': 1.0, 'color': [1, 1, 1, 1]}\n",
    "            ],\n",
    "            'sunset': [\n",
    "                {'position': 0.0, 'color': [0.1, 0.1, 0.3, 1]},\n",
    "                {'position': 0.3, 'color': [0.8, 0.3, 0.1, 1]},\n",
    "                {'position': 0.7, 'color': [1, 0.7, 0.3, 1]},\n",
    "                {'position': 1.0, 'color': [1, 0.9, 0.7, 1]}\n",
    "            ],\n",
    "            'ice': [\n",
    "                {'position': 0.0, 'color': [0.1, 0.1, 0.3, 1]},\n",
    "                {'position': 0.5, 'color': [0.3, 0.6, 0.9, 1]},\n",
    "                {'position': 1.0, 'color': [0.9, 0.95, 1, 1]}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        if preset in presets:\n",
    "            self.color_stops = presets[preset]\n",
    "            \n",
    "            # Update stop index slider range\n",
    "            self.stop_index_slider.max = len(self.color_stops) - 1\n",
    "            self.stop_index_slider.value = 0\n",
    "            \n",
    "            # Update current stop display\n",
    "            self.select_color_stop()\n",
    "        \n",
    "        self.update_display()\n",
    "    \n",
    "    def update_color_stop(self, change=None):\n",
    "        \"\"\"Update the currently selected color stop.\"\"\"\n",
    "        if len(self.color_stops) == 0:\n",
    "            return\n",
    "            \n",
    "        index = self.stop_index_slider.value\n",
    "        if 0 <= index < len(self.color_stops):\n",
    "            self.color_stops[index]['position'] = self.stop_position_slider.value\n",
    "            rgb = self.hex_to_rgb(self.stop_color_picker.value)\n",
    "            self.color_stops[index]['color'] = rgb + [1.0]  # Add alpha\n",
    "            \n",
    "            # Validate after update\n",
    "            self.validate_color_stops()\n",
    "            \n",
    "        self.update_display()\n",
    "    \n",
    "    def select_color_stop(self, change=None):\n",
    "        \"\"\"Select a color stop for editing.\"\"\"\n",
    "        index = self.stop_index_slider.value\n",
    "        if 0 <= index < len(self.color_stops):\n",
    "            stop = self.color_stops[index]\n",
    "            self.stop_position_slider.value = stop['position']\n",
    "            \n",
    "            # Convert RGB to hex\n",
    "            rgb = stop['color'][:3]\n",
    "            hex_color = '#{:02x}{:02x}{:02x}'.format(\n",
    "                int(rgb[0] * 255),\n",
    "                int(rgb[1] * 255),\n",
    "                int(rgb[2] * 255)\n",
    "            )\n",
    "            self.stop_color_picker.value = hex_color\n",
    "    \n",
    "    def add_color_stop(self, button):\n",
    "        \"\"\"Add a new color stop.\"\"\"\n",
    "        # Find position for new stop\n",
    "        new_position = 0.5\n",
    "        if len(self.color_stops) > 0:\n",
    "            positions = [stop['position'] for stop in self.color_stops]\n",
    "            positions.sort()\n",
    "            # Find largest gap\n",
    "            max_gap = 0\n",
    "            best_pos = 0.5\n",
    "            for i in range(len(positions) - 1):\n",
    "                gap = positions[i + 1] - positions[i]\n",
    "                if gap > max_gap:\n",
    "                    max_gap = gap\n",
    "                    best_pos = (positions[i] + positions[i + 1]) / 2\n",
    "            new_position = best_pos\n",
    "        \n",
    "        # Add new stop\n",
    "        new_stop = {'position': new_position, 'color': [0.5, 0.5, 0.5, 1]}\n",
    "        self.color_stops.append(new_stop)\n",
    "        \n",
    "        # Update slider range and select new stop\n",
    "        self.stop_index_slider.max = len(self.color_stops) - 1\n",
    "        self.stop_index_slider.value = len(self.color_stops) - 1\n",
    "        self.select_color_stop()\n",
    "        \n",
    "        self.update_display()\n",
    "    \n",
    "    def remove_color_stop(self, button):\n",
    "        \"\"\"Remove the currently selected color stop.\"\"\"\n",
    "        if len(self.color_stops) <= 2:\n",
    "            return  # Keep at least 2 stops\n",
    "            \n",
    "        index = self.stop_index_slider.value\n",
    "        if 0 <= index < len(self.color_stops):\n",
    "            self.color_stops.pop(index)\n",
    "            \n",
    "            # Update slider range\n",
    "            self.stop_index_slider.max = len(self.color_stops) - 1\n",
    "            if self.stop_index_slider.value >= len(self.color_stops):\n",
    "                self.stop_index_slider.value = len(self.color_stops) - 1\n",
    "            \n",
    "            # Ensure we still have stops at 0.0 and 1.0\n",
    "            self.validate_color_stops()\n",
    "            \n",
    "            self.select_color_stop()\n",
    "        \n",
    "        self.update_display()\n",
    "    \n",
    "    def validate_color_stops(self):\n",
    "        \"\"\"Ensure color stops are valid (have stops at 0.0 and 1.0).\"\"\"\n",
    "        positions = [stop['position'] for stop in self.color_stops]\n",
    "        \n",
    "        # Check if we have a stop at 0.0\n",
    "        has_zero = any(abs(pos) < 0.001 for pos in positions)\n",
    "        if not has_zero:\n",
    "            # Find the stop closest to 0 and set it to 0\n",
    "            min_idx = min(range(len(positions)), key=lambda i: positions[i])\n",
    "            self.color_stops[min_idx]['position'] = 0.0\n",
    "        \n",
    "        # Check if we have a stop at 1.0\n",
    "        has_one = any(abs(pos - 1.0) < 0.001 for pos in positions)\n",
    "        if not has_one:\n",
    "            # Find the stop closest to 1 and set it to 1\n",
    "            max_idx = max(range(len(positions)), key=lambda i: positions[i])\n",
    "            self.color_stops[max_idx]['position'] = 1.0\n",
    "    \n",
    "    def toggle_animation(self, button):\n",
    "        \"\"\"Toggle noise animation.\"\"\"\n",
    "        if button.description == 'Start Animation':\n",
    "            button.description = 'Stop Animation'\n",
    "            button.button_style = 'warning'\n",
    "            # TODO: Implement animation loop\n",
    "        else:\n",
    "            button.description = 'Start Animation'\n",
    "            button.button_style = 'info'\n",
    "    \n",
    "    def update_display(self, change=None):\n",
    "        \"\"\"Update the main visualization.\"\"\"\n",
    "        with self.output:\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Generate noise\n",
    "            noise_array = self.generate_noise()\n",
    "            \n",
    "            # Create colormap\n",
    "            cmap = self.create_colormap()\n",
    "            \n",
    "            # Create figure\n",
    "            if self.show_histogram.value or self.show_stats.value:\n",
    "                fig, axes = plt.subplots(2, 2, figsize=self.fig_size)\n",
    "                ax_main = axes[0, :]\n",
    "                ax_hist = axes[1, 0] if self.show_histogram.value else None\n",
    "                ax_stats = axes[1, 1] if self.show_stats.value else None\n",
    "            else:\n",
    "                fig, ax_main = plt.subplots(1, 1, figsize=(8, 6))\n",
    "                axes = None\n",
    "            \n",
    "            # Main noise visualization\n",
    "            if axes is not None:\n",
    "                im = ax_main[0].imshow(noise_array, cmap=cmap, origin='lower')\n",
    "                ax_main[0].set_title(f'{self.noise_type_dropdown.value.title()} Noise with Color Ramp')\n",
    "                ax_main[0].axis('off')\n",
    "                \n",
    "                # Color ramp visualization\n",
    "                gradient = np.linspace(0, 1, 256).reshape(1, -1)\n",
    "                ax_main[1].imshow(gradient, aspect='auto', cmap=cmap)\n",
    "                ax_main[1].set_title('Color Ramp')\n",
    "                ax_main[1].set_xlim(0, 255)\n",
    "                ax_main[1].set_xticks([0, 64, 128, 192, 255])\n",
    "                ax_main[1].set_xticklabels(['0.0', '0.25', '0.5', '0.75', '1.0'])\n",
    "                ax_main[1].set_yticks([])\n",
    "            else:\n",
    "                im = ax_main.imshow(noise_array, cmap=cmap, origin='lower')\n",
    "                ax_main.set_title(f'{self.noise_type_dropdown.value.title()} Noise with Color Ramp')\n",
    "                ax_main.axis('off')\n",
    "            \n",
    "            # Histogram\n",
    "            if self.show_histogram.value and ax_hist is not None:\n",
    "                ax_hist.hist(noise_array.flatten(), bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "                ax_hist.set_title('Noise Value Distribution')\n",
    "                ax_hist.set_xlabel('Noise Value')\n",
    "                ax_hist.set_ylabel('Frequency')\n",
    "                ax_hist.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Statistics\n",
    "            if self.show_stats.value and ax_stats is not None:\n",
    "                stats = self.calculate_statistics(noise_array)\n",
    "                stats_text = f\"\"\"Statistics:\n",
    "Mean: {stats['mean']:.3f}\n",
    "Std: {stats['std']:.3f}\n",
    "Min: {stats['min']:.3f}\n",
    "Max: {stats['max']:.3f}\n",
    "Range: {stats['range']:.3f}\n",
    "\n",
    "Parameters:\n",
    "Scale: {self.scale_slider.value}\n",
    "Octaves: {self.octaves_slider.value}\n",
    "Persistence: {self.persistence_slider.value:.2f}\n",
    "Lacunarity: {self.lacunarity_slider.value:.1f}\"\"\"\n",
    "                \n",
    "                ax_stats.text(0.05, 0.95, stats_text, transform=ax_stats.transAxes, \n",
    "                             verticalalignment='top', fontfamily='monospace', fontsize=10)\n",
    "                ax_stats.set_title('Noise Statistics')\n",
    "                ax_stats.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the complete widget interface.\"\"\"\n",
    "        \n",
    "        # Create widget layout\n",
    "        noise_controls = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>ðŸ”Š Noise Parameters</h3>\"),\n",
    "            self.noise_type_dropdown,\n",
    "            self.scale_slider,\n",
    "            self.octaves_slider,\n",
    "            self.persistence_slider,\n",
    "            self.lacunarity_slider,\n",
    "            self.time_offset_slider\n",
    "        ])\n",
    "        \n",
    "        color_controls = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>ðŸŽ¨ Color Ramp</h3>\"),\n",
    "            self.color_preset_dropdown,\n",
    "            widgets.HTML(\"<b>Edit Color Stops:</b>\"),\n",
    "            self.stop_index_slider,\n",
    "            self.stop_position_slider,\n",
    "            self.stop_color_picker,\n",
    "            widgets.HBox([self.add_stop_button, self.remove_stop_button])\n",
    "        ])\n",
    "        \n",
    "        animation_controls = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>âš¡ Animation & Analysis</h3>\"),\n",
    "            self.animate_button,\n",
    "            self.animation_speed_slider,\n",
    "            self.show_histogram,\n",
    "            self.show_stats\n",
    "        ])\n",
    "        \n",
    "        controls_panel = widgets.HBox([\n",
    "            noise_controls,\n",
    "            color_controls,\n",
    "            animation_controls\n",
    "        ])\n",
    "        \n",
    "        main_interface = widgets.VBox([\n",
    "            widgets.HTML(\"<h2>ðŸŽ¨ Color Ramp Noise Function Explorer</h2>\"),\n",
    "            controls_panel,\n",
    "            self.output\n",
    "        ])\n",
    "        \n",
    "        # Initial display\n",
    "        self.update_display()\n",
    "        \n",
    "        return main_interface\n",
    "\n",
    "# Usage example:\n",
    "def create_color_ramp_explorer():\n",
    "    \"\"\"Create and return a ColorRampNoiseExplorer widget.\"\"\"\n",
    "    explorer = ColorRampNoiseExplorer()\n",
    "    return explorer.display()\n",
    "\n",
    "# Installation instructions:\n",
    "\"\"\"\n",
    "To use this Color Ramp Noise Explorer widget:\n",
    "\n",
    "REQUIRED packages:\n",
    "    pip install ipywidgets matplotlib numpy scipy opensimplex\n",
    "\n",
    "USAGE in Jupyter notebook:\n",
    "    widget = create_color_ramp_explorer()\n",
    "    display(widget)\n",
    "\n",
    "The widget will automatically use opensimplex for high-quality noise generation,\n",
    "with built-in fallback functions if opensimplex is not available.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51ada351-333b-46c0-905a-ec28476e9ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd977bc50c124a0888a400d6ecfa9634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>ðŸŽ¨ Color Ramp Noise Function Explorer</h2>'), HBox(children=(VBox(children=(HTMLâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget = create_color_ramp_explorer()\n",
    "display(widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7323997-2b3f-405a-a431-b065f966d700",
   "metadata": {},
   "source": [
    "# Gfow Machinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92e6975b-ab53-4f03-a85a-56d9566ee734",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFlowNet:\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        self.forward_net = MLP(...)  # P_F network\n",
    "        self.backward_net = MLP(...) # P_B network  \n",
    "        self.log_Z = nn.Parameter(torch.tensor(0.0))  # Initial flow\n",
    "        \n",
    "    def forward_policy(self, state):\n",
    "        # Return action probabilities\n",
    "        pass\n",
    "    def backward_policy(self, state, parent_state):\n",
    "        # Return backward transition probs\n",
    "        pass\n",
    "        \n",
    "    def sample_trajectory(self):\n",
    "        # Generate complete trajectory using P_F\n",
    "        pass\n",
    "        \n",
    "    def trajectory_balance_loss(self, trajectories):\n",
    "        # Implement Equation (1) from paper\n",
    "        pass\n",
    "        \n",
    "    def train_step(self, batch_trajectories):\n",
    "        # Compute loss and update parameters\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa7b49-812c-4e0b-b9b6-954a9760df67",
   "metadata": {},
   "source": [
    "## General Flow Network model (NOT GFN)\n",
    "This is what the flow network started as that is trying to flow match based on trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff6ae3e-da06-414b-8ded-d4c5c4e55da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Network Experiment\n",
      "========================================\n",
      "\n",
      "State s0: [1.0, 0.0, 0.0, 0.0, 0.0]\n",
      "Action probabilities: [0.34223992 0.3381573  0.31960285]\n",
      "Sum of probs: 1.000\n",
      "\n",
      "State s1: [0.0, 1.0, 0.0, 0.0, 0.0]\n",
      "Action probabilities: [0.2774047  0.35551074 0.3670846 ]\n",
      "Sum of probs: 1.000\n",
      "\n",
      "State s2: [0.0, 0.0, 1.0, 0.0, 0.0]\n",
      "Action probabilities: [0.2984059  0.35374996 0.3478442 ]\n",
      "Sum of probs: 1.000\n",
      "\n",
      "========================================\n",
      "Sampling actions:\n",
      "State s0 â†’ Action 0 (prob: 0.342)\n",
      "State s1 â†’ Action 1 (prob: 0.356)\n",
      "State s2 â†’ Action 2 (prob: 0.348)\n",
      "\n",
      "That's it! Feed in state, get out action probabilities.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def forward_network_validation():\n",
    "    \"\"\"\n",
    "    This is just validating that the Model that I am using will work\n",
    "    \"\"\"\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    # Just the network, no class wrapper\n",
    "    state_dim = 5  # 5 states in our example\n",
    "    action_dim = 3  # max 3 possible actions from any state\n",
    "    \n",
    "    # ======================================================================\n",
    "    # Flow Based model Definition\n",
    "    # ======================================================================\n",
    "    forward_net = nn.Sequential(\n",
    "        nn.Linear(state_dim, 32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32, action_dim),\n",
    "        nn.Softmax(dim=-1)\n",
    "    )\n",
    "    # Test with different states\n",
    "    states = {\n",
    "        's0': torch.tensor([1, 0, 0, 0, 0], dtype=torch.float32),  # one-hot for s0\n",
    "        's1': torch.tensor([0, 1, 0, 0, 0], dtype=torch.float32),  # one-hot for s1  \n",
    "        's2': torch.tensor([0, 0, 1, 0, 0], dtype=torch.float32),  # one-hot for s2\n",
    "    }\n",
    "    print(\"Forward Network Experiment\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for state_name, state_vector in states.items():\n",
    "        action_probs = forward_net(state_vector)\n",
    "        print(f\"\\nState {state_name}: {state_vector.tolist()}\")\n",
    "        print(f\"Action probabilities: {action_probs.detach().numpy()}\")\n",
    "        print(f\"Sum of probs: {action_probs.sum().item():.3f}\")  # Should be 1.0\n",
    "    \n",
    "    # Sample an action from the probabilities\n",
    "    print(\"\\n\" + \"=\" * 40)\n",
    "    print(\"Sampling actions:\")\n",
    "    for state_name, state_vector in states.items():\n",
    "        action_probs = forward_net(state_vector)\n",
    "        action = torch.multinomial(action_probs, 1).item()\n",
    "        print(f\"State {state_name} â†’ Action {action} (prob: {action_probs[action]:.3f})\")\n",
    "    \n",
    "    print(\"\\nThat's it! Feed in state, get out action probabilities.\")\n",
    "\n",
    "# ======================================================================\n",
    "# Loss Function for Flow Based model\n",
    "# ======================================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "def flow_conservation_loss(flow_net, visited_states, edges, rewards, encode_state):\n",
    "    \"\"\"Flow conservation loss - physics constraint\"\"\"\n",
    "    total_loss = torch.tensor(0.0)\n",
    "    \n",
    "    # Collect data for table\n",
    "    table_data = []\n",
    "    \n",
    "    for state in visited_states:\n",
    "        flow_in = torch.tensor(0.0)\n",
    "        flow_out = torch.tensor(0.0)\n",
    "        \n",
    "        # ======================================================================\n",
    "        # FLOW IN\n",
    "        # ======================================================================\n",
    "        incoming_details = []\n",
    "        for from_state, to_state in edges:\n",
    "            if to_state == state:\n",
    "                from_vec = encode_state(from_state)\n",
    "                to_vec = encode_state(to_state)\n",
    "                edge_input = torch.cat([from_vec, to_vec])\n",
    "                predicted_flow = flow_net(edge_input).squeeze()\n",
    "                flow_in += predicted_flow\n",
    "                incoming_details.append(f\"{from_state}â†’{predicted_flow.item():.3f}\")\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Flow OUT (rewards + outgoing flows)\n",
    "        # ======================================================================\n",
    "        outgoing_details = []\n",
    "        \n",
    "        if state in rewards:\n",
    "            reward_flow = torch.tensor(rewards[state])\n",
    "            flow_out += reward_flow\n",
    "            outgoing_details.append(f\"R:{reward_flow.item():.1f}\")\n",
    "        \n",
    "        for from_state, to_state in edges:\n",
    "            if from_state == state:\n",
    "                from_vec = encode_state(from_state)\n",
    "                to_vec = encode_state(to_state)\n",
    "                edge_input = torch.cat([from_vec, to_vec])\n",
    "                predicted_flow = flow_net(edge_input).squeeze()\n",
    "                flow_out += predicted_flow\n",
    "                outgoing_details.append(f\"â†’{to_state}:{predicted_flow.item():.3f}\")\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Conservation Constraint Flow In == Flow out\n",
    "        # ======================================================================\n",
    "        conservation_error = (flow_in - flow_out) ** 2\n",
    "        \n",
    "        # Format details\n",
    "        in_detail = \",\".join(incoming_details) if incoming_details else \"none\"\n",
    "        out_detail = \",\".join(outgoing_details) if outgoing_details else \"none\"\n",
    "        \n",
    "        table_data.append({\n",
    "            'State': state,\n",
    "            'Flow_IN': flow_in.item(),\n",
    "            'Flow_OUT': flow_out.item(),\n",
    "            'Error': conservation_error.item(),\n",
    "            'IN_Details': in_detail,\n",
    "            'OUT_Details': out_detail\n",
    "        })\n",
    "        \n",
    "        total_loss += conservation_error\n",
    "    \n",
    "    # Create and display pandas table\n",
    "    df = pd.DataFrame(table_data)\n",
    "    print(\"\\n=== FLOW CONSERVATION ANALYSIS ===\")\n",
    "    print(df.to_string(index=False, float_format='%.4f'))\n",
    "    print(f\"\\nTotal Loss: {total_loss.item():.6f}\")\n",
    "    print(\"Expected: Flow IN = Flow OUT for all states\")\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "forward_network_validation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524519c-305e-4146-8f3d-a6de05dc7eae",
   "metadata": {},
   "source": [
    "## Trajectory Balance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9d0b01-7574-407c-81b6-97619c8c1b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================================\n",
    "# Trajecory balance Model Definition\n",
    "# ======================================================================\n",
    "class TBModel(nn.Module):\n",
    "    def __init__(self, state_dim, num_hid=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Forward polocy model\n",
    "        # ======================================================================\n",
    "        \n",
    "        self.forward_policy = nn.Sequential(\n",
    "            nn.Linear(state_dim, num_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hid, state_dim)\n",
    "        )\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Backward polocy model\n",
    "        # ======================================================================\n",
    "        \n",
    "        self.backward_policy = nn.Sequential(\n",
    "            nn.Linear(state_dim, num_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hid, state_dim)\n",
    "        )\n",
    "        \n",
    "        # ======================================================================\n",
    "        # partition function\n",
    "        # ======================================================================\n",
    "        \n",
    "        self.logZ = nn.Parameter(torch.tensor(5.0))\n",
    "    \n",
    "    def forward(self, state_onehot):\n",
    "        P_F_logits = self.forward_policy(state_onehot)\n",
    "        P_B_logits = self.backward_policy(state_onehot)\n",
    "        return P_F_logits, P_B_logits\n",
    "\n",
    "# ======================================================================\n",
    "# Loss Function for Trajecory balance Model\n",
    "# ======================================================================\n",
    "def trajectory_balance_loss(forward_logits, backward_logits, logZ, trajectory, reward):\n",
    "    \"\"\"\n",
    "    From paper equation (1):\n",
    "    L_TB = [log(Z_Î¸ * âˆP_F) - log(R(x) * âˆP_B)]Â²\n",
    "    \"\"\"\n",
    "\n",
    "    # Forward path: Z_Î¸ * âˆP_F(s_t|s_{t-1})\n",
    "\n",
    "    log_forward_prob = logZ + sum_of_forward_log_probs_along_trajectory\n",
    "    \n",
    "\n",
    "    # Backward path: R(x) * âˆP_B(s_{t-1}|s_t) \n",
    "\n",
    "    log_backward_prob = torch.log(reward) + sum_of_backward_log_probs_along_trajectory\n",
    "\n",
    "\n",
    "    # Trajectory balance loss\n",
    "\n",
    "    loss = (log_forward_prob - log_backward_prob) ** 2\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8376461b-0324-4512-b10d-511bf2232552",
   "metadata": {},
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15a95738-0619-4838-a127-da5cf7928088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Simple Trajectory Balance Example\n",
      "==================================================\n",
      "Trajectory: (0,0) -> (1,0) -> (2,0)\n",
      "Actions: right, right\n",
      "Final reward: 1.0\n",
      "\n",
      "ðŸ”® Forward Path: Z_Î¸ * P_F(right|(0,0)) * P_F(right|(1,0))\n",
      "   = exp(logZ) * P_F(action1) * P_F(action2)\n",
      "   = exp(5.0) * 0.4 * 0.3  (example probabilities)\n",
      "   = 148.4 * 0.4 * 0.3 = 17.8\n",
      "   log_forward = 5.0 + log(0.4) + log(0.3) = 2.77\n",
      "\n",
      "ðŸ”™ Backward Path: R(x) * P_B(right|(1,0)) * P_B(right|(2,0))\n",
      "   = 1.0 * P_B(action1) * P_B(action2)\n",
      "   = 1.0 * 0.5 * 0.6  (example probabilities)\n",
      "   = 0.3\n",
      "   log_backward = log(1.0) + log(0.5) + log(0.6) = -1.20\n",
      "\n",
      "ðŸ’¥ Trajectory Balance Loss:\n",
      "   L_TB = [log_forward - log_backward]Â²\n",
      "   = [2.77 - (-1.20)]Â²\n",
      "   = [3.97]Â²\n",
      "   = 15.76\n",
      "\n",
      "ðŸŽ¯ The model will adjust logZ, P_F, and P_B to minimize this!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def trajectory_balance_loss(model, trajectories, env):\n",
    "    \"\"\"\n",
    "    Trajectory Balance Loss from paper equation (1):\n",
    "    L_TB = [log(Z_Î¸ * âˆP_F) - log(R(x) * âˆP_B)]Â²\n",
    "    \n",
    "    Optimized version with early termination for invalid trajectories.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ===================================================================\n",
    "    # EARLY CHECK: Filter for rewarded trajectories upfront\n",
    "    # ===================================================================\n",
    "    rewarded_trajectories = []\n",
    "    for traj in trajectories:\n",
    "        if len(traj) >= 2:  # Valid length\n",
    "            final_state = traj[-1]\n",
    "            reward = env.get_reward(final_state)\n",
    "            if reward > 0:  # Has reward\n",
    "                rewarded_trajectories.append((traj, reward))\n",
    "    \n",
    "    # Early exit if no valid trajectories\n",
    "    if len(rewarded_trajectories) == 0:\n",
    "        return torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "    # ===================================================================\n",
    "    # MAIN COMPUTATION: Process only rewarded trajectories\n",
    "    # ===================================================================\n",
    "    total_loss = torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "    for traj, reward in rewarded_trajectories:\n",
    "        \n",
    "        # ===================================================================\n",
    "        # STEP 1: Compute FORWARD path probability\n",
    "        # This is: Z_Î¸ * âˆP_F(s_t|s_{t-1}) for each step in trajectory\n",
    "        # ===================================================================\n",
    "        \n",
    "        # Start with logZ (the partition function)\n",
    "        log_forward = model.logZ\n",
    "        \n",
    "        # For each step in the trajectory: s0 -> s1 -> s2 -> ... -> final\n",
    "        for step in range(len(traj) - 1):\n",
    "            current_state = traj[step]      # Where we are\n",
    "            next_state = traj[step + 1]     # Where we go next\n",
    "            \n",
    "            # Encode the current state for the neural network\n",
    "            current_encoding = torch.tensor(env.encode_state(current_state), dtype=torch.float)\n",
    "            \n",
    "            # Get forward policy predictions: \"from current state, where should I go?\"\n",
    "            P_F_logits, _ = model(current_encoding)  # Shape: [4] for 4 actions\n",
    "            \n",
    "            # Mask out invalid actions explicitly\n",
    "            action_mask = torch.tensor(env.get_valid_action_mask(current_state))\n",
    "            masked_logits = P_F_logits.clone()\n",
    "            \n",
    "            # Set invalid actions to large negative value (makes probability â‰ˆ 0)\n",
    "            for action_idx in range(len(masked_logits)):\n",
    "                if action_mask[action_idx] == 0:  # Invalid action\n",
    "                    masked_logits[action_idx] = -100.0\n",
    "            \n",
    "            # Convert to probabilities\n",
    "            probs = F.softmax(masked_logits, dim=0)  # Shape: [4]\n",
    "            \n",
    "            # Find which action was actually taken in this trajectory\n",
    "            for action_str in env.get_valid_actions(current_state):\n",
    "                if env.take_action(current_state, action_str) == next_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    # Add log probability of this action to forward path\n",
    "                    log_forward = log_forward + torch.log(probs[action_idx].clamp(min=1e-8))\n",
    "                    break\n",
    "        \n",
    "        # ===================================================================\n",
    "        # STEP 2: Compute BACKWARD path probability  \n",
    "        # This is: R(x) * âˆP_B(s_{t-1}|s_t) for each step BACKWARDS\n",
    "        # ===================================================================\n",
    "        \n",
    "        # Start with the reward at the end\n",
    "        log_backward = torch.log(torch.tensor(reward, dtype=torch.float, requires_grad=True))\n",
    "        \n",
    "        # For each step BACKWARDS: final -> ... -> s2 -> s1 -> s0\n",
    "        for step in range(len(traj) - 1, 0, -1):\n",
    "            current_state = traj[step]      # Where we are now\n",
    "            prev_state = traj[step - 1]     # Where we came from\n",
    "            \n",
    "            # Encode current state for neural network\n",
    "            current_encoding = torch.tensor(env.encode_state(current_state), dtype=torch.float)\n",
    "            \n",
    "            # Get backward policy predictions: \"to get here, where did I come from?\"\n",
    "            _, P_B_logits = model(current_encoding)  # Shape: [4] for 4 actions\n",
    "            \n",
    "            # For backward, valid actions are those that could have led here\n",
    "            valid_prev_actions = []\n",
    "            for action_str in env.get_action_list():\n",
    "                action_idx = env.action_to_index(action_str)\n",
    "                if env.take_action(prev_state, action_str) == current_state:\n",
    "                    valid_prev_actions.append(action_idx)\n",
    "            \n",
    "            # Create mask for valid previous actions\n",
    "            prev_action_mask = torch.zeros(4)\n",
    "            for action_idx in valid_prev_actions:\n",
    "                prev_action_mask[action_idx] = 1.0\n",
    "            \n",
    "            # Mask invalid previous actions explicitly\n",
    "            masked_logits = P_B_logits.clone()\n",
    "            for action_idx in range(len(masked_logits)):\n",
    "                if prev_action_mask[action_idx] == 0:  # Invalid previous action\n",
    "                    masked_logits[action_idx] = -100.0\n",
    "            \n",
    "            # Convert to probabilities\n",
    "            probs = F.softmax(masked_logits, dim=0)\n",
    "            \n",
    "            # Find which action led to current state\n",
    "            for action_str in env.get_action_list():\n",
    "                if env.take_action(prev_state, action_str) == current_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    # Add log probability of this action to backward path\n",
    "                    log_backward = log_backward + torch.log(probs[action_idx].clamp(min=1e-8))\n",
    "                    break\n",
    "        \n",
    "        # ===================================================================\n",
    "        # STEP 3: Apply trajectory balance equation\n",
    "        # L_TB = [log(forward) - log(backward)]Â²\n",
    "        # ===================================================================\n",
    "        trajectory_loss = (log_forward - log_backward) ** 2\n",
    "        total_loss = total_loss + trajectory_loss\n",
    "    \n",
    "    # ===================================================================\n",
    "    # STEP 4: Return average loss over rewarded trajectories\n",
    "    # ===================================================================\n",
    "    return total_loss / len(rewarded_trajectories)\n",
    "\n",
    "\n",
    "# ===================================================================\n",
    "# SIMPLE EXAMPLE to show what's happening\n",
    "# ===================================================================\n",
    "def simple_example():\n",
    "    \"\"\"\n",
    "    Let's trace through a simple 2-step trajectory: (0,0) -> (1,0) -> (2,0)\n",
    "    \"\"\"\n",
    "    print(\"ðŸ” Simple Trajectory Balance Example\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Imagine we have trajectory: (0,0) -> (1,0) -> (2,0)  \n",
    "    # Actions taken: \"right\", \"right\"\n",
    "    # Final reward: 1.0\n",
    "    \n",
    "    print(\"Trajectory: (0,0) -> (1,0) -> (2,0)\")\n",
    "    print(\"Actions: right, right\") \n",
    "    print(\"Final reward: 1.0\")\n",
    "    print()\n",
    "    \n",
    "    # FORWARD PATH COMPUTATION:\n",
    "    print(\"ðŸ”® Forward Path: Z_Î¸ * P_F(right|(0,0)) * P_F(right|(1,0))\")\n",
    "    print(\"   = exp(logZ) * P_F(action1) * P_F(action2)\")\n",
    "    print(\"   = exp(5.0) * 0.4 * 0.3  (example probabilities)\")\n",
    "    print(\"   = 148.4 * 0.4 * 0.3 = 17.8\")\n",
    "    print(\"   log_forward = 5.0 + log(0.4) + log(0.3) = 2.77\")\n",
    "    print()\n",
    "    \n",
    "    # BACKWARD PATH COMPUTATION:\n",
    "    print(\"ðŸ”™ Backward Path: R(x) * P_B(right|(1,0)) * P_B(right|(2,0))\")  \n",
    "    print(\"   = 1.0 * P_B(action1) * P_B(action2)\")\n",
    "    print(\"   = 1.0 * 0.5 * 0.6  (example probabilities)\")\n",
    "    print(\"   = 0.3\")\n",
    "    print(\"   log_backward = log(1.0) + log(0.5) + log(0.6) = -1.20\")\n",
    "    print()\n",
    "    \n",
    "    # LOSS COMPUTATION:\n",
    "    print(\"ðŸ’¥ Trajectory Balance Loss:\")\n",
    "    print(\"   L_TB = [log_forward - log_backward]Â²\")\n",
    "    print(\"   = [2.77 - (-1.20)]Â²\")\n",
    "    print(\"   = [3.97]Â²\")  \n",
    "    print(\"   = 15.76\")\n",
    "    print()\n",
    "    print(\"ðŸŽ¯ The model will adjust logZ, P_F, and P_B to minimize this!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    simple_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab44d6f-c170-4536-9074-62083e7b2921",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d1ef50-fe75-4915-b9d0-4cfeebde10be",
   "metadata": {},
   "source": [
    "# Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e7cbe2-2046-42ad-86dc-86d7690c69d5",
   "metadata": {},
   "source": [
    "## Gridworld "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff9b36f5-98c5-4677-9eec-2ac3f938fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Set, Dict, Union, Optional\n",
    "\n",
    "# ====================================================\n",
    "# Define HyperGrid Environment (Encoded State Only)\n",
    "# ====================================================\n",
    "class HyperGrid:\n",
    "    \"\"\"8x8 HyperGrid environment for GFlowNet - All methods use encoded states\"\"\"\n",
    "    \n",
    "    def __init__(self, size: int = 8, reward_region_size: int = 2) -> None:\n",
    "        self.size = size\n",
    "        self.reward_region_size = reward_region_size\n",
    "        \n",
    "        # Define goal region bounds (computed, not stored)\n",
    "        self.goal_min_x = size - reward_region_size\n",
    "        self.goal_min_y = size - reward_region_size\n",
    "        \n",
    "        # Start state as encoded\n",
    "        self.start_state = tuple(self.encode_raw_state((0, 0)))\n",
    "        \n",
    "        print(f\"Grid size: {size}x{size}\")\n",
    "        print(f\"Goal region: x >= {self.goal_min_x}, y >= {self.goal_min_y}\")\n",
    "        print(f\"State encoding dimension: {self.get_state_dim()}\")\n",
    "    \n",
    "    # ====================================================\n",
    "    # State encoding utilities\n",
    "    # ====================================================\n",
    "    \n",
    "    def encode_raw_state(self, raw_state: Tuple[int, int]) -> List[float]:\n",
    "        \"\"\"Convert raw (x,y) state to encoded one-hot vector\n",
    "        \n",
    "        Args:\n",
    "            raw_state: (x, y) tuple\n",
    "        Returns:\n",
    "            list: one-hot encoded vector of length sizeÂ²\n",
    "        \"\"\"\n",
    "        x, y = raw_state\n",
    "        idx = y * self.size + x\n",
    "        encoding = [0.0] * (self.size * self.size)\n",
    "        encoding[idx] = 1.0\n",
    "        return encoding\n",
    "    \n",
    "    def decode_state_to_raw(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> Tuple[int, int]:\n",
    "        \"\"\"Convert encoded state back to raw (x,y) tuple\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot vector or tuple\n",
    "        Returns:\n",
    "            tuple: (x, y) coordinates\n",
    "        \"\"\"\n",
    "        if isinstance(encoded_state, tuple):\n",
    "            encoded_state = list(encoded_state)\n",
    "        \n",
    "        idx = encoded_state.index(1.0)\n",
    "        x = idx % self.size\n",
    "        y = idx // self.size\n",
    "        return (x, y)\n",
    "    \n",
    "    def get_state_dim(self) -> int:\n",
    "        \"\"\"Get the dimension of encoded states\"\"\"\n",
    "        return self.size * self.size\n",
    "    \n",
    "    # ====================================================\n",
    "    # Actions (work with encoded states)\n",
    "    # ====================================================    \n",
    "    \n",
    "    def get_valid_actions(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[str]:\n",
    "        \"\"\"Get valid actions from an encoded state\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            list: valid action strings\n",
    "        \"\"\"\n",
    "        # Convert to raw to check boundaries\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        actions = []\n",
    "        \n",
    "        if x + 1 < self.size:\n",
    "            actions.append('right')\n",
    "        if y + 1 < self.size:\n",
    "            actions.append('up')\n",
    "        if x - 1 >= 0:\n",
    "            actions.append('left')\n",
    "        if y - 1 >= 0:\n",
    "            actions.append('down')\n",
    "            \n",
    "        return actions\n",
    "    \n",
    "    def take_action(self, encoded_state: Union[List[float], Tuple[float, ...]], action: str) -> Tuple[float, ...]:\n",
    "        \"\"\"Take action from encoded state to get next encoded state\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "            action: action string\n",
    "        Returns:\n",
    "            tuple: next encoded state\n",
    "        \"\"\"\n",
    "        # Convert to raw, take action, convert back\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        \n",
    "        if action == 'right':\n",
    "            new_raw = (x + 1, y)\n",
    "        elif action == 'up':\n",
    "            new_raw = (x, y + 1)\n",
    "        elif action == 'left':\n",
    "            new_raw = (x - 1, y)\n",
    "        elif action == 'down':\n",
    "            new_raw = (x, y - 1)\n",
    "        else:\n",
    "            new_raw = (x, y)\n",
    "        \n",
    "        return tuple(self.encode_raw_state(new_raw))\n",
    "    \n",
    "    # ====================================================\n",
    "    # Action encoding\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_action_list(self) -> List[str]:\n",
    "        \"\"\"Get list of all possible actions\"\"\"\n",
    "        return ['right', 'up', 'left', 'down']\n",
    "    \n",
    "    def action_to_index(self, action: str) -> int:\n",
    "        \"\"\"Convert action string to index\"\"\"\n",
    "        action_map = {'right': 0, 'up': 1, 'left': 2, 'down': 3}\n",
    "        return action_map.get(action, -1)\n",
    "    \n",
    "    def index_to_action(self, index: int) -> Optional[str]:\n",
    "        \"\"\"Convert action index to string\"\"\"\n",
    "        actions = ['right', 'up', 'left', 'down']\n",
    "        return actions[index] if 0 <= index < len(actions) else None\n",
    "    \n",
    "    def get_action_dim(self) -> int:\n",
    "        \"\"\"Get number of possible actions\"\"\"\n",
    "        return 4\n",
    "    \n",
    "    # ====================================================\n",
    "    # Action masking (work with encoded states)\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_valid_action_mask(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[float]:\n",
    "        \"\"\"Get binary mask for valid actions\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            list: [right, up, left, down] with 1.0 for valid, 0.0 for invalid\n",
    "        \"\"\"\n",
    "        valid_actions = self.get_valid_actions(encoded_state)\n",
    "        mask = [0.0] * 4\n",
    "        for action in valid_actions:\n",
    "            idx = self.action_to_index(action)\n",
    "            if idx >= 0:\n",
    "                mask[idx] = 1.0\n",
    "        return mask\n",
    "    \n",
    "    def get_valid_parent_states(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[Tuple[float, ...]]:\n",
    "        \"\"\"Get all encoded states that can reach this state in one step\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            list: List of encoded states that can reach this state\n",
    "        \"\"\"\n",
    "        # Convert to raw to find parents\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        parent_raws = []\n",
    "        \n",
    "        # Check each direction\n",
    "        if x > 0:  # Could have come from left\n",
    "            parent_raws.append((x - 1, y))\n",
    "        if x < self.size - 1:  # Could have come from right\n",
    "            parent_raws.append((x + 1, y))\n",
    "        if y > 0:  # Could have come from below\n",
    "            parent_raws.append((x, y - 1))\n",
    "        if y < self.size - 1:  # Could have come from above\n",
    "            parent_raws.append((x, y + 1))\n",
    "        \n",
    "        # Convert to encoded and filter valid\n",
    "        valid_parents = []\n",
    "        for parent_raw in parent_raws:\n",
    "            px, py = parent_raw\n",
    "            if 0 <= px < self.size and 0 <= py < self.size:\n",
    "                encoded_parent = tuple(self.encode_raw_state(parent_raw))\n",
    "                valid_parents.append(encoded_parent)\n",
    "        \n",
    "        return valid_parents\n",
    "    \n",
    "    def get_valid_parent_mask(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[float]:\n",
    "        \"\"\"Get binary mask for valid parent states\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            list: mask of length sizeÂ² for valid parent states\n",
    "        \"\"\"\n",
    "        valid_parents = self.get_valid_parent_states(encoded_state)\n",
    "        mask = [0.0] * (self.size * self.size)\n",
    "        \n",
    "        for parent_encoded in valid_parents:\n",
    "            # Find the index of the 1.0 in the parent encoding\n",
    "            parent_list = list(parent_encoded)\n",
    "            idx = parent_list.index(1.0)\n",
    "            mask[idx] = 1.0\n",
    "        \n",
    "        return mask\n",
    "            \n",
    "    # ====================================================\n",
    "    # REWARD (work with encoded states)\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_reward(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> float:\n",
    "        \"\"\"Get reward for an encoded state using bounds checking\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            float: reward value\n",
    "        \"\"\"\n",
    "        # Convert to raw coordinates for bounds checking\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        \n",
    "        # Check if in goal region using bounds\n",
    "        if x >= self.goal_min_x and y >= self.goal_min_y:\n",
    "            return 1.0\n",
    "        return 0.0\n",
    "    \n",
    "    def is_terminal(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> bool:\n",
    "        \"\"\"Check if encoded state is terminal\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            bool: True if terminal\n",
    "        \"\"\"\n",
    "        return self.get_reward(encoded_state) > 0.0\n",
    "    \n",
    "    # ====================================================\n",
    "    # Batch processing\n",
    "    # ====================================================\n",
    "    \n",
    "    def compute_trajectory_rewards(self, trajectories: List[List[Union[List[float], Tuple[float, ...]]]]) -> Dict[Tuple[float, ...], float]:\n",
    "        \"\"\"Compute rewards for a batch of trajectories with encoded states\n",
    "        \n",
    "        Args:\n",
    "            trajectories: List of trajectories (each trajectory has encoded states)\n",
    "        Returns:\n",
    "            dict: mapping encoded states to rewards\n",
    "        \"\"\"\n",
    "        rewards = {}\n",
    "        for trajectory in trajectories:\n",
    "            if len(trajectory) > 0:\n",
    "                final_state = trajectory[-1]\n",
    "                if self.is_terminal(final_state):\n",
    "                    state_tuple = tuple(final_state) if not isinstance(final_state, tuple) else final_state\n",
    "                    rewards[state_tuple] = self.get_reward(final_state)\n",
    "        return rewards\n",
    "     \n",
    "    # ====================================================\n",
    "    # Visualization (converts to raw for plotting)\n",
    "    # ====================================================\n",
    "    \n",
    "    def visualize_grid(self, trajectories: Optional[List[List[Union[List[float], Tuple[float, ...]]]]] = None, title: str = \"HyperGrid\") -> None:\n",
    "        \"\"\"Visualize the grid (converts encoded trajectories to raw for plotting)\n",
    "        \n",
    "        Args:\n",
    "            trajectories: List of trajectories with encoded states\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        \n",
    "        # Create base grid\n",
    "        ax.set_xlim(-0.5, self.size - 0.5)\n",
    "        ax.set_ylim(-0.5, self.size - 0.5)\n",
    "        \n",
    "        # Add grid lines\n",
    "        for i in range(self.size + 1):\n",
    "            ax.axhline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "            ax.axvline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "        \n",
    "        # Mark start state (convert to raw for plotting)\n",
    "        start_raw = self.decode_state_to_raw(self.start_state)\n",
    "        ax.scatter(start_raw[0], start_raw[1], c='green', s=300, marker='s', label='Start')\n",
    "        \n",
    "        # Mark reward region using bounds checking\n",
    "        for x in range(max(0, self.goal_min_x), self.size):\n",
    "            for y in range(max(0, self.goal_min_y), self.size):\n",
    "                ax.add_patch(plt.Rectangle((x-0.4, y-0.4), 0.8, 0.8, \n",
    "                                         facecolor='red', alpha=0.3))\n",
    "        ax.scatter([], [], c='red', s=200, marker='s', alpha=0.3, label='Reward Region')\n",
    "        \n",
    "        # Plot trajectories if provided (convert to raw for plotting)\n",
    "        if trajectories:\n",
    "            colors = plt.cm.Set1(np.linspace(0, 1, len(trajectories)))\n",
    "            for i, (traj, color) in enumerate(zip(trajectories, colors)):\n",
    "                if len(traj) < 2:\n",
    "                    continue\n",
    "                    \n",
    "                # Convert encoded trajectory to raw coordinates\n",
    "                raw_traj = [self.decode_state_to_raw(encoded_state) for encoded_state in traj]\n",
    "                xs, ys = zip(*raw_traj)\n",
    "                \n",
    "                success = self.is_terminal(traj[-1])\n",
    "                linestyle = '-' if success else '--'\n",
    "                ax.plot(xs, ys, color=color, linewidth=2, linestyle=linestyle, \n",
    "                       label=f'Traj {i+1} ({\"âœ“\" if success else \"âœ—\"})')\n",
    "        \n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.set_aspect('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ====================================================\n",
    "# Trajectory Sampling (work with encoded states)\n",
    "# ====================================================\n",
    "class GridTrajectorySampler:\n",
    "    \"\"\"Samples trajectories with encoded states\"\"\"\n",
    "    def __init__(self, env: 'HyperGrid') -> None:\n",
    "        self.env = env\n",
    "    \n",
    "    def sample_trajectory(self, max_steps: int = 15) -> List[Tuple[float, ...]]:\n",
    "        \"\"\"Sample a single trajectory with encoded states\n",
    "        \n",
    "        Returns:\n",
    "            list: trajectory of encoded states\n",
    "        \"\"\"\n",
    "        trajectory = [self.env.start_state]\n",
    "        state = self.env.start_state\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if self.env.is_terminal(state):\n",
    "                break\n",
    "            \n",
    "            valid_actions = self.env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break\n",
    "            \n",
    "            # Random action selection\n",
    "            action = random.choice(valid_actions)\n",
    "            next_state = self.env.take_action(state, action)\n",
    "            trajectory.append(next_state)\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def sample_batch(self, batch_size: int, max_steps: int = 15) -> List[List[Tuple[float, ...]]]:\n",
    "        \"\"\"Sample a batch of trajectories with encoded states\"\"\"\n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            traj = self.sample_trajectory(max_steps)\n",
    "            trajectories.append(traj)\n",
    "        return trajectories\n",
    "\n",
    "# ====================================================\n",
    "# Policy-based sampling (work with encoded states)\n",
    "# ====================================================\n",
    "class PolicyTrajectorySampler:\n",
    "    \"\"\"Sample trajectories using a policy with encoded states\"\"\"\n",
    "    \n",
    "    def __init__(self, env: 'HyperGrid', model: Optional[object] = None, epsilon: float = 0.2) -> None:\n",
    "        self.env = env\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_trajectory_with_policy(self, max_steps: int = 15) -> List[Tuple[float, ...]]:\n",
    "        \"\"\"Sample trajectory using model policy with encoded states\"\"\"\n",
    "        import torch\n",
    "        import torch.nn.functional as F\n",
    "        \n",
    "        trajectory = [self.env.start_state]\n",
    "        state = self.env.start_state\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if self.env.is_terminal(state):\n",
    "                break\n",
    "            \n",
    "            valid_actions = self.env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break\n",
    "            \n",
    "            if self.model is None or random.random() < self.epsilon:\n",
    "                # Random exploration\n",
    "                action = random.choice(valid_actions)\n",
    "            else:\n",
    "                # Use policy - state is already encoded!\n",
    "                state_tensor = torch.tensor(list(state), dtype=torch.float)\n",
    "                P_F_logits, _ = self.model(state_tensor)\n",
    "                \n",
    "                # Mask invalid actions\n",
    "                action_mask = torch.tensor(self.env.get_valid_action_mask(state))\n",
    "                masked_logits = P_F_logits.where(action_mask.bool(), torch.tensor(-100.0))\n",
    "                \n",
    "                # Sample from policy\n",
    "                probs = F.softmax(masked_logits, dim=0)\n",
    "                action_idx = torch.multinomial(probs, 1).item()\n",
    "                action = self.env.index_to_action(action_idx)\n",
    "            \n",
    "            next_state = self.env.take_action(state, action)\n",
    "            trajectory.append(next_state)\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def sample_batch_with_policy(self, batch_size: int, max_steps: int = 15) -> List[List[Tuple[float, ...]]]:\n",
    "        \"\"\"Sample batch of trajectories with encoded states\"\"\"\n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            traj = self.sample_trajectory_with_policy(max_steps)\n",
    "            trajectories.append(traj)\n",
    "        return trajectories\n",
    "\n",
    "# ====================================================\n",
    "# Grid world configurations\n",
    "# ====================================================\n",
    "def HyperGrid_8x8() -> 'HyperGrid':\n",
    "    return HyperGrid()\n",
    "\n",
    "# ====================================================\n",
    "# Test the encoded-only environment\n",
    "# ====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸ§ª Testing Encoded-Only HyperGrid\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    env = HyperGrid(size=4, reward_region_size=1)\n",
    "    \n",
    "    # Test raw to encoded conversion\n",
    "    print(\"ðŸ” Testing state encoding utilities:\")\n",
    "    raw_state = (1, 2)\n",
    "    encoded_state = env.encode_raw_state(raw_state)\n",
    "    decoded_state = env.decode_state_to_raw(encoded_state)\n",
    "    print(f\"  Raw state: {raw_state}\")\n",
    "    print(f\"  Encoded: {encoded_state[:10]}... (length: {len(encoded_state)})\")\n",
    "    print(f\"  Decoded back: {decoded_state}\")\n",
    "    \n",
    "    # Test environment methods with encoded states\n",
    "    print(f\"\\nðŸ” Testing environment with encoded states:\")\n",
    "    print(f\"  Start state (encoded): {env.start_state[:10]}...\")\n",
    "    print(f\"  Start state (raw): {env.decode_state_to_raw(env.start_state)}\")\n",
    "    \n",
    "    valid_actions = env.get_valid_actions(env.start_state)\n",
    "    print(f\"  Valid actions from start: {valid_actions}\")\n",
    "    \n",
    "    action_mask = env.get_valid_action_mask(env.start_state)\n",
    "    print(f\"  Action mask: {action_mask}\")\n",
    "    \n",
    "    # Test taking an action\n",
    "    if valid_actions:\n",
    "        next_state = env.take_action(env.start_state, valid_actions[0])\n",
    "        print(f\"  After action '{valid_actions[0]}': {env.decode_state_to_raw(next_state)}\")\n",
    "    \n",
    "    # Test trajectory sampling\n",
    "    print(f\"\\nðŸ” Testing trajectory sampling:\")\n",
    "    sampler = GridTrajectorySampler(env)\n",
    "    trajectories = sampler.sample_batch(3, max_steps=8)\n",
    "    \n",
    "    for i, traj in enumerate(trajectories):\n",
    "        # Convert to raw for readable output\n",
    "        raw_traj = [env.decode_state_to_raw(state) for state in traj]\n",
    "        success = env.is_terminal(traj[-1])\n",
    "        reward = env.get_reward(traj[-1])\n",
    "        print(f\"  Traj {i+1}: {raw_traj} -> success: {success}, reward: {reward}\")\n",
    "    \n",
    "    print(f\"\\nâœ… All encoded-state functions working!\")\n",
    "    print(f\"Environment now consistently uses encoded states throughout.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3851865b-3981-43e9-b8b4-b341889b2df4",
   "metadata": {},
   "source": [
    "### v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e562ea0-0a1d-47de-b9fb-5006b11d5f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª Testing Encoded-Only HyperGrid\n",
      "==================================================\n",
      "Grid size: 4x4\n",
      "Goal region: x >= 3, y >= 3\n",
      "State encoding dimension: 16\n",
      "ðŸ” Testing state encoding utilities:\n",
      "  Raw state: (1, 2)\n",
      "  Encoded: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]... (length: 16)\n",
      "  Decoded back: (1, 2)\n",
      "\n",
      "ðŸ” Testing environment with encoded states:\n",
      "  Start state (encoded): (1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0)...\n",
      "  Start state (raw): (0, 0)\n",
      "  Valid actions from start: ['right', 'up']\n",
      "  Action mask: [1.0, 1.0, 0.0, 0.0]\n",
      "  After action 'right': (1, 0)\n",
      "\n",
      "ðŸ” Testing trajectory sampling:\n",
      "  Traj 1: [(0, 0), (0, 1), (1, 1), (0, 1), (0, 0), (0, 1), (0, 0), (1, 0), (2, 0)] -> success: False, reward: 0.0\n",
      "  Traj 2: [(0, 0), (0, 1), (1, 1), (1, 0), (1, 1), (1, 2), (1, 3), (1, 2), (2, 2)] -> success: False, reward: 0.0\n",
      "  Traj 3: [(0, 0), (1, 0), (1, 1), (0, 1), (0, 0), (0, 1), (0, 0), (0, 1), (1, 1)] -> success: False, reward: 0.0\n",
      "\n",
      "âœ… All encoded-state functions working!\n",
      "Environment now consistently uses encoded states throughout.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Set, Dict, Union, Optional\n",
    "\n",
    "# ====================================================\n",
    "# Define HyperGrid Environment (Encoded State Only)\n",
    "# ====================================================\n",
    "class HyperGrid:\n",
    "    \"\"\"8x8 HyperGrid environment for GFlowNet - All methods use encoded states\"\"\"\n",
    "    \n",
    "    def __init__(self, size: int = 8, reward_region_size: int = 2) -> None:\n",
    "        self.size = size\n",
    "        self.reward_region_size = reward_region_size\n",
    "        \n",
    "        # Define goal region bounds (computed, not stored)\n",
    "        self.goal_min_x = size - reward_region_size\n",
    "        self.goal_min_y = size - reward_region_size\n",
    "        \n",
    "        # Start state as encoded\n",
    "        self.start_state = tuple(self.encode_raw_state((0, 0)))\n",
    "        \n",
    "        print(f\"Grid size: {size}x{size}\")\n",
    "        print(f\"Goal region: x >= {self.goal_min_x}, y >= {self.goal_min_y}\")\n",
    "        print(f\"State encoding dimension: {self.get_state_dim()}\")\n",
    "    \n",
    "    # ====================================================\n",
    "    # State encoding utilities\n",
    "    # ====================================================\n",
    "    \n",
    "    def encode_raw_state(self, raw_state: Tuple[int, int]) -> List[float]:\n",
    "        \"\"\"Convert raw (x,y) state to encoded one-hot vector\n",
    "        \n",
    "        Args:\n",
    "            raw_state: (x, y) tuple\n",
    "        Returns:\n",
    "            list: one-hot encoded vector of length sizeÂ²\n",
    "        \"\"\"\n",
    "        x, y = raw_state\n",
    "        idx = y * self.size + x\n",
    "        encoding = [0.0] * (self.size * self.size)\n",
    "        encoding[idx] = 1.0\n",
    "        return encoding\n",
    "    \n",
    "    def decode_state_to_raw(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> Tuple[int, int]:\n",
    "        \"\"\"Convert encoded state back to raw (x,y) tuple\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot vector or tuple\n",
    "        Returns:\n",
    "            tuple: (x, y) coordinates\n",
    "        \"\"\"\n",
    "        if isinstance(encoded_state, tuple):\n",
    "            encoded_state = list(encoded_state)\n",
    "        \n",
    "        idx = encoded_state.index(1.0)\n",
    "        x = idx % self.size\n",
    "        y = idx // self.size\n",
    "        return (x, y)\n",
    "    \n",
    "    def get_state_dim(self) -> int:\n",
    "        \"\"\"Get the dimension of encoded states\"\"\"\n",
    "        return self.size * self.size\n",
    "    \n",
    "    # ====================================================\n",
    "    # Actions (work with encoded states)\n",
    "    # ====================================================    \n",
    "    \n",
    "    def get_valid_actions(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[str]:\n",
    "        \"\"\"Get valid actions from an encoded state\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            list: valid action strings\n",
    "        \"\"\"\n",
    "        # Convert to raw to check boundaries\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        actions = []\n",
    "        \n",
    "        if x + 1 < self.size:\n",
    "            actions.append('right')\n",
    "        if y + 1 < self.size:\n",
    "            actions.append('up')\n",
    "        if x - 1 >= 0:\n",
    "            actions.append('left')\n",
    "        if y - 1 >= 0:\n",
    "            actions.append('down')\n",
    "            \n",
    "        return actions\n",
    "    \n",
    "    def take_action(self, encoded_state: Union[List[float], Tuple[float, ...]], action: str) -> Tuple[float, ...]:\n",
    "        \"\"\"Take action from encoded state to get next encoded state\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "            action: action string\n",
    "        Returns:\n",
    "            tuple: next encoded state\n",
    "        \"\"\"\n",
    "        # Convert to raw, take action, convert back\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        \n",
    "        if action == 'right':\n",
    "            new_raw = (x + 1, y)\n",
    "        elif action == 'up':\n",
    "            new_raw = (x, y + 1)\n",
    "        elif action == 'left':\n",
    "            new_raw = (x - 1, y)\n",
    "        elif action == 'down':\n",
    "            new_raw = (x, y - 1)\n",
    "        else:\n",
    "            new_raw = (x, y)\n",
    "        \n",
    "        return tuple(self.encode_raw_state(new_raw))\n",
    "    \n",
    "    # ====================================================\n",
    "    # Action encoding\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_action_list(self) -> List[str]:\n",
    "        \"\"\"Get list of all possible actions\"\"\"\n",
    "        return ['right', 'up', 'left', 'down']\n",
    "    \n",
    "    def action_to_index(self, action: str) -> int:\n",
    "        \"\"\"Convert action string to index\"\"\"\n",
    "        action_map = {'right': 0, 'up': 1, 'left': 2, 'down': 3}\n",
    "        return action_map.get(action, -1)\n",
    "    \n",
    "    def index_to_action(self, index: int) -> Optional[str]:\n",
    "        \"\"\"Convert action index to string\"\"\"\n",
    "        actions = ['right', 'up', 'left', 'down']\n",
    "        return actions[index] if 0 <= index < len(actions) else None\n",
    "    \n",
    "    def get_action_dim(self) -> int:\n",
    "        \"\"\"Get number of possible actions\"\"\"\n",
    "        return 4\n",
    "    \n",
    "    # ====================================================\n",
    "    # Action masking (work with encoded states)\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_valid_action_mask(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[float]:\n",
    "        \"\"\"Get binary mask for valid actions\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            list: [right, up, left, down] with 1.0 for valid, 0.0 for invalid\n",
    "        \"\"\"\n",
    "        valid_actions = self.get_valid_actions(encoded_state)\n",
    "        mask = [0.0] * 4\n",
    "        for action in valid_actions:\n",
    "            idx = self.action_to_index(action)\n",
    "            if idx >= 0:\n",
    "                mask[idx] = 1.0\n",
    "        return mask\n",
    "    \n",
    "    def get_valid_parent_states(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[Tuple[float, ...]]:\n",
    "        \"\"\"Get all encoded states that can reach this state in one step\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            list: List of encoded states that can reach this state\n",
    "        \"\"\"\n",
    "        # Convert to raw to find parents\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        parent_raws = []\n",
    "        \n",
    "        # Check each direction\n",
    "        if x > 0:  # Could have come from left\n",
    "            parent_raws.append((x - 1, y))\n",
    "        if x < self.size - 1:  # Could have come from right\n",
    "            parent_raws.append((x + 1, y))\n",
    "        if y > 0:  # Could have come from below\n",
    "            parent_raws.append((x, y - 1))\n",
    "        if y < self.size - 1:  # Could have come from above\n",
    "            parent_raws.append((x, y + 1))\n",
    "        \n",
    "        # Convert to encoded and filter valid\n",
    "        valid_parents = []\n",
    "        for parent_raw in parent_raws:\n",
    "            px, py = parent_raw\n",
    "            if 0 <= px < self.size and 0 <= py < self.size:\n",
    "                encoded_parent = tuple(self.encode_raw_state(parent_raw))\n",
    "                valid_parents.append(encoded_parent)\n",
    "        \n",
    "        return valid_parents\n",
    "    \n",
    "    def get_valid_parent_mask(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[float]:\n",
    "        \"\"\"Get binary mask for valid parent states\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            list: mask of length sizeÂ² for valid parent states\n",
    "        \"\"\"\n",
    "        valid_parents = self.get_valid_parent_states(encoded_state)\n",
    "        mask = [0.0] * (self.size * self.size)\n",
    "        \n",
    "        for parent_encoded in valid_parents:\n",
    "            # Find the index of the 1.0 in the parent encoding\n",
    "            parent_list = list(parent_encoded)\n",
    "            idx = parent_list.index(1.0)\n",
    "            mask[idx] = 1.0\n",
    "        \n",
    "        return mask\n",
    "            \n",
    "    # ====================================================\n",
    "    # REWARD (work with encoded states)\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_reward(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> float:\n",
    "        \"\"\"Get reward for an encoded state using bounds checking\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            float: reward value\n",
    "        \"\"\"\n",
    "        # Convert to raw coordinates for bounds checking\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        \n",
    "        # Check if in goal region using bounds\n",
    "        if x >= self.goal_min_x and y >= self.goal_min_y:\n",
    "            return 1.0\n",
    "        return 0.0\n",
    "    \n",
    "    def is_terminal(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> bool:\n",
    "        \"\"\"Check if encoded state is terminal\n",
    "        \n",
    "        Args:\n",
    "            encoded_state: one-hot encoded state\n",
    "        Returns:\n",
    "            bool: True if terminal\n",
    "        \"\"\"\n",
    "        return self.get_reward(encoded_state) > 0.0\n",
    "    \n",
    "    # ====================================================\n",
    "    # Batch processing\n",
    "    # ====================================================\n",
    "    \n",
    "    def compute_trajectory_rewards(self, trajectories: List[List[Union[List[float], Tuple[float, ...]]]]) -> Dict[Tuple[float, ...], float]:\n",
    "        \"\"\"Compute rewards for a batch of trajectories with encoded states\n",
    "        \n",
    "        Args:\n",
    "            trajectories: List of trajectories (each trajectory has encoded states)\n",
    "        Returns:\n",
    "            dict: mapping encoded states to rewards\n",
    "        \"\"\"\n",
    "        rewards = {}\n",
    "        for trajectory in trajectories:\n",
    "            if len(trajectory) > 0:\n",
    "                final_state = trajectory[-1]\n",
    "                if self.is_terminal(final_state):\n",
    "                    state_tuple = tuple(final_state) if not isinstance(final_state, tuple) else final_state\n",
    "                    rewards[state_tuple] = self.get_reward(final_state)\n",
    "        return rewards\n",
    "     \n",
    "    # ====================================================\n",
    "    # Visualization (converts to raw for plotting)\n",
    "    # ====================================================\n",
    "    \n",
    "    def visualize_grid(self, trajectories: Optional[List[List[Union[List[float], Tuple[float, ...]]]]] = None, title: str = \"HyperGrid\") -> None:\n",
    "        \"\"\"Visualize the grid (converts encoded trajectories to raw for plotting)\n",
    "        \n",
    "        Args:\n",
    "            trajectories: List of trajectories with encoded states\n",
    "        \"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        \n",
    "        # Create base grid\n",
    "        ax.set_xlim(-0.5, self.size - 0.5)\n",
    "        ax.set_ylim(-0.5, self.size - 0.5)\n",
    "        \n",
    "        # Add grid lines\n",
    "        for i in range(self.size + 1):\n",
    "            ax.axhline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "            ax.axvline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "        \n",
    "        # Mark start state (convert to raw for plotting)\n",
    "        start_raw = self.decode_state_to_raw(self.start_state)\n",
    "        ax.scatter(start_raw[0], start_raw[1], c='green', s=300, marker='s', label='Start')\n",
    "        \n",
    "        # Mark reward region using bounds checking\n",
    "        for x in range(max(0, self.goal_min_x), self.size):\n",
    "            for y in range(max(0, self.goal_min_y), self.size):\n",
    "                ax.add_patch(plt.Rectangle((x-0.4, y-0.4), 0.8, 0.8, \n",
    "                                         facecolor='red', alpha=0.3))\n",
    "        ax.scatter([], [], c='red', s=200, marker='s', alpha=0.3, label='Reward Region')\n",
    "        \n",
    "        # Plot trajectories if provided (convert to raw for plotting)\n",
    "        if trajectories:\n",
    "            colors = plt.cm.Set1(np.linspace(0, 1, len(trajectories)))\n",
    "            for i, (traj, color) in enumerate(zip(trajectories, colors)):\n",
    "                if len(traj) < 2:\n",
    "                    continue\n",
    "                    \n",
    "                # Convert encoded trajectory to raw coordinates\n",
    "                raw_traj = [self.decode_state_to_raw(encoded_state) for encoded_state in traj]\n",
    "                xs, ys = zip(*raw_traj)\n",
    "                \n",
    "                success = self.is_terminal(traj[-1])\n",
    "                linestyle = '-' if success else '--'\n",
    "                ax.plot(xs, ys, color=color, linewidth=2, linestyle=linestyle, \n",
    "                       label=f'Traj {i+1} ({\"âœ“\" if success else \"âœ—\"})')\n",
    "        \n",
    "        ax.set_xlabel('X Position')\n",
    "        ax.set_ylabel('Y Position')\n",
    "        ax.set_title(title)\n",
    "        ax.legend()\n",
    "        ax.set_aspect('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ====================================================\n",
    "# Trajectory Sampling (work with encoded states)\n",
    "# ====================================================\n",
    "class GridTrajectorySampler:\n",
    "    \"\"\"Samples trajectories with encoded states\"\"\"\n",
    "    def __init__(self, env: 'HyperGrid') -> None:\n",
    "        self.env = env\n",
    "    \n",
    "    def sample_trajectory(self, max_steps: int = 15) -> List[Tuple[float, ...]]:\n",
    "        \"\"\"Sample a single trajectory with encoded states\n",
    "        \n",
    "        Returns:\n",
    "            list: trajectory of encoded states\n",
    "        \"\"\"\n",
    "        trajectory = [self.env.start_state]\n",
    "        state = self.env.start_state\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if self.env.is_terminal(state):\n",
    "                break\n",
    "            \n",
    "            valid_actions = self.env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break\n",
    "            \n",
    "            # Random action selection\n",
    "            action = random.choice(valid_actions)\n",
    "            next_state = self.env.take_action(state, action)\n",
    "            trajectory.append(next_state)\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def sample_batch(self, batch_size: int, max_steps: int = 15) -> List[List[Tuple[float, ...]]]:\n",
    "        \"\"\"Sample a batch of trajectories with encoded states\"\"\"\n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            traj = self.sample_trajectory(max_steps)\n",
    "            trajectories.append(traj)\n",
    "        return trajectories\n",
    "\n",
    "# ====================================================\n",
    "# Policy-based sampling (work with encoded states)\n",
    "# ====================================================\n",
    "class PolicyTrajectorySampler:\n",
    "    \"\"\"Sample trajectories using a policy with encoded states\"\"\"\n",
    "    \n",
    "    def __init__(self, env: 'HyperGrid', model: Optional[object] = None, epsilon: float = 0.2) -> None:\n",
    "        self.env = env\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_trajectory_with_policy(self, max_steps: int = 15) -> List[Tuple[float, ...]]:\n",
    "        \"\"\"Sample trajectory using model policy with encoded states\"\"\"\n",
    "        import torch\n",
    "        import torch.nn.functional as F\n",
    "        \n",
    "        trajectory = [self.env.start_state]\n",
    "        state = self.env.start_state\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if self.env.is_terminal(state):\n",
    "                break\n",
    "            \n",
    "            valid_actions = self.env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break\n",
    "            \n",
    "            if self.model is None or random.random() < self.epsilon:\n",
    "                # Random exploration\n",
    "                action = random.choice(valid_actions)\n",
    "            else:\n",
    "                # Use policy - state is already encoded!\n",
    "                state_tensor = torch.tensor(list(state), dtype=torch.float)\n",
    "                P_F_logits, _ = self.model(state_tensor)\n",
    "                \n",
    "                # Mask invalid actions\n",
    "                action_mask = torch.tensor(self.env.get_valid_action_mask(state))\n",
    "                masked_logits = P_F_logits.where(action_mask.bool(), torch.tensor(-100.0))\n",
    "                \n",
    "                # Sample from policy\n",
    "                probs = F.softmax(masked_logits, dim=0)\n",
    "                action_idx = torch.multinomial(probs, 1).item()\n",
    "                action = self.env.index_to_action(action_idx)\n",
    "            \n",
    "            next_state = self.env.take_action(state, action)\n",
    "            trajectory.append(next_state)\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def sample_batch_with_policy(self, batch_size: int, max_steps: int = 15) -> List[List[Tuple[float, ...]]]:\n",
    "        \"\"\"Sample batch of trajectories with encoded states\"\"\"\n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            traj = self.sample_trajectory_with_policy(max_steps)\n",
    "            trajectories.append(traj)\n",
    "        return trajectories\n",
    "\n",
    "# ====================================================\n",
    "# Grid world configurations\n",
    "# ====================================================\n",
    "def HyperGrid_8x8() -> 'HyperGrid':\n",
    "    return HyperGrid()\n",
    "\n",
    "# ====================================================\n",
    "# Test the encoded-only environment\n",
    "# ====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸ§ª Testing Encoded-Only HyperGrid\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    env = HyperGrid(size=4, reward_region_size=1)\n",
    "    \n",
    "    # Test raw to encoded conversion\n",
    "    print(\"ðŸ” Testing state encoding utilities:\")\n",
    "    raw_state = (1, 2)\n",
    "    encoded_state = env.encode_raw_state(raw_state)\n",
    "    decoded_state = env.decode_state_to_raw(encoded_state)\n",
    "    print(f\"  Raw state: {raw_state}\")\n",
    "    print(f\"  Encoded: {encoded_state[:10]}... (length: {len(encoded_state)})\")\n",
    "    print(f\"  Decoded back: {decoded_state}\")\n",
    "    \n",
    "    # Test environment methods with encoded states\n",
    "    print(f\"\\nðŸ” Testing environment with encoded states:\")\n",
    "    print(f\"  Start state (encoded): {env.start_state[:10]}...\")\n",
    "    print(f\"  Start state (raw): {env.decode_state_to_raw(env.start_state)}\")\n",
    "    \n",
    "    valid_actions = env.get_valid_actions(env.start_state)\n",
    "    print(f\"  Valid actions from start: {valid_actions}\")\n",
    "    \n",
    "    action_mask = env.get_valid_action_mask(env.start_state)\n",
    "    print(f\"  Action mask: {action_mask}\")\n",
    "    \n",
    "    # Test taking an action\n",
    "    if valid_actions:\n",
    "        next_state = env.take_action(env.start_state, valid_actions[0])\n",
    "        print(f\"  After action '{valid_actions[0]}': {env.decode_state_to_raw(next_state)}\")\n",
    "    \n",
    "    # Test trajectory sampling\n",
    "    print(f\"\\nðŸ” Testing trajectory sampling:\")\n",
    "    sampler = GridTrajectorySampler(env)\n",
    "    trajectories = sampler.sample_batch(3, max_steps=8)\n",
    "    \n",
    "    for i, traj in enumerate(trajectories):\n",
    "        # Convert to raw for readable output\n",
    "        raw_traj = [env.decode_state_to_raw(state) for state in traj]\n",
    "        success = env.is_terminal(traj[-1])\n",
    "        reward = env.get_reward(traj[-1])\n",
    "        print(f\"  Traj {i+1}: {raw_traj} -> success: {success}, reward: {reward}\")\n",
    "    \n",
    "    print(f\"\\nâœ… All encoded-state functions working!\")\n",
    "    print(f\"Environment now consistently uses encoded states throughout.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27753f77-ccb7-48e7-bf66-0547b562b888",
   "metadata": {},
   "source": [
    "## FaceComposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12caa698-d4f0-4c1a-9a21-009696addafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# ====================================================\n",
    "# Define Face Composition Environment\n",
    "# ====================================================\n",
    "\n",
    "class FaceComposition:\n",
    "    \"\"\"Face composition environment for GFlowNet\n",
    "    \n",
    "    State: [hair, eyes, mouth] where each is 0 or 1\n",
    "    Actions: 'add_hair', 'add_eyes', 'add_mouth'\n",
    "    Goal: Build complete faces, get rewards based on beauty\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Face has 3 parts: hair, eyes, mouth\n",
    "        self.num_parts = 3\n",
    "        self.part_names = ['hair', 'eyes', 'mouth']\n",
    "        \n",
    "        # Start with empty face\n",
    "        self.start_state = (0, 0, 0)\n",
    "        \n",
    "        # Define reward structure\n",
    "        self.reward_map = {\n",
    "            (1, 1, 1): 10.0,  # Perfect face\n",
    "            (1, 1, 0): 5.0,   # Good hair + eyes\n",
    "            (1, 0, 1): 3.0,   # Good hair + mouth\n",
    "            (0, 1, 1): 1.0,   # Good eyes + mouth\n",
    "            (0, 0, 1): 0.1,   # Just mouth\n",
    "            (0, 1, 0): 0.1,   # Just eyes\n",
    "            (1, 0, 0): 0.1,   # Just hair\n",
    "        }\n",
    "        \n",
    "        print(f\"Face parts: {self.part_names}\")\n",
    "        print(f\"Start state: {self.start_state}\")\n",
    "        print(f\"Reward structure: {self.reward_map}\")\n",
    "        \n",
    "    # ====================================================\n",
    "    # Actions\n",
    "    # ====================================================    \n",
    "    \n",
    "    def get_valid_actions(self, state):\n",
    "        \"\"\"Get valid actions from a state\"\"\"\n",
    "        hair, eyes, mouth = state\n",
    "        actions = []\n",
    "        \n",
    "        if hair == 0:\n",
    "            actions.append('add_hair')\n",
    "        if eyes == 0:\n",
    "            actions.append('add_eyes')\n",
    "        if mouth == 0:\n",
    "            actions.append('add_mouth')\n",
    "            \n",
    "        return actions\n",
    "    \n",
    "    def take_action(self, state, action):\n",
    "        \"\"\"Take action from state to get next state\"\"\"\n",
    "        hair, eyes, mouth = state\n",
    "        \n",
    "        if action == 'add_hair':\n",
    "            return (1, eyes, mouth)\n",
    "        elif action == 'add_eyes':\n",
    "            return (hair, 1, mouth)\n",
    "        elif action == 'add_mouth':\n",
    "            return (hair, eyes, 1)\n",
    "        else:\n",
    "            return state\n",
    "            \n",
    "    # ====================================================\n",
    "    # REWARD\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_reward(self, state):\n",
    "        \"\"\"Reward for complete faces\"\"\"\n",
    "        return self.reward_map.get(state, 0.0)\n",
    "    \n",
    "    def is_terminal(self, state):\n",
    "        \"\"\"Face is terminal when all parts are chosen\"\"\"\n",
    "        return sum(state) == 3\n",
    "    \n",
    "    # ====================================================\n",
    "    # Visualization\n",
    "    # ====================================================\n",
    "    \n",
    "    def visualize_faces(self, trajectories=None, title=\"Face Composition\"):\n",
    "        \"\"\"Visualize face trajectories and final results\"\"\"\n",
    "        if not trajectories:\n",
    "            return\n",
    "        \n",
    "        # Count final faces\n",
    "        face_counts = {}\n",
    "        for traj in trajectories:\n",
    "            if len(traj) > 0:\n",
    "                final_face = traj[-1]\n",
    "                if self.is_terminal(final_face):\n",
    "                    face_counts[final_face] = face_counts.get(final_face, 0) + 1\n",
    "        \n",
    "        if not face_counts:\n",
    "            print(\"No complete faces found in trajectories\")\n",
    "            return\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Left plot: Face distribution\n",
    "        faces = list(face_counts.keys())\n",
    "        counts = list(face_counts.values())\n",
    "        rewards = [self.get_reward(face) for face in faces]\n",
    "        \n",
    "        # Sort by reward for better visualization\n",
    "        sorted_data = sorted(zip(faces, counts, rewards), key=lambda x: x[2], reverse=True)\n",
    "        faces, counts, rewards = zip(*sorted_data)\n",
    "        \n",
    "        face_labels = [f\"{face}\\nR={reward}\" for face, reward in zip(faces, rewards)]\n",
    "        bars = ax1.bar(range(len(faces)), counts, color=plt.cm.viridis(np.array(rewards)/max(rewards)))\n",
    "        \n",
    "        ax1.set_xlabel('Face Type')\n",
    "        ax1.set_ylabel('Count')\n",
    "        ax1.set_title('Face Distribution')\n",
    "        ax1.set_xticks(range(len(faces)))\n",
    "        ax1.set_xticklabels(face_labels, rotation=45)\n",
    "        \n",
    "        # Add count labels on bars\n",
    "        for bar, count in zip(bars, counts):\n",
    "            height = bar.get_height()\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "                    f'{count}', ha='center', va='bottom')\n",
    "        \n",
    "        # Right plot: Reward vs Probability\n",
    "        total_faces = sum(counts)\n",
    "        probs = [c/total_faces for c in counts]\n",
    "        \n",
    "        ax2.scatter(rewards, probs, s=100, alpha=0.7)\n",
    "        for i, face in enumerate(faces):\n",
    "            ax2.annotate(f'{face}', (rewards[i], probs[i]), \n",
    "                        xytext=(5, 5), textcoords='offset points')\n",
    "        \n",
    "        ax2.set_xlabel('Reward')\n",
    "        ax2.set_ylabel('Probability')\n",
    "        ax2.set_title('Reward vs Sampling Probability')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary\n",
    "        print(f\"\\nFace Summary ({total_faces} complete faces):\")\n",
    "        for face, count, reward in zip(faces, counts, rewards):\n",
    "            prob = count/total_faces\n",
    "            print(f\"  {face} -> {count} ({prob:.1%}), reward={reward}\")\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Face Trajectory Sampling\n",
    "# ====================================================\n",
    "\n",
    "class FaceTrajectorySampler:\n",
    "    \"\"\"Samples random trajectories using face environment\"\"\"\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "    \n",
    "    def sample_trajectory(self, max_steps=3):\n",
    "        \"\"\"Sample a single random trajectory\"\"\"\n",
    "        trajectory = [self.env.start_state]\n",
    "        state = self.env.start_state\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if self.env.is_terminal(state):\n",
    "                break\n",
    "            \n",
    "            valid_actions = self.env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break\n",
    "            \n",
    "            # Random action selection\n",
    "            action = random.choice(valid_actions)\n",
    "            next_state = self.env.take_action(state, action)\n",
    "            trajectory.append(next_state)\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def sample_batch(self, batch_size, max_steps=3):\n",
    "        \"\"\"Sample a batch of trajectories\"\"\"\n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            traj = self.sample_trajectory(max_steps)\n",
    "            trajectories.append(traj)\n",
    "        return trajectories\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Face Environment Configurations\n",
    "# ====================================================\n",
    "\n",
    "def FaceComposition_3Parts():\n",
    "    \"\"\"Standard 3-part face composition\"\"\"\n",
    "    return FaceComposition()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca375b2e-d0f2-4584-a037-7e91c4943282",
   "metadata": {},
   "source": [
    "### example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "960b7ec5-e103-4630-9879-53bc68bf535c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ­ Testing Face Composition Environment\n",
      "==================================================\n",
      "Face parts: ['hair', 'eyes', 'mouth']\n",
      "Start state: (0, 0, 0)\n",
      "Reward structure: {(1, 1, 1): 10.0, (1, 1, 0): 5.0, (1, 0, 1): 3.0, (0, 1, 1): 1.0, (0, 0, 1): 0.1, (0, 1, 0): 0.1, (1, 0, 0): 0.1}\n",
      "\n",
      "Start state: (0, 0, 0)\n",
      "Valid actions from start: ['add_hair', 'add_eyes', 'add_mouth']\n",
      "\n",
      "Testing actions:\n",
      "  Current state: (0, 0, 0)\n",
      "  After add_hair: (1, 0, 0)\n",
      "  After add_eyes: (1, 1, 0)\n",
      "  After add_mouth: (1, 1, 1)\n",
      "  Is terminal: True\n",
      "  Reward: 10.0\n",
      "\n",
      "Sampling 10 random trajectories:\n",
      "  Traj 1: [(0, 0, 0), (0, 1, 0), (0, 1, 1), (1, 1, 1)] -> R=10.0 âœ“\n",
      "  Traj 2: [(0, 0, 0), (0, 1, 0), (0, 1, 1), (1, 1, 1)] -> R=10.0 âœ“\n",
      "  Traj 3: [(0, 0, 0), (0, 1, 0), (1, 1, 0), (1, 1, 1)] -> R=10.0 âœ“\n",
      "  Traj 4: [(0, 0, 0), (0, 1, 0), (0, 1, 1), (1, 1, 1)] -> R=10.0 âœ“\n",
      "  Traj 5: [(0, 0, 0), (0, 0, 1), (1, 0, 1), (1, 1, 1)] -> R=10.0 âœ“\n",
      "  Traj 6: [(0, 0, 0), (0, 1, 0), (1, 1, 0), (1, 1, 1)] -> R=10.0 âœ“\n",
      "  Traj 7: [(0, 0, 0), (0, 1, 0), (0, 1, 1), (1, 1, 1)] -> R=10.0 âœ“\n",
      "  Traj 8: [(0, 0, 0), (1, 0, 0), (1, 1, 0), (1, 1, 1)] -> R=10.0 âœ“\n",
      "  Traj 9: [(0, 0, 0), (0, 1, 0), (0, 1, 1), (1, 1, 1)] -> R=10.0 âœ“\n",
      "  Traj 10: [(0, 0, 0), (0, 0, 1), (0, 1, 1), (1, 1, 1)] -> R=10.0 âœ“\n",
      "\n",
      "Testing with 100 random trajectories...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Face Summary (100 complete faces):\n",
      "  (1, 1, 1) -> 100 (100.0%), reward=10.0\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# Test the environment\n",
    "# ====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸŽ­ Testing Face Composition Environment\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create environment\n",
    "    env = FaceComposition()\n",
    "    sampler = FaceTrajectorySampler(env)\n",
    "    \n",
    "    print(f\"\\nStart state: {env.start_state}\")\n",
    "    print(f\"Valid actions from start: {env.get_valid_actions(env.start_state)}\")\n",
    "    \n",
    "    # Test action taking\n",
    "    state = env.start_state\n",
    "    print(f\"\\nTesting actions:\")\n",
    "    print(f\"  Current state: {state}\")\n",
    "    \n",
    "    action = 'add_hair'\n",
    "    next_state = env.take_action(state, action)\n",
    "    print(f\"  After {action}: {next_state}\")\n",
    "    \n",
    "    action = 'add_eyes'\n",
    "    final_state = env.take_action(next_state, action)\n",
    "    print(f\"  After {action}: {final_state}\")\n",
    "    \n",
    "    action = 'add_mouth'\n",
    "    complete_state = env.take_action(final_state, action)\n",
    "    print(f\"  After {action}: {complete_state}\")\n",
    "    \n",
    "    print(f\"  Is terminal: {env.is_terminal(complete_state)}\")\n",
    "    print(f\"  Reward: {env.get_reward(complete_state)}\")\n",
    "    \n",
    "    # Sample some trajectories\n",
    "    print(f\"\\nSampling 10 random trajectories:\")\n",
    "    trajectories = sampler.sample_batch(10)\n",
    "    \n",
    "    for i, traj in enumerate(trajectories):\n",
    "        reward = env.get_reward(traj[-1]) if env.is_terminal(traj[-1]) else 0\n",
    "        terminal = \"âœ“\" if env.is_terminal(traj[-1]) else \"âœ—\"\n",
    "        print(f\"  Traj {i+1}: {traj} -> R={reward} {terminal}\")\n",
    "    \n",
    "    # Visualize results\n",
    "    print(f\"\\nTesting with 100 random trajectories...\")\n",
    "    test_trajectories = sampler.sample_batch(100)\n",
    "    env.visualize_faces(test_trajectories, \"Random Face Sampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2162a2a9-4667-4f08-8a5c-ce8e7be8a152",
   "metadata": {},
   "source": [
    "---\n",
    "# MLflow experiments\n",
    "\n",
    "## Phisics based flow model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5c2766bc-fc6f-45ee-9672-9e29630462d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Reward states: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Starting training: lr=0.001, hidden_dim=128\n",
      "Step 0: Loss=6.2808, Success=0.00%, Avg Length=21.0, Total Successful Found: 0\n",
      "Step 10: Loss=8.0818, Success=0.00%, Avg Length=21.0, Total Successful Found: 0\n",
      "Step 20: Loss=5.5081, Success=0.00%, Avg Length=21.0, Total Successful Found: 0\n",
      "Step 30: Loss=3.7721, Success=0.00%, Avg Length=21.0, Total Successful Found: 1\n",
      "Step 40: Loss=3.3892, Success=0.00%, Avg Length=21.0, Total Successful Found: 1\n",
      "Total successful trajectories found during training: 1\n",
      "Found 1 successful trajectories (1 unique)\n",
      "Final Success Rate: 0.0%\n",
      "Final Avg Length: 21.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import random\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def flow_conservation_loss(flow_net, visited_states, edges, rewards, encode_state, verbose=False):\n",
    "    \"\"\"Flow conservation loss - physics constraint\"\"\"\n",
    "    total_loss = torch.tensor(0.0)\n",
    "    \n",
    "    for state in visited_states:\n",
    "        flow_in = torch.tensor(0.0)\n",
    "        flow_out = torch.tensor(0.0)\n",
    "        \n",
    "        # Flow IN\n",
    "        for from_state, to_state in edges:\n",
    "            if to_state == state:\n",
    "                from_vec = encode_state(from_state)\n",
    "                to_vec = encode_state(to_state)\n",
    "                edge_input = torch.cat([from_vec, to_vec])\n",
    "                predicted_flow = flow_net(edge_input).squeeze()\n",
    "                flow_in += predicted_flow\n",
    "        \n",
    "        # Flow OUT (rewards + outgoing flows)\n",
    "        if state in rewards:\n",
    "            reward_flow = torch.tensor(rewards[state])\n",
    "            flow_out += reward_flow\n",
    "        \n",
    "        for from_state, to_state in edges:\n",
    "            if from_state == state:\n",
    "                from_vec = encode_state(from_state)\n",
    "                to_vec = encode_state(to_state)\n",
    "                edge_input = torch.cat([from_vec, to_vec])\n",
    "                predicted_flow = flow_net(edge_input).squeeze()\n",
    "                flow_out += predicted_flow\n",
    "        \n",
    "        # Conservation constraint\n",
    "        conservation_error = (flow_in - flow_out) ** 2\n",
    "        total_loss += conservation_error\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "def visualize_trajectories(trajectories, env, title=\"Trajectories\", save_path=None):\n",
    "    \"\"\"Visualize trajectories on grid as heatmap\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    \n",
    "    # Create grid\n",
    "    grid = np.zeros((env.size, env.size))\n",
    "    \n",
    "    # Count visits to each state\n",
    "    visit_counts = {}\n",
    "    for traj in trajectories:\n",
    "        for state in traj:\n",
    "            visit_counts[state] = visit_counts.get(state, 0) + 1\n",
    "    \n",
    "    # Fill grid with visit counts\n",
    "    for (x, y), count in visit_counts.items():\n",
    "        grid[env.size-1-y, x] = count  # Flip y for visualization\n",
    "    \n",
    "    # Plot heatmap\n",
    "    im = ax.imshow(grid, cmap='Blues', origin='lower')\n",
    "    \n",
    "    # Mark start and reward region\n",
    "    ax.scatter(env.start_state[0], env.start_state[1], c='green', s=200, marker='s', label='Start')\n",
    "    \n",
    "    # Mark entire reward region\n",
    "    for state in env.reward_states:\n",
    "        ax.scatter(state[0], state[1], c='red', s=200, marker='*', alpha=0.7)\n",
    "    ax.scatter([], [], c='red', s=200, marker='*', label='Reward Region')  # For legend\n",
    "    \n",
    "    # Add grid lines\n",
    "    ax.set_xticks(range(env.size))\n",
    "    ax.set_yticks(range(env.size))\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Labels and title\n",
    "    ax.set_xlabel('X Position')\n",
    "    ax.set_ylabel('Y Position')\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    \n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(im, ax=ax)\n",
    "    cbar.set_label('Visit Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_individual_trajectories(trajectories, env, title=\"Individual Trajectories\", save_path=None, max_trajectories=5):\n",
    "    \"\"\"Visualize individual trajectory paths on grid\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Create base grid\n",
    "    ax.set_xlim(-0.5, env.size - 0.5)\n",
    "    ax.set_ylim(-0.5, env.size - 0.5)\n",
    "    \n",
    "    # Add grid lines\n",
    "    for i in range(env.size + 1):\n",
    "        ax.axhline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "        ax.axvline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "    \n",
    "    # Mark start and reward region\n",
    "    ax.scatter(env.start_state[0], env.start_state[1], c='green', s=300, marker='s', label='Start', zorder=5)\n",
    "    \n",
    "    for state in env.reward_states:\n",
    "        ax.add_patch(plt.Rectangle((state[0]-0.4, state[1]-0.4), 0.8, 0.8, \n",
    "                                 facecolor='red', alpha=0.3, zorder=1))\n",
    "    ax.scatter([], [], c='red', s=200, marker='s', alpha=0.3, label='Reward Region')\n",
    "    \n",
    "    # Plot trajectories\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, min(len(trajectories), max_trajectories)))\n",
    "    \n",
    "    for i, (traj, color) in enumerate(zip(trajectories[:max_trajectories], colors)):\n",
    "        if len(traj) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Extract x, y coordinates\n",
    "        xs, ys = zip(*traj)\n",
    "        \n",
    "        # Determine if successful\n",
    "        success = traj[-1] in env.reward_states\n",
    "        linestyle = '-' if success else '--'\n",
    "        alpha = 0.8 if success else 0.5\n",
    "        \n",
    "        # Plot trajectory line\n",
    "        ax.plot(xs, ys, color=color, linewidth=2, alpha=alpha, \n",
    "               linestyle=linestyle, label=f'Traj {i+1} ({\"âœ“\" if success else \"âœ—\"})')\n",
    "        \n",
    "        # Mark trajectory points\n",
    "        ax.scatter(xs[1:-1], ys[1:-1], color=color, s=30, alpha=0.6, zorder=3)\n",
    "        \n",
    "        # Mark end point\n",
    "        if success:\n",
    "            ax.scatter(xs[-1], ys[-1], color=color, s=100, marker='o', \n",
    "                      edgecolor='black', linewidth=1, zorder=4)\n",
    "        else:\n",
    "            ax.scatter(xs[-1], ys[-1], color=color, s=100, marker='x', \n",
    "                      linewidth=2, zorder=4)\n",
    "    \n",
    "    ax.set_xlabel('X Position')\n",
    "    ax.set_ylabel('Y Position')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def find_best_trajectories(trajectories, env, n_best=3):\n",
    "    \"\"\"Find the best trajectories based on success and length\"\"\"\n",
    "    successful = [traj for traj in trajectories if traj[-1] in env.reward_states]\n",
    "    failed = [traj for traj in trajectories if traj[-1] not in env.reward_states]\n",
    "    \n",
    "    # Sort successful by length (shorter is better)\n",
    "    successful.sort(key=len)\n",
    "    \n",
    "    # Sort failed by how close they got to reward region\n",
    "    def distance_to_reward(traj):\n",
    "        end_x, end_y = traj[-1]\n",
    "        min_dist = float('inf')\n",
    "        for rx, ry in env.reward_states:\n",
    "            dist = abs(end_x - rx) + abs(end_y - ry)  # Manhattan distance\n",
    "            min_dist = min(min_dist, dist)\n",
    "        return min_dist\n",
    "    \n",
    "    failed.sort(key=distance_to_reward)\n",
    "    \n",
    "    # Return mix of best successful and best failed\n",
    "    best_trajectories = []\n",
    "    best_trajectories.extend(successful[:min(n_best, len(successful))])\n",
    "    \n",
    "    remaining_slots = n_best - len(best_trajectories)\n",
    "    if remaining_slots > 0:\n",
    "        best_trajectories.extend(failed[:remaining_slots])\n",
    "    \n",
    "    return best_trajectories\n",
    "\n",
    "def sample_trajectory_from_flows(flow_net, env, encode_state, start_state, max_steps=20):\n",
    "    \"\"\"Sample trajectory using learned flow network\"\"\"\n",
    "    trajectory = [start_state]\n",
    "    state = start_state\n",
    "    \n",
    "    for _ in range(max_steps):\n",
    "        if env.is_terminal(state):\n",
    "            break\n",
    "        \n",
    "        valid_actions = env.get_valid_actions(state)\n",
    "        if not valid_actions:\n",
    "            break\n",
    "        \n",
    "        # Get flow predictions for all valid next states\n",
    "        next_states = [env.take_action(state, action) for action in valid_actions]\n",
    "        flows = []\n",
    "        \n",
    "        for next_state in next_states:\n",
    "            from_vec = encode_state(state)\n",
    "            to_vec = encode_state(next_state)\n",
    "            edge_input = torch.cat([from_vec, to_vec])\n",
    "            flow = flow_net(edge_input).squeeze()\n",
    "            flows.append(flow.item())\n",
    "        \n",
    "        # Convert flows to probabilities\n",
    "        flows = torch.tensor(flows)\n",
    "        probs = torch.softmax(flows, dim=0)\n",
    "        \n",
    "        # Sample next state based on flow probabilities\n",
    "        choice_idx = torch.multinomial(probs, 1).item()\n",
    "        next_state = next_states[choice_idx]\n",
    "        \n",
    "        trajectory.append(next_state)\n",
    "        state = next_state\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "def run_hypergrid_experiment(lr=0.001, hidden_dim=128, n_steps=50, batch_size=32):\n",
    "    \"\"\"Run single HyperGrid experiment with MLflow tracking\"\"\"\n",
    "    \n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run():\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"hidden_dim\", hidden_dim)\n",
    "        mlflow.log_param(\"n_steps\", n_steps)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        \n",
    "        # Initialize environment\n",
    "        env = HyperGrid(size=8)\n",
    "        \n",
    "        def encode_state(state):\n",
    "            \"\"\"Encode (x,y) state as one-hot vector\"\"\"\n",
    "            x, y = state\n",
    "            idx = y * env.size + x\n",
    "            vec = [0.0] * (env.size * env.size)\n",
    "            vec[idx] = 1.0\n",
    "            return torch.tensor(vec, dtype=torch.float32)\n",
    "        \n",
    "        # Flow network\n",
    "        state_dim = env.size * env.size\n",
    "        flow_net = nn.Sequential(\n",
    "            nn.Linear(state_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim//2),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_dim//2, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        optimizer = optim.Adam(flow_net.parameters(), lr=lr)\n",
    "        \n",
    "        # Set up rewards - all states in reward region get reward\n",
    "        rewards = {}\n",
    "        for state in env.reward_states:\n",
    "            rewards[state] = 1.0\n",
    "        \n",
    "        print(f\"Reward states: {sorted(rewards.keys())}\")\n",
    "        \n",
    "        # Training metrics\n",
    "        losses = []\n",
    "        success_rates = []\n",
    "        avg_lengths = []\n",
    "        all_successful_trajectories = []  # Store ALL successful trajectories found during training\n",
    "        \n",
    "        print(f\"Starting training: lr={lr}, hidden_dim={hidden_dim}\")\n",
    "        \n",
    "        # Training loop\n",
    "        for step in range(n_steps):\n",
    "            # Sample trajectories\n",
    "            trajectories = []\n",
    "            for _ in range(batch_size):\n",
    "                traj = env.sample_random_trajectory(max_steps=15)\n",
    "                trajectories.append(traj)\n",
    "                \n",
    "                # Collect successful trajectories\n",
    "                if traj[-1] in env.reward_states:\n",
    "                    all_successful_trajectories.append(traj)\n",
    "            \n",
    "            # Extract edges and states\n",
    "            edges = set()\n",
    "            visited_states = set()\n",
    "            for traj in trajectories:\n",
    "                visited_states.update(traj)\n",
    "                for i in range(len(traj) - 1):\n",
    "                    edges.add((traj[i], traj[i + 1]))\n",
    "            \n",
    "            edges = list(edges)\n",
    "            visited_states = list(visited_states)\n",
    "            \n",
    "            # Compute loss and update\n",
    "            loss = flow_conservation_loss(flow_net, visited_states, edges, rewards, encode_state)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Evaluate every 10 steps\n",
    "            if step % 10 == 0:\n",
    "                # Generate samples and measure performance\n",
    "                test_trajectories = []\n",
    "                success_count = 0\n",
    "                \n",
    "                for _ in range(20):\n",
    "                    traj = sample_trajectory_from_flows(flow_net, env, encode_state, env.start_state)\n",
    "                    test_trajectories.append(traj)\n",
    "                    success_count += (traj[-1] in env.reward_states)\n",
    "                    \n",
    "                    # Collect successful model trajectories too\n",
    "                    if traj[-1] in env.reward_states:\n",
    "                        all_successful_trajectories.append(traj)\n",
    "                \n",
    "                success_rate = success_count / 20\n",
    "                avg_length = sum(len(traj) for traj in test_trajectories) / len(test_trajectories)\n",
    "                \n",
    "                success_rates.append(success_rate)\n",
    "                avg_lengths.append(avg_length)\n",
    "                \n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"loss\", loss.item(), step=step)\n",
    "                mlflow.log_metric(\"success_rate\", success_rate, step=step)\n",
    "                mlflow.log_metric(\"avg_trajectory_length\", avg_length, step=step)\n",
    "                \n",
    "                print(f\"Step {step}: Loss={loss.item():.4f}, Success={success_rate:.2%}, Avg Length={avg_length:.1f}, Total Successful Found: {len(all_successful_trajectories)}\")\n",
    "        \n",
    "        # Final evaluation\n",
    "        final_trajectories = []\n",
    "        for _ in range(50):\n",
    "            traj = sample_trajectory_from_flows(flow_net, env, encode_state, env.start_state)\n",
    "            final_trajectories.append(traj)\n",
    "            # Add final successful trajectories\n",
    "            if traj[-1] in env.reward_states:\n",
    "                all_successful_trajectories.append(traj)\n",
    "        \n",
    "        final_success_rate = sum(1 for traj in final_trajectories if traj[-1] in env.reward_states) / len(final_trajectories)\n",
    "        final_avg_length = sum(len(traj) for traj in final_trajectories) / len(final_trajectories)\n",
    "        \n",
    "        # Log final metrics\n",
    "        mlflow.log_metric(\"final_success_rate\", final_success_rate)\n",
    "        mlflow.log_metric(\"final_avg_length\", final_avg_length)\n",
    "        mlflow.log_metric(\"total_successful_trajectories_found\", len(all_successful_trajectories))\n",
    "        \n",
    "        print(f\"Total successful trajectories found during training: {len(all_successful_trajectories)}\")\n",
    "        \n",
    "        # Create and log visualizations\n",
    "        \n",
    "        # 1. Training curves\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        \n",
    "        ax1.plot(losses)\n",
    "        ax1.set_title('Training Loss')\n",
    "        ax1.set_xlabel('Step')\n",
    "        ax1.set_ylabel('Flow Conservation Loss')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        eval_steps = list(range(0, n_steps, 10))\n",
    "        ax2.plot(eval_steps, success_rates, 'o-')\n",
    "        ax2.set_title('Success Rate')\n",
    "        ax2.set_xlabel('Step')\n",
    "        ax2.set_ylabel('Success Rate')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        ax3.plot(eval_steps, avg_lengths, 'o-')\n",
    "        ax3.set_title('Average Trajectory Length')\n",
    "        ax3.set_xlabel('Step')\n",
    "        ax3.set_ylabel('Average Length')\n",
    "        ax3.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact(\"training_curves.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Final trajectories heatmap\n",
    "        fig = visualize_trajectories(final_trajectories, env, \n",
    "                                   title=f\"Final Trajectories Heatmap (Success: {final_success_rate:.1%})\",\n",
    "                                   save_path=\"final_trajectories_heatmap.png\")\n",
    "        mlflow.log_artifact(\"final_trajectories_heatmap.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. ALL successful trajectories found during training\n",
    "        if all_successful_trajectories:\n",
    "            # Remove duplicates (same path)\n",
    "            unique_successful = []\n",
    "            seen_paths = set()\n",
    "            for traj in all_successful_trajectories:\n",
    "                path_tuple = tuple(traj)\n",
    "                if path_tuple not in seen_paths:\n",
    "                    unique_successful.append(traj)\n",
    "                    seen_paths.add(path_tuple)\n",
    "            \n",
    "            print(f\"Found {len(all_successful_trajectories)} successful trajectories ({len(unique_successful)} unique)\")\n",
    "            \n",
    "            # Visualize all unique successful trajectories\n",
    "            fig = visualize_individual_trajectories(\n",
    "                unique_successful, env,\n",
    "                title=f\"All Unique Successful Trajectories Found During Training ({len(unique_successful)} paths)\",\n",
    "                save_path=\"all_successful_trajectories.png\",\n",
    "                max_trajectories=min(20, len(unique_successful))  # Limit to 20 for readability\n",
    "            )\n",
    "            mlflow.log_artifact(\"all_successful_trajectories.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Also create a heatmap of just successful trajectories\n",
    "            fig = visualize_trajectories(unique_successful, env,\n",
    "                                       title=f\"Successful Trajectories Heatmap ({len(unique_successful)} unique paths)\",\n",
    "                                       save_path=\"successful_trajectories_heatmap.png\")\n",
    "            mlflow.log_artifact(\"successful_trajectories_heatmap.png\")\n",
    "            plt.close()\n",
    "            \n",
    "            # Log trajectory statistics\n",
    "            lengths = [len(traj) for traj in unique_successful]\n",
    "            mlflow.log_metric(\"min_successful_length\", min(lengths))\n",
    "            mlflow.log_metric(\"max_successful_length\", max(lengths))\n",
    "            mlflow.log_metric(\"avg_successful_length\", sum(lengths) / len(lengths))\n",
    "            mlflow.log_metric(\"unique_successful_paths\", len(unique_successful))\n",
    "        else:\n",
    "            print(\"No successful trajectories found during training!\")\n",
    "        \n",
    "        # 4. Best individual trajectories from final evaluation\n",
    "        best_trajectories = find_best_trajectories(final_trajectories, env, n_best=5)\n",
    "        fig = visualize_individual_trajectories(best_trajectories, env,\n",
    "                                              title=\"Best Individual Trajectories\",\n",
    "                                              save_path=\"best_trajectories.png\")\n",
    "        mlflow.log_artifact(\"best_trajectories.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # 5. Random baseline comparison\n",
    "        random_trajectories = []\n",
    "        for _ in range(50):\n",
    "            traj = env.sample_random_trajectory(max_steps=20)\n",
    "            random_trajectories.append(traj)\n",
    "        \n",
    "        fig = visualize_trajectories(random_trajectories, env, \n",
    "                                   title=\"Random Policy Trajectories\",\n",
    "                                   save_path=\"random_trajectories.png\")\n",
    "        mlflow.log_artifact(\"random_trajectories.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # 6. Best random trajectories for comparison\n",
    "        best_random = find_best_trajectories(random_trajectories, env, n_best=5)\n",
    "        fig = visualize_individual_trajectories(best_random, env,\n",
    "                                              title=\"Best Random Trajectories\",\n",
    "                                              save_path=\"best_random_trajectories.png\")\n",
    "        mlflow.log_artifact(\"best_random_trajectories.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Log model with input example\n",
    "        example_from_state = encode_state((0, 0))  # Start state\n",
    "        example_to_state = encode_state((1, 0))    # Adjacent state\n",
    "        example_input = torch.cat([example_from_state, example_to_state]).unsqueeze(0)  # Add batch dim\n",
    "        \n",
    "        mlflow.pytorch.log_model(\n",
    "            flow_net, \n",
    "            \"flow_model\",\n",
    "            input_example=example_input.numpy()\n",
    "        )\n",
    "        \n",
    "        print(f\"Final Success Rate: {final_success_rate:.1%}\")\n",
    "        print(f\"Final Avg Length: {final_avg_length:.1f}\")\n",
    "        \n",
    "        return final_success_rate, final_avg_length\n",
    "\n",
    "def run_hyperparameter_sweep():\n",
    "    \"\"\"Run hyperparameter sweep\"\"\"\n",
    "    \n",
    "    # Set up MLflow experiment\n",
    "    mlflow.set_experiment(\"HyperGrid_GFlowNet\")\n",
    "    \n",
    "    # Hyperparameter grid\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    hidden_dims = [64, 128, 256]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Running: lr={lr}, hidden_dim={hidden_dim}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            success_rate, avg_length = run_hypergrid_experiment(\n",
    "                lr=lr, \n",
    "                hidden_dim=hidden_dim, \n",
    "                n_steps=100,\n",
    "                batch_size=32\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'lr': lr,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'success_rate': success_rate,\n",
    "                'avg_length': avg_length\n",
    "            })\n",
    "    \n",
    "    # Summary results\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HYPERPARAMETER SWEEP RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    print(results_df.to_string(index=False))\n",
    "    \n",
    "    # Find best configuration\n",
    "    best_config = results_df.loc[results_df['success_rate'].idxmax()]\n",
    "    print(f\"\\nBest configuration:\")\n",
    "    print(f\"  Learning Rate: {best_config['lr']}\")\n",
    "    print(f\"  Hidden Dim: {best_config['hidden_dim']}\")\n",
    "    print(f\"  Success Rate: {best_config['success_rate']:.1%}\")\n",
    "    print(f\"  Avg Length: {best_config['avg_length']:.1f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run single experiment\n",
    "    run_hypergrid_experiment(lr=0.001, hidden_dim=128, n_steps=50)\n",
    "    \n",
    "    # Or run full hyperparameter sweep\n",
    "    # run_hyperparameter_sweep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "81284856-a620-46be-b72c-48cbc87543ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GFlowNet...\n",
      "Grid size: 8x8\n",
      "State encoding: one-hot vectors of size 64\n",
      "Flow network input: concatenated states (size 128)\n",
      "Trajectories: 3\n",
      "Edges: 8\n",
      "Visited states: 9\n",
      "Rewards: {(3, 0): 1.0, (1, 2): 0.5, (2, 1): 0.8}\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.7322    0.7277 0.0000 (0, 0)â†’0.732               â†’(0, 2):0.728\n",
      "(1, 2)   0.7385    0.5000 0.0569 (0, 2)â†’0.738                       R:0.5\n",
      "(2, 1)   0.7298    0.8000 0.0049 (1, 1)â†’0.730                       R:0.8\n",
      "(0, 0)   0.0000    1.4593 2.1297         none â†’(0, 1):0.732,â†’(1, 0):0.727\n",
      "(1, 1)   0.7396    0.7298 0.0001 (1, 0)â†’0.740               â†’(2, 1):0.730\n",
      "(2, 0)   0.7412    0.7280 0.0002 (1, 0)â†’0.741               â†’(3, 0):0.728\n",
      "(3, 0)   0.7280    1.0000 0.0740 (2, 0)â†’0.728                       R:1.0\n",
      "(0, 2)   0.7277    0.7385 0.0001 (0, 1)â†’0.728               â†’(1, 2):0.738\n",
      "(1, 0)   0.7271    1.4808 0.5680 (0, 0)â†’0.727 â†’(2, 0):0.741,â†’(1, 1):0.740\n",
      "\n",
      "Total Loss: 2.833825\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "Step 0: Loss = 2.833825\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.7234    0.7218 0.0000 (0, 0)â†’0.723               â†’(0, 2):0.722\n",
      "(1, 2)   0.7311    0.5000 0.0534 (0, 2)â†’0.731                       R:0.5\n",
      "(2, 1)   0.7254    0.8000 0.0056 (1, 1)â†’0.725                       R:0.8\n",
      "(0, 0)   0.0000    1.4408 2.0758         none â†’(0, 1):0.723,â†’(1, 0):0.717\n",
      "(1, 1)   0.7298    0.7254 0.0000 (1, 0)â†’0.730               â†’(2, 1):0.725\n",
      "(2, 0)   0.7306    0.7219 0.0001 (1, 0)â†’0.731               â†’(3, 0):0.722\n",
      "(3, 0)   0.7219    1.0000 0.0773 (2, 0)â†’0.722                       R:1.0\n",
      "(0, 2)   0.7218    0.7311 0.0001 (0, 1)â†’0.722               â†’(1, 2):0.731\n",
      "(1, 0)   0.7174    1.4604 0.5521 (0, 0)â†’0.717 â†’(2, 0):0.731,â†’(1, 1):0.730\n",
      "\n",
      "Total Loss: 2.764396\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.7147    0.7160 0.0000 (0, 0)â†’0.715               â†’(0, 2):0.716\n",
      "(1, 2)   0.7237    0.5000 0.0501 (0, 2)â†’0.724                       R:0.5\n",
      "(2, 1)   0.7211    0.8000 0.0062 (1, 1)â†’0.721                       R:0.8\n",
      "(0, 0)   0.0000    1.4227 2.0240         none â†’(0, 1):0.715,â†’(1, 0):0.708\n",
      "(1, 1)   0.7201    0.7211 0.0000 (1, 0)â†’0.720               â†’(2, 1):0.721\n",
      "(2, 0)   0.7205    0.7157 0.0000 (1, 0)â†’0.720               â†’(3, 0):0.716\n",
      "(3, 0)   0.7157    1.0000 0.0808 (2, 0)â†’0.716                       R:1.0\n",
      "(0, 2)   0.7160    0.7237 0.0001 (0, 1)â†’0.716               â†’(1, 2):0.724\n",
      "(1, 0)   0.7079    1.4405 0.5367 (0, 0)â†’0.708 â†’(2, 0):0.720,â†’(1, 1):0.720\n",
      "\n",
      "Total Loss: 2.697906\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.7068    0.7101 0.0000 (0, 0)â†’0.707               â†’(0, 2):0.710\n",
      "(1, 2)   0.7162    0.5000 0.0467 (0, 2)â†’0.716                       R:0.5\n",
      "(2, 1)   0.7171    0.8000 0.0069 (1, 1)â†’0.717                       R:0.8\n",
      "(0, 0)   0.0000    1.4054 1.9751         none â†’(0, 1):0.707,â†’(1, 0):0.699\n",
      "(1, 1)   0.7106    0.7171 0.0000 (1, 0)â†’0.711               â†’(2, 1):0.717\n",
      "(2, 0)   0.7113    0.7098 0.0000 (1, 0)â†’0.711               â†’(3, 0):0.710\n",
      "(3, 0)   0.7098    1.0000 0.0842 (2, 0)â†’0.710                       R:1.0\n",
      "(0, 2)   0.7101    0.7162 0.0000 (0, 1)â†’0.710               â†’(1, 2):0.716\n",
      "(1, 0)   0.6986    1.4219 0.5232 (0, 0)â†’0.699 â†’(2, 0):0.711,â†’(1, 1):0.711\n",
      "\n",
      "Total Loss: 2.636225\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6990    0.7043 0.0000 (0, 0)â†’0.699               â†’(0, 2):0.704\n",
      "(1, 2)   0.7083    0.5000 0.0434 (0, 2)â†’0.708                       R:0.5\n",
      "(2, 1)   0.7130    0.8000 0.0076 (1, 1)â†’0.713                       R:0.8\n",
      "(0, 0)   0.0000    1.3883 1.9274         none â†’(0, 1):0.699,â†’(1, 0):0.689\n",
      "(1, 1)   0.7020    0.7130 0.0001 (1, 0)â†’0.702               â†’(2, 1):0.713\n",
      "(2, 0)   0.7022    0.7041 0.0000 (1, 0)â†’0.702               â†’(3, 0):0.704\n",
      "(3, 0)   0.7041    1.0000 0.0876 (2, 0)â†’0.704                       R:1.0\n",
      "(0, 2)   0.7043    0.7083 0.0000 (0, 1)â†’0.704               â†’(1, 2):0.708\n",
      "(1, 0)   0.6893    1.4041 0.5109 (0, 0)â†’0.689 â†’(2, 0):0.702,â†’(1, 1):0.702\n",
      "\n",
      "Total Loss: 2.577017\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6907    0.6984 0.0001 (0, 0)â†’0.691               â†’(0, 2):0.698\n",
      "(1, 2)   0.7005    0.5000 0.0402 (0, 2)â†’0.701                       R:0.5\n",
      "(2, 1)   0.7092    0.8000 0.0082 (1, 1)â†’0.709                       R:0.8\n",
      "(0, 0)   0.0000    1.3715 1.8811         none â†’(0, 1):0.691,â†’(1, 0):0.681\n",
      "(1, 1)   0.6933    0.7092 0.0003 (1, 0)â†’0.693               â†’(2, 1):0.709\n",
      "(2, 0)   0.6931    0.6989 0.0000 (1, 0)â†’0.693               â†’(3, 0):0.699\n",
      "(3, 0)   0.6989    1.0000 0.0907 (2, 0)â†’0.699                       R:1.0\n",
      "(0, 2)   0.6984    0.7005 0.0000 (0, 1)â†’0.698               â†’(1, 2):0.701\n",
      "(1, 0)   0.6808    1.3864 0.4978 (0, 0)â†’0.681 â†’(2, 0):0.693,â†’(1, 1):0.693\n",
      "\n",
      "Total Loss: 2.518350\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6823    0.6920 0.0001 (0, 0)â†’0.682               â†’(0, 2):0.692\n",
      "(1, 2)   0.6928    0.5000 0.0372 (0, 2)â†’0.693                       R:0.5\n",
      "(2, 1)   0.7056    0.8000 0.0089 (1, 1)â†’0.706                       R:0.8\n",
      "(0, 0)   0.0000    1.3546 1.8350         none â†’(0, 1):0.682,â†’(1, 0):0.672\n",
      "(1, 1)   0.6847    0.7056 0.0004 (1, 0)â†’0.685               â†’(2, 1):0.706\n",
      "(2, 0)   0.6844    0.6938 0.0001 (1, 0)â†’0.684               â†’(3, 0):0.694\n",
      "(3, 0)   0.6938    1.0000 0.0938 (2, 0)â†’0.694                       R:1.0\n",
      "(0, 2)   0.6920    0.6928 0.0000 (0, 1)â†’0.692               â†’(1, 2):0.693\n",
      "(1, 0)   0.6723    1.3692 0.4856 (0, 0)â†’0.672 â†’(2, 0):0.684,â†’(1, 1):0.685\n",
      "\n",
      "Total Loss: 2.461120\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6738    0.6852 0.0001 (0, 0)â†’0.674               â†’(0, 2):0.685\n",
      "(1, 2)   0.6849    0.5000 0.0342 (0, 2)â†’0.685                       R:0.5\n",
      "(2, 1)   0.7020    0.8000 0.0096 (1, 1)â†’0.702                       R:0.8\n",
      "(0, 0)   0.0000    1.3380 1.7902         none â†’(0, 1):0.674,â†’(1, 0):0.664\n",
      "(1, 1)   0.6761    0.7020 0.0007 (1, 0)â†’0.676               â†’(2, 1):0.702\n",
      "(2, 0)   0.6757    0.6888 0.0002 (1, 0)â†’0.676               â†’(3, 0):0.689\n",
      "(3, 0)   0.6888    1.0000 0.0969 (2, 0)â†’0.689                       R:1.0\n",
      "(0, 2)   0.6852    0.6849 0.0000 (0, 1)â†’0.685               â†’(1, 2):0.685\n",
      "(1, 0)   0.6642    1.3517 0.4727 (0, 0)â†’0.664 â†’(2, 0):0.676,â†’(1, 1):0.676\n",
      "\n",
      "Total Loss: 2.404535\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6651    0.6780 0.0002 (0, 0)â†’0.665               â†’(0, 2):0.678\n",
      "(1, 2)   0.6772    0.5000 0.0314 (0, 2)â†’0.677                       R:0.5\n",
      "(2, 1)   0.6980    0.8000 0.0104 (1, 1)â†’0.698                       R:0.8\n",
      "(0, 0)   0.0000    1.3215 1.7464         none â†’(0, 1):0.665,â†’(1, 0):0.656\n",
      "(1, 1)   0.6671    0.6980 0.0010 (1, 0)â†’0.667               â†’(2, 1):0.698\n",
      "(2, 0)   0.6667    0.6839 0.0003 (1, 0)â†’0.667               â†’(3, 0):0.684\n",
      "(3, 0)   0.6839    1.0000 0.0999 (2, 0)â†’0.684                       R:1.0\n",
      "(0, 2)   0.6780    0.6772 0.0000 (0, 1)â†’0.678               â†’(1, 2):0.677\n",
      "(1, 0)   0.6564    1.3338 0.4589 (0, 0)â†’0.656 â†’(2, 0):0.667,â†’(1, 1):0.667\n",
      "\n",
      "Total Loss: 2.348386\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6564    0.6702 0.0002 (0, 0)â†’0.656               â†’(0, 2):0.670\n",
      "(1, 2)   0.6692    0.5000 0.0286 (0, 2)â†’0.669                       R:0.5\n",
      "(2, 1)   0.6938    0.8000 0.0113 (1, 1)â†’0.694                       R:0.8\n",
      "(0, 0)   0.0000    1.3047 1.7021         none â†’(0, 1):0.656,â†’(1, 0):0.648\n",
      "(1, 1)   0.6579    0.6938 0.0013 (1, 0)â†’0.658               â†’(2, 1):0.694\n",
      "(2, 0)   0.6575    0.6791 0.0005 (1, 0)â†’0.658               â†’(3, 0):0.679\n",
      "(3, 0)   0.6791    1.0000 0.1030 (2, 0)â†’0.679                       R:1.0\n",
      "(0, 2)   0.6702    0.6692 0.0000 (0, 1)â†’0.670               â†’(1, 2):0.669\n",
      "(1, 0)   0.6482    1.3154 0.4452 (0, 0)â†’0.648 â†’(2, 0):0.658,â†’(1, 1):0.658\n",
      "\n",
      "Total Loss: 2.292133\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6480    0.6621 0.0002 (0, 0)â†’0.648               â†’(0, 2):0.662\n",
      "(1, 2)   0.6611    0.5000 0.0259 (0, 2)â†’0.661                       R:0.5\n",
      "(2, 1)   0.6897    0.8000 0.0122 (1, 1)â†’0.690                       R:0.8\n",
      "(0, 0)   0.0000    1.2877 1.6583         none â†’(0, 1):0.648,â†’(1, 0):0.640\n",
      "(1, 1)   0.6485    0.6897 0.0017 (1, 0)â†’0.648               â†’(2, 1):0.690\n",
      "(2, 0)   0.6484    0.6741 0.0007 (1, 0)â†’0.648               â†’(3, 0):0.674\n",
      "(3, 0)   0.6741    1.0000 0.1062 (2, 0)â†’0.674                       R:1.0\n",
      "(0, 2)   0.6621    0.6611 0.0000 (0, 1)â†’0.662               â†’(1, 2):0.661\n",
      "(1, 0)   0.6397    1.2969 0.4318 (0, 0)â†’0.640 â†’(2, 0):0.648,â†’(1, 1):0.648\n",
      "\n",
      "Total Loss: 2.236988\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6393    0.6538 0.0002 (0, 0)â†’0.639               â†’(0, 2):0.654\n",
      "(1, 2)   0.6530    0.5000 0.0234 (0, 2)â†’0.653                       R:0.5\n",
      "(2, 1)   0.6856    0.8000 0.0131 (1, 1)â†’0.686                       R:0.8\n",
      "(0, 0)   0.0000    1.2702 1.6134         none â†’(0, 1):0.639,â†’(1, 0):0.631\n",
      "(1, 1)   0.6388    0.6856 0.0022 (1, 0)â†’0.639               â†’(2, 1):0.686\n",
      "(2, 0)   0.6390    0.6692 0.0009 (1, 0)â†’0.639               â†’(3, 0):0.669\n",
      "(3, 0)   0.6692    1.0000 0.1094 (2, 0)â†’0.669                       R:1.0\n",
      "(0, 2)   0.6538    0.6530 0.0000 (0, 1)â†’0.654               â†’(1, 2):0.653\n",
      "(1, 0)   0.6309    1.2778 0.4185 (0, 0)â†’0.631 â†’(2, 0):0.639,â†’(1, 1):0.639\n",
      "\n",
      "Total Loss: 2.181172\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6304    0.6452 0.0002 (0, 0)â†’0.630               â†’(0, 2):0.645\n",
      "(1, 2)   0.6446    0.5000 0.0209 (0, 2)â†’0.645                       R:0.5\n",
      "(2, 1)   0.6816    0.8000 0.0140 (1, 1)â†’0.682                       R:0.8\n",
      "(0, 0)   0.0000    1.2518 1.5670         none â†’(0, 1):0.630,â†’(1, 0):0.621\n",
      "(1, 1)   0.6290    0.6816 0.0028 (1, 0)â†’0.629               â†’(2, 1):0.682\n",
      "(2, 0)   0.6296    0.6643 0.0012 (1, 0)â†’0.630               â†’(3, 0):0.664\n",
      "(3, 0)   0.6643    1.0000 0.1127 (2, 0)â†’0.664                       R:1.0\n",
      "(0, 2)   0.6452    0.6446 0.0000 (0, 1)â†’0.645               â†’(1, 2):0.645\n",
      "(1, 0)   0.6214    1.2587 0.4061 (0, 0)â†’0.621 â†’(2, 0):0.630,â†’(1, 1):0.629\n",
      "\n",
      "Total Loss: 2.124851\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6210    0.6364 0.0002 (0, 0)â†’0.621               â†’(0, 2):0.636\n",
      "(1, 2)   0.6360    0.5000 0.0185 (0, 2)â†’0.636                       R:0.5\n",
      "(2, 1)   0.6778    0.8000 0.0149 (1, 1)â†’0.678                       R:0.8\n",
      "(0, 0)   0.0000    1.2326 1.5193         none â†’(0, 1):0.621,â†’(1, 0):0.612\n",
      "(1, 1)   0.6191    0.6778 0.0034 (1, 0)â†’0.619               â†’(2, 1):0.678\n",
      "(2, 0)   0.6200    0.6596 0.0016 (1, 0)â†’0.620               â†’(3, 0):0.660\n",
      "(3, 0)   0.6596    1.0000 0.1159 (2, 0)â†’0.660                       R:1.0\n",
      "(0, 2)   0.6364    0.6360 0.0000 (0, 1)â†’0.636               â†’(1, 2):0.636\n",
      "(1, 0)   0.6116    1.2391 0.3937 (0, 0)â†’0.612 â†’(2, 0):0.620,â†’(1, 1):0.619\n",
      "\n",
      "Total Loss: 2.067567\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6112    0.6274 0.0003 (0, 0)â†’0.611               â†’(0, 2):0.627\n",
      "(1, 2)   0.6273    0.5000 0.0162 (0, 2)â†’0.627                       R:0.5\n",
      "(2, 1)   0.6742    0.8000 0.0158 (1, 1)â†’0.674                       R:0.8\n",
      "(0, 0)   0.0000    1.2125 1.4702         none â†’(0, 1):0.611,â†’(1, 0):0.601\n",
      "(1, 1)   0.6086    0.6742 0.0043 (1, 0)â†’0.609               â†’(2, 1):0.674\n",
      "(2, 0)   0.6101    0.6550 0.0020 (1, 0)â†’0.610               â†’(3, 0):0.655\n",
      "(3, 0)   0.6550    1.0000 0.1190 (2, 0)â†’0.655                       R:1.0\n",
      "(0, 2)   0.6274    0.6273 0.0000 (0, 1)â†’0.627               â†’(1, 2):0.627\n",
      "(1, 0)   0.6014    1.2188 0.3811 (0, 0)â†’0.601 â†’(2, 0):0.610,â†’(1, 1):0.609\n",
      "\n",
      "Total Loss: 2.009036\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.6008    0.6183 0.0003 (0, 0)â†’0.601               â†’(0, 2):0.618\n",
      "(1, 2)   0.6183    0.5000 0.0140 (0, 2)â†’0.618                       R:0.5\n",
      "(2, 1)   0.6706    0.8000 0.0167 (1, 1)â†’0.671                       R:0.8\n",
      "(0, 0)   0.0000    1.1913 1.4192         none â†’(0, 1):0.601,â†’(1, 0):0.590\n",
      "(1, 1)   0.5977    0.6706 0.0053 (1, 0)â†’0.598               â†’(2, 1):0.671\n",
      "(2, 0)   0.6000    0.6505 0.0026 (1, 0)â†’0.600               â†’(3, 0):0.650\n",
      "(3, 0)   0.6505    1.0000 0.1222 (2, 0)â†’0.650                       R:1.0\n",
      "(0, 2)   0.6183    0.6183 0.0000 (0, 1)â†’0.618               â†’(1, 2):0.618\n",
      "(1, 0)   0.5905    1.1977 0.3687 (0, 0)â†’0.590 â†’(2, 0):0.600,â†’(1, 1):0.598\n",
      "\n",
      "Total Loss: 1.948952\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.5901    0.6088 0.0004 (0, 0)â†’0.590               â†’(0, 2):0.609\n",
      "(1, 2)   0.6090    0.5000 0.0119 (0, 2)â†’0.609                       R:0.5\n",
      "(2, 1)   0.6671    0.8000 0.0177 (1, 1)â†’0.667                       R:0.8\n",
      "(0, 0)   0.0000    1.1691 1.3667         none â†’(0, 1):0.590,â†’(1, 0):0.579\n",
      "(1, 1)   0.5865    0.6671 0.0065 (1, 0)â†’0.587               â†’(2, 1):0.667\n",
      "(2, 0)   0.5894    0.6460 0.0032 (1, 0)â†’0.589               â†’(3, 0):0.646\n",
      "(3, 0)   0.6460    1.0000 0.1253 (2, 0)â†’0.646                       R:1.0\n",
      "(0, 2)   0.6088    0.6090 0.0000 (0, 1)â†’0.609               â†’(1, 2):0.609\n",
      "(1, 0)   0.5790    1.1759 0.3563 (0, 0)â†’0.579 â†’(2, 0):0.589,â†’(1, 1):0.587\n",
      "\n",
      "Total Loss: 1.887961\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.5789    0.5991 0.0004 (0, 0)â†’0.579               â†’(0, 2):0.599\n",
      "(1, 2)   0.5995    0.5000 0.0099 (0, 2)â†’0.599                       R:0.5\n",
      "(2, 1)   0.6636    0.8000 0.0186 (1, 1)â†’0.664                       R:0.8\n",
      "(0, 0)   0.0000    1.1460 1.3133         none â†’(0, 1):0.579,â†’(1, 0):0.567\n",
      "(1, 1)   0.5752    0.6636 0.0078 (1, 0)â†’0.575               â†’(2, 1):0.664\n",
      "(2, 0)   0.5787    0.6415 0.0039 (1, 0)â†’0.579               â†’(3, 0):0.642\n",
      "(3, 0)   0.6415    1.0000 0.1285 (2, 0)â†’0.642                       R:1.0\n",
      "(0, 2)   0.5991    0.5995 0.0000 (0, 1)â†’0.599               â†’(1, 2):0.599\n",
      "(1, 0)   0.5671    1.1539 0.3443 (0, 0)â†’0.567 â†’(2, 0):0.579,â†’(1, 1):0.575\n",
      "\n",
      "Total Loss: 1.826722\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.5671    0.5890 0.0005 (0, 0)â†’0.567               â†’(0, 2):0.589\n",
      "(1, 2)   0.5896    0.5000 0.0080 (0, 2)â†’0.590                       R:0.5\n",
      "(2, 1)   0.6602    0.8000 0.0195 (1, 1)â†’0.660                       R:0.8\n",
      "(0, 0)   0.0000    1.1218 1.2584         none â†’(0, 1):0.567,â†’(1, 0):0.555\n",
      "(1, 1)   0.5633    0.6602 0.0094 (1, 0)â†’0.563               â†’(2, 1):0.660\n",
      "(2, 0)   0.5676    0.6372 0.0048 (1, 0)â†’0.568               â†’(3, 0):0.637\n",
      "(3, 0)   0.6372    1.0000 0.1316 (2, 0)â†’0.637                       R:1.0\n",
      "(0, 2)   0.5890    0.5896 0.0000 (0, 1)â†’0.589               â†’(1, 2):0.590\n",
      "(1, 0)   0.5547    1.1309 0.3321 (0, 0)â†’0.555 â†’(2, 0):0.568,â†’(1, 1):0.563\n",
      "\n",
      "Total Loss: 1.764409\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.5550    0.5785 0.0006 (0, 0)â†’0.555               â†’(0, 2):0.579\n",
      "(1, 2)   0.5793    0.5000 0.0063 (0, 2)â†’0.579                       R:0.5\n",
      "(2, 1)   0.6570    0.8000 0.0205 (1, 1)â†’0.657                       R:0.8\n",
      "(0, 0)   0.0000    1.0967 1.2028         none â†’(0, 1):0.555,â†’(1, 0):0.542\n",
      "(1, 1)   0.5511    0.6570 0.0112 (1, 0)â†’0.551               â†’(2, 1):0.657\n",
      "(2, 0)   0.5561    0.6330 0.0059 (1, 0)â†’0.556               â†’(3, 0):0.633\n",
      "(3, 0)   0.6330    1.0000 0.1347 (2, 0)â†’0.633                       R:1.0\n",
      "(0, 2)   0.5785    0.5793 0.0000 (0, 1)â†’0.579               â†’(1, 2):0.579\n",
      "(1, 0)   0.5417    1.1072 0.3198 (0, 0)â†’0.542 â†’(2, 0):0.556,â†’(1, 1):0.551\n",
      "\n",
      "Total Loss: 1.701677\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.5424    0.5674 0.0006 (0, 0)â†’0.542               â†’(0, 2):0.567\n",
      "(1, 2)   0.5687    0.5000 0.0047 (0, 2)â†’0.569                       R:0.5\n",
      "(2, 1)   0.6538    0.8000 0.0214 (1, 1)â†’0.654                       R:0.8\n",
      "(0, 0)   0.0000    1.0708 1.1467         none â†’(0, 1):0.542,â†’(1, 0):0.528\n",
      "(1, 1)   0.5384    0.6538 0.0133 (1, 0)â†’0.538               â†’(2, 1):0.654\n",
      "(2, 0)   0.5440    0.6289 0.0072 (1, 0)â†’0.544               â†’(3, 0):0.629\n",
      "(3, 0)   0.6289    1.0000 0.1377 (2, 0)â†’0.629                       R:1.0\n",
      "(0, 2)   0.5674    0.5687 0.0000 (0, 1)â†’0.567               â†’(1, 2):0.569\n",
      "(1, 0)   0.5284    1.0824 0.3069 (0, 0)â†’0.528 â†’(2, 0):0.544,â†’(1, 1):0.538\n",
      "\n",
      "Total Loss: 1.638545\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "Step 20: Loss = 1.638545\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.5296    0.5557 0.0007 (0, 0)â†’0.530               â†’(0, 2):0.556\n",
      "(1, 2)   0.5578    0.5000 0.0033 (0, 2)â†’0.558                       R:0.5\n",
      "(2, 1)   0.6507    0.8000 0.0223 (1, 1)â†’0.651                       R:0.8\n",
      "(0, 0)   0.0000    1.0443 1.0905         none â†’(0, 1):0.530,â†’(1, 0):0.515\n",
      "(1, 1)   0.5251    0.6507 0.0158 (1, 0)â†’0.525               â†’(2, 1):0.651\n",
      "(2, 0)   0.5315    0.6247 0.0087 (1, 0)â†’0.531               â†’(3, 0):0.625\n",
      "(3, 0)   0.6247    1.0000 0.1408 (2, 0)â†’0.625                       R:1.0\n",
      "(0, 2)   0.5557    0.5578 0.0000 (0, 1)â†’0.556               â†’(1, 2):0.558\n",
      "(1, 0)   0.5146    1.0565 0.2936 (0, 0)â†’0.515 â†’(2, 0):0.531,â†’(1, 1):0.525\n",
      "\n",
      "Total Loss: 1.575763\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.5164    0.5433 0.0007 (0, 0)â†’0.516               â†’(0, 2):0.543\n",
      "(1, 2)   0.5466    0.5000 0.0022 (0, 2)â†’0.547                       R:0.5\n",
      "(2, 1)   0.6477    0.8000 0.0232 (1, 1)â†’0.648                       R:0.8\n",
      "(0, 0)   0.0000    1.0169 1.0340         none â†’(0, 1):0.516,â†’(1, 0):0.500\n",
      "(1, 1)   0.5114    0.6477 0.0186 (1, 0)â†’0.511               â†’(2, 1):0.648\n",
      "(2, 0)   0.5185    0.6208 0.0105 (1, 0)â†’0.518               â†’(3, 0):0.621\n",
      "(3, 0)   0.6208    1.0000 0.1438 (2, 0)â†’0.621                       R:1.0\n",
      "(0, 2)   0.5433    0.5466 0.0000 (0, 1)â†’0.543               â†’(1, 2):0.547\n",
      "(1, 0)   0.5005    1.0299 0.2803 (0, 0)â†’0.500 â†’(2, 0):0.518,â†’(1, 1):0.511\n",
      "\n",
      "Total Loss: 1.513231\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.5027    0.5305 0.0008 (0, 0)â†’0.503               â†’(0, 2):0.531\n",
      "(1, 2)   0.5351    0.5000 0.0012 (0, 2)â†’0.535                       R:0.5\n",
      "(2, 1)   0.6447    0.8000 0.0241 (1, 1)â†’0.645                       R:0.8\n",
      "(0, 0)   0.0000    0.9887 0.9775         none â†’(0, 1):0.503,â†’(1, 0):0.486\n",
      "(1, 1)   0.4974    0.6447 0.0217 (1, 0)â†’0.497               â†’(2, 1):0.645\n",
      "(2, 0)   0.5050    0.6172 0.0126 (1, 0)â†’0.505               â†’(3, 0):0.617\n",
      "(3, 0)   0.6172    1.0000 0.1466 (2, 0)â†’0.617                       R:1.0\n",
      "(0, 2)   0.5305    0.5351 0.0000 (0, 1)â†’0.531               â†’(1, 2):0.535\n",
      "(1, 0)   0.4860    1.0025 0.2668 (0, 0)â†’0.486 â†’(2, 0):0.505,â†’(1, 1):0.497\n",
      "\n",
      "Total Loss: 1.451232\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.4885    0.5173 0.0008 (0, 0)â†’0.489               â†’(0, 2):0.517\n",
      "(1, 2)   0.5234    0.5000 0.0005 (0, 2)â†’0.523                       R:0.5\n",
      "(2, 1)   0.6416    0.8000 0.0251 (1, 1)â†’0.642                       R:0.8\n",
      "(0, 0)   0.0000    0.9596 0.9209         none â†’(0, 1):0.489,â†’(1, 0):0.471\n",
      "(1, 1)   0.4831    0.6416 0.0251 (1, 0)â†’0.483               â†’(2, 1):0.642\n",
      "(2, 0)   0.4911    0.6138 0.0150 (1, 0)â†’0.491               â†’(3, 0):0.614\n",
      "(3, 0)   0.6138    1.0000 0.1492 (2, 0)â†’0.614                       R:1.0\n",
      "(0, 2)   0.5173    0.5234 0.0000 (0, 1)â†’0.517               â†’(1, 2):0.523\n",
      "(1, 0)   0.4711    0.9743 0.2532 (0, 0)â†’0.471 â†’(2, 0):0.491,â†’(1, 1):0.483\n",
      "\n",
      "Total Loss: 1.389899\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.4740    0.5036 0.0009 (0, 0)â†’0.474               â†’(0, 2):0.504\n",
      "(1, 2)   0.5115    0.5000 0.0001 (0, 2)â†’0.512                       R:0.5\n",
      "(2, 1)   0.6384    0.8000 0.0261 (1, 1)â†’0.638                       R:0.8\n",
      "(0, 0)   0.0000    0.9299 0.8648         none â†’(0, 1):0.474,â†’(1, 0):0.456\n",
      "(1, 1)   0.4685    0.6384 0.0289 (1, 0)â†’0.469               â†’(2, 1):0.638\n",
      "(2, 0)   0.4769    0.6107 0.0179 (1, 0)â†’0.477               â†’(3, 0):0.611\n",
      "(3, 0)   0.6107    1.0000 0.1516 (2, 0)â†’0.611                       R:1.0\n",
      "(0, 2)   0.5036    0.5115 0.0001 (0, 1)â†’0.504               â†’(1, 2):0.512\n",
      "(1, 0)   0.4559    0.9454 0.2397 (0, 0)â†’0.456 â†’(2, 0):0.477,â†’(1, 1):0.469\n",
      "\n",
      "Total Loss: 1.329921\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.4592    0.4896 0.0009 (0, 0)â†’0.459               â†’(0, 2):0.490\n",
      "(1, 2)   0.4995    0.5000 0.0000 (0, 2)â†’0.500                       R:0.5\n",
      "(2, 1)   0.6347    0.8000 0.0273 (1, 1)â†’0.635                       R:0.8\n",
      "(0, 0)   0.0000    0.8997 0.8094         none â†’(0, 1):0.459,â†’(1, 0):0.440\n",
      "(1, 1)   0.4536    0.6347 0.0328 (1, 0)â†’0.454               â†’(2, 1):0.635\n",
      "(2, 0)   0.4624    0.6079 0.0212 (1, 0)â†’0.462               â†’(3, 0):0.608\n",
      "(3, 0)   0.6079    1.0000 0.1538 (2, 0)â†’0.608                       R:1.0\n",
      "(0, 2)   0.4896    0.4995 0.0001 (0, 1)â†’0.490               â†’(1, 2):0.500\n",
      "(1, 0)   0.4404    0.9160 0.2262 (0, 0)â†’0.440 â†’(2, 0):0.462,â†’(1, 1):0.454\n",
      "\n",
      "Total Loss: 1.271614\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.4442    0.4751 0.0010 (0, 0)â†’0.444               â†’(0, 2):0.475\n",
      "(1, 2)   0.4875    0.5000 0.0002 (0, 2)â†’0.487                       R:0.5\n",
      "(2, 1)   0.6306    0.8000 0.0287 (1, 1)â†’0.631                       R:0.8\n",
      "(0, 0)   0.0000    0.8689 0.7550         none â†’(0, 1):0.444,â†’(1, 0):0.425\n",
      "(1, 1)   0.4386    0.6306 0.0369 (1, 0)â†’0.439               â†’(2, 1):0.631\n",
      "(2, 0)   0.4475    0.6053 0.0249 (1, 0)â†’0.448               â†’(3, 0):0.605\n",
      "(3, 0)   0.6053    1.0000 0.1558 (2, 0)â†’0.605                       R:1.0\n",
      "(0, 2)   0.4751    0.4875 0.0002 (0, 1)â†’0.475               â†’(1, 2):0.487\n",
      "(1, 0)   0.4247    0.8861 0.2129 (0, 0)â†’0.425 â†’(2, 0):0.448,â†’(1, 1):0.439\n",
      "\n",
      "Total Loss: 1.215358\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.4289    0.4605 0.0010 (0, 0)â†’0.429               â†’(0, 2):0.460\n",
      "(1, 2)   0.4755    0.5000 0.0006 (0, 2)â†’0.475                       R:0.5\n",
      "(2, 1)   0.6257    0.8000 0.0304 (1, 1)â†’0.626                       R:0.8\n",
      "(0, 0)   0.0000    0.8378 0.7018         none â†’(0, 1):0.429,â†’(1, 0):0.409\n",
      "(1, 1)   0.4234    0.6257 0.0410 (1, 0)â†’0.423               â†’(2, 1):0.626\n",
      "(2, 0)   0.4324    0.6030 0.0291 (1, 0)â†’0.432               â†’(3, 0):0.603\n",
      "(3, 0)   0.6030    1.0000 0.1576 (2, 0)â†’0.603                       R:1.0\n",
      "(0, 2)   0.4605    0.4755 0.0002 (0, 1)â†’0.460               â†’(1, 2):0.475\n",
      "(1, 0)   0.4089    0.8558 0.1997 (0, 0)â†’0.409 â†’(2, 0):0.432,â†’(1, 1):0.423\n",
      "\n",
      "Total Loss: 1.161448\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.4134    0.4456 0.0010 (0, 0)â†’0.413               â†’(0, 2):0.446\n",
      "(1, 2)   0.4637    0.5000 0.0013 (0, 2)â†’0.464                       R:0.5\n",
      "(2, 1)   0.6201    0.8000 0.0324 (1, 1)â†’0.620                       R:0.8\n",
      "(0, 0)   0.0000    0.8063 0.6502         none â†’(0, 1):0.413,â†’(1, 0):0.393\n",
      "(1, 1)   0.4080    0.6201 0.0450 (1, 0)â†’0.408               â†’(2, 1):0.620\n",
      "(2, 0)   0.4172    0.6009 0.0338 (1, 0)â†’0.417               â†’(3, 0):0.601\n",
      "(3, 0)   0.6009    1.0000 0.1593 (2, 0)â†’0.601                       R:1.0\n",
      "(0, 2)   0.4456    0.4637 0.0003 (0, 1)â†’0.446               â†’(1, 2):0.464\n",
      "(1, 0)   0.3929    0.8252 0.1869 (0, 0)â†’0.393 â†’(2, 0):0.417,â†’(1, 1):0.408\n",
      "\n",
      "Total Loss: 1.110122\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.3979    0.4306 0.0011 (0, 0)â†’0.398               â†’(0, 2):0.431\n",
      "(1, 2)   0.4522    0.5000 0.0023 (0, 2)â†’0.452                       R:0.5\n",
      "(2, 1)   0.6136    0.8000 0.0347 (1, 1)â†’0.614                       R:0.8\n",
      "(0, 0)   0.0000    0.7748 0.6003         none â†’(0, 1):0.398,â†’(1, 0):0.377\n",
      "(1, 1)   0.3928    0.6136 0.0488 (1, 0)â†’0.393               â†’(2, 1):0.614\n",
      "(2, 0)   0.4019    0.5992 0.0389 (1, 0)â†’0.402               â†’(3, 0):0.599\n",
      "(3, 0)   0.5992    1.0000 0.1606 (2, 0)â†’0.599                       R:1.0\n",
      "(0, 2)   0.4306    0.4522 0.0005 (0, 1)â†’0.431               â†’(1, 2):0.452\n",
      "(1, 0)   0.3770    0.7947 0.1745 (0, 0)â†’0.377 â†’(2, 0):0.402,â†’(1, 1):0.393\n",
      "\n",
      "Total Loss: 1.061728\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.3822    0.4155 0.0011 (0, 0)â†’0.382               â†’(0, 2):0.415\n",
      "(1, 2)   0.4411    0.5000 0.0035 (0, 2)â†’0.441                       R:0.5\n",
      "(2, 1)   0.6062    0.8000 0.0375 (1, 1)â†’0.606                       R:0.8\n",
      "(0, 0)   0.0000    0.7433 0.5525         none â†’(0, 1):0.382,â†’(1, 0):0.361\n",
      "(1, 1)   0.3777    0.6062 0.0523 (1, 0)â†’0.378               â†’(2, 1):0.606\n",
      "(2, 0)   0.3867    0.5978 0.0446 (1, 0)â†’0.387               â†’(3, 0):0.598\n",
      "(3, 0)   0.5978    1.0000 0.1617 (2, 0)â†’0.598                       R:1.0\n",
      "(0, 2)   0.4155    0.4411 0.0007 (0, 1)â†’0.415               â†’(1, 2):0.441\n",
      "(1, 0)   0.3611    0.7644 0.1627 (0, 0)â†’0.361 â†’(2, 0):0.387,â†’(1, 1):0.378\n",
      "\n",
      "Total Loss: 1.016507\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.3667    0.4005 0.0011 (0, 0)â†’0.367               â†’(0, 2):0.401\n",
      "(1, 2)   0.4304    0.5000 0.0048 (0, 2)â†’0.430                       R:0.5\n",
      "(2, 1)   0.5980    0.8000 0.0408 (1, 1)â†’0.598                       R:0.8\n",
      "(0, 0)   0.0000    0.7120 0.5070         none â†’(0, 1):0.367,â†’(1, 0):0.345\n",
      "(1, 1)   0.3628    0.5980 0.0553 (1, 0)â†’0.363               â†’(2, 1):0.598\n",
      "(2, 0)   0.3718    0.5968 0.0506 (1, 0)â†’0.372               â†’(3, 0):0.597\n",
      "(3, 0)   0.5968    1.0000 0.1626 (2, 0)â†’0.597                       R:1.0\n",
      "(0, 2)   0.4005    0.4304 0.0009 (0, 1)â†’0.401               â†’(1, 2):0.430\n",
      "(1, 0)   0.3454    0.7346 0.1515 (0, 0)â†’0.345 â†’(2, 0):0.372,â†’(1, 1):0.363\n",
      "\n",
      "Total Loss: 0.974676\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.3512    0.3859 0.0012 (0, 0)â†’0.351               â†’(0, 2):0.386\n",
      "(1, 2)   0.4203    0.5000 0.0063 (0, 2)â†’0.420                       R:0.5\n",
      "(2, 1)   0.5889    0.8000 0.0445 (1, 1)â†’0.589                       R:0.8\n",
      "(0, 0)   0.0000    0.6810 0.4637         none â†’(0, 1):0.351,â†’(1, 0):0.330\n",
      "(1, 1)   0.3482    0.5889 0.0580 (1, 0)â†’0.348               â†’(2, 1):0.589\n",
      "(2, 0)   0.3571    0.5960 0.0571 (1, 0)â†’0.357               â†’(3, 0):0.596\n",
      "(3, 0)   0.5960    1.0000 0.1632 (2, 0)â†’0.596                       R:1.0\n",
      "(0, 2)   0.3859    0.4203 0.0012 (0, 1)â†’0.386               â†’(1, 2):0.420\n",
      "(1, 0)   0.3298    0.7053 0.1410 (0, 0)â†’0.330 â†’(2, 0):0.357,â†’(1, 1):0.348\n",
      "\n",
      "Total Loss: 0.936267\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.3359    0.3717 0.0013 (0, 0)â†’0.336               â†’(0, 2):0.372\n",
      "(1, 2)   0.4109    0.5000 0.0079 (0, 2)â†’0.411                       R:0.5\n",
      "(2, 1)   0.5792    0.8000 0.0488 (1, 1)â†’0.579                       R:0.8\n",
      "(0, 0)   0.0000    0.6504 0.4230         none â†’(0, 1):0.336,â†’(1, 0):0.314\n",
      "(1, 1)   0.3339    0.5792 0.0602 (1, 0)â†’0.334               â†’(2, 1):0.579\n",
      "(2, 0)   0.3429    0.5956 0.0639 (1, 0)â†’0.343               â†’(3, 0):0.596\n",
      "(3, 0)   0.5956    1.0000 0.1635 (2, 0)â†’0.596                       R:1.0\n",
      "(0, 2)   0.3717    0.4109 0.0015 (0, 1)â†’0.372               â†’(1, 2):0.411\n",
      "(1, 0)   0.3144    0.6768 0.1313 (0, 0)â†’0.314 â†’(2, 0):0.343,â†’(1, 1):0.334\n",
      "\n",
      "Total Loss: 0.901379\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.3210    0.3584 0.0014 (0, 0)â†’0.321               â†’(0, 2):0.358\n",
      "(1, 2)   0.4021    0.5000 0.0096 (0, 2)â†’0.402                       R:0.5\n",
      "(2, 1)   0.5690    0.8000 0.0534 (1, 1)â†’0.569                       R:0.8\n",
      "(0, 0)   0.0000    0.6205 0.3850         none â†’(0, 1):0.321,â†’(1, 0):0.299\n",
      "(1, 1)   0.3201    0.5690 0.0619 (1, 0)â†’0.320               â†’(2, 1):0.569\n",
      "(2, 0)   0.3290    0.5956 0.0711 (1, 0)â†’0.329               â†’(3, 0):0.596\n",
      "(3, 0)   0.5956    1.0000 0.1635 (2, 0)â†’0.596                       R:1.0\n",
      "(0, 2)   0.3584    0.4021 0.0019 (0, 1)â†’0.358               â†’(1, 2):0.402\n",
      "(1, 0)   0.2995    0.6492 0.1223 (0, 0)â†’0.299 â†’(2, 0):0.329,â†’(1, 1):0.320\n",
      "\n",
      "Total Loss: 0.870051\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.3063    0.3458 0.0016 (0, 0)â†’0.306               â†’(0, 2):0.346\n",
      "(1, 2)   0.3941    0.5000 0.0112 (0, 2)â†’0.394                       R:0.5\n",
      "(2, 1)   0.5586    0.8000 0.0583 (1, 1)â†’0.559                       R:0.8\n",
      "(0, 0)   0.0000    0.5913 0.3496         none â†’(0, 1):0.306,â†’(1, 0):0.285\n",
      "(1, 1)   0.3069    0.5586 0.0634 (1, 0)â†’0.307               â†’(2, 1):0.559\n",
      "(2, 0)   0.3158    0.5960 0.0785 (1, 0)â†’0.316               â†’(3, 0):0.596\n",
      "(3, 0)   0.5960    1.0000 0.1632 (2, 0)â†’0.596                       R:1.0\n",
      "(0, 2)   0.3458    0.3941 0.0023 (0, 1)â†’0.346               â†’(1, 2):0.394\n",
      "(1, 0)   0.2849    0.6226 0.1140 (0, 0)â†’0.285 â†’(2, 0):0.316,â†’(1, 1):0.307\n",
      "\n",
      "Total Loss: 0.842130\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.2918    0.3344 0.0018 (0, 0)â†’0.292               â†’(0, 2):0.334\n",
      "(1, 2)   0.3869    0.5000 0.0128 (0, 2)â†’0.387                       R:0.5\n",
      "(2, 1)   0.5479    0.8000 0.0635 (1, 1)â†’0.548                       R:0.8\n",
      "(0, 0)   0.0000    0.5626 0.3165         none â†’(0, 1):0.292,â†’(1, 0):0.271\n",
      "(1, 1)   0.2942    0.5479 0.0644 (1, 0)â†’0.294               â†’(2, 1):0.548\n",
      "(2, 0)   0.3031    0.5967 0.0863 (1, 0)â†’0.303               â†’(3, 0):0.597\n",
      "(3, 0)   0.5967    1.0000 0.1626 (2, 0)â†’0.597                       R:1.0\n",
      "(0, 2)   0.3344    0.3869 0.0028 (0, 1)â†’0.334               â†’(1, 2):0.387\n",
      "(1, 0)   0.2708    0.5972 0.1066 (0, 0)â†’0.271 â†’(2, 0):0.303,â†’(1, 1):0.294\n",
      "\n",
      "Total Loss: 0.817252\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.2778    0.3239 0.0021 (0, 0)â†’0.278               â†’(0, 2):0.324\n",
      "(1, 2)   0.3804    0.5000 0.0143 (0, 2)â†’0.380                       R:0.5\n",
      "(2, 1)   0.5376    0.8000 0.0689 (1, 1)â†’0.538                       R:0.8\n",
      "(0, 0)   0.0000    0.5348 0.2860         none â†’(0, 1):0.278,â†’(1, 0):0.257\n",
      "(1, 1)   0.2821    0.5376 0.0653 (1, 0)â†’0.282               â†’(2, 1):0.538\n",
      "(2, 0)   0.2910    0.5979 0.0942 (1, 0)â†’0.291               â†’(3, 0):0.598\n",
      "(3, 0)   0.5979    1.0000 0.1616 (2, 0)â†’0.598                       R:1.0\n",
      "(0, 2)   0.3239    0.3804 0.0032 (0, 1)â†’0.324               â†’(1, 2):0.380\n",
      "(1, 0)   0.2570    0.5730 0.0999 (0, 0)â†’0.257 â†’(2, 0):0.291,â†’(1, 1):0.282\n",
      "\n",
      "Total Loss: 0.795520\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.2643    0.3143 0.0025 (0, 0)â†’0.264               â†’(0, 2):0.314\n",
      "(1, 2)   0.3748    0.5000 0.0157 (0, 2)â†’0.375                       R:0.5\n",
      "(2, 1)   0.5282    0.8000 0.0739 (1, 1)â†’0.528                       R:0.8\n",
      "(0, 0)   0.0000    0.5081 0.2582         none â†’(0, 1):0.264,â†’(1, 0):0.244\n",
      "(1, 1)   0.2707    0.5282 0.0663 (1, 0)â†’0.271               â†’(2, 1):0.528\n",
      "(2, 0)   0.2796    0.5995 0.1024 (1, 0)â†’0.280               â†’(3, 0):0.600\n",
      "(3, 0)   0.5995    1.0000 0.1604 (2, 0)â†’0.600                       R:1.0\n",
      "(0, 2)   0.3143    0.3748 0.0037 (0, 1)â†’0.314               â†’(1, 2):0.375\n",
      "(1, 0)   0.2438    0.5502 0.0939 (0, 0)â†’0.244 â†’(2, 0):0.280,â†’(1, 1):0.271\n",
      "\n",
      "Total Loss: 0.776839\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.2513    0.3056 0.0029 (0, 0)â†’0.251               â†’(0, 2):0.306\n",
      "(1, 2)   0.3699    0.5000 0.0169 (0, 2)â†’0.370                       R:0.5\n",
      "(2, 1)   0.5200    0.8000 0.0784 (1, 1)â†’0.520                       R:0.8\n",
      "(0, 0)   0.0000    0.4826 0.2329         none â†’(0, 1):0.251,â†’(1, 0):0.231\n",
      "(1, 1)   0.2600    0.5200 0.0676 (1, 0)â†’0.260               â†’(2, 1):0.520\n",
      "(2, 0)   0.2690    0.6014 0.1105 (1, 0)â†’0.269               â†’(3, 0):0.601\n",
      "(3, 0)   0.6014    1.0000 0.1589 (2, 0)â†’0.601                       R:1.0\n",
      "(0, 2)   0.3056    0.3699 0.0041 (0, 1)â†’0.306               â†’(1, 2):0.370\n",
      "(1, 0)   0.2313    0.5289 0.0886 (0, 0)â†’0.231 â†’(2, 0):0.269,â†’(1, 1):0.260\n",
      "\n",
      "Total Loss: 0.760927\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "Step 40: Loss = 0.760927\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.2390    0.2978 0.0035 (0, 0)â†’0.239               â†’(0, 2):0.298\n",
      "(1, 2)   0.3658    0.5000 0.0180 (0, 2)â†’0.366                       R:0.5\n",
      "(2, 1)   0.5133    0.8000 0.0822 (1, 1)â†’0.513                       R:0.8\n",
      "(0, 0)   0.0000    0.4585 0.2102         none â†’(0, 1):0.239,â†’(1, 0):0.219\n",
      "(1, 1)   0.2500    0.5133 0.0693 (1, 0)â†’0.250               â†’(2, 1):0.513\n",
      "(2, 0)   0.2592    0.6036 0.1186 (1, 0)â†’0.259               â†’(3, 0):0.604\n",
      "(3, 0)   0.6036    1.0000 0.1571 (2, 0)â†’0.604                       R:1.0\n",
      "(0, 2)   0.2978    0.3658 0.0046 (0, 1)â†’0.298               â†’(1, 2):0.366\n",
      "(1, 0)   0.2195    0.5093 0.0840 (0, 0)â†’0.219 â†’(2, 0):0.259,â†’(1, 1):0.250\n",
      "\n",
      "Total Loss: 0.747507\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.2274    0.2908 0.0040 (0, 0)â†’0.227               â†’(0, 2):0.291\n",
      "(1, 2)   0.3625    0.5000 0.0189 (0, 2)â†’0.362                       R:0.5\n",
      "(2, 1)   0.5079    0.8000 0.0853 (1, 1)â†’0.508                       R:0.8\n",
      "(0, 0)   0.0000    0.4357 0.1898         none â†’(0, 1):0.227,â†’(1, 0):0.208\n",
      "(1, 1)   0.2408    0.5079 0.0713 (1, 0)â†’0.241               â†’(2, 1):0.508\n",
      "(2, 0)   0.2501    0.6060 0.1266 (1, 0)â†’0.250               â†’(3, 0):0.606\n",
      "(3, 0)   0.6060    1.0000 0.1553 (2, 0)â†’0.606                       R:1.0\n",
      "(0, 2)   0.2908    0.3625 0.0051 (0, 1)â†’0.291               â†’(1, 2):0.362\n",
      "(1, 0)   0.2083    0.4909 0.0799 (0, 0)â†’0.208 â†’(2, 0):0.250,â†’(1, 1):0.241\n",
      "\n",
      "Total Loss: 0.736324\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.2164    0.2847 0.0047 (0, 0)â†’0.216               â†’(0, 2):0.285\n",
      "(1, 2)   0.3598    0.5000 0.0196 (0, 2)â†’0.360                       R:0.5\n",
      "(2, 1)   0.5039    0.8000 0.0877 (1, 1)â†’0.504                       R:0.8\n",
      "(0, 0)   0.0000    0.4143 0.1717         none â†’(0, 1):0.216,â†’(1, 0):0.198\n",
      "(1, 1)   0.2322    0.5039 0.0738 (1, 0)â†’0.232               â†’(2, 1):0.504\n",
      "(2, 0)   0.2418    0.6085 0.1345 (1, 0)â†’0.242               â†’(3, 0):0.609\n",
      "(3, 0)   0.6085    1.0000 0.1532 (2, 0)â†’0.609                       R:1.0\n",
      "(0, 2)   0.2847    0.3598 0.0056 (0, 1)â†’0.285               â†’(1, 2):0.360\n",
      "(1, 0)   0.1979    0.4740 0.0762 (0, 0)â†’0.198 â†’(2, 0):0.242,â†’(1, 1):0.232\n",
      "\n",
      "Total Loss: 0.727081\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.2061    0.2794 0.0054 (0, 0)â†’0.206               â†’(0, 2):0.279\n",
      "(1, 2)   0.3579    0.5000 0.0202 (0, 2)â†’0.358                       R:0.5\n",
      "(2, 1)   0.5011    0.8000 0.0893 (1, 1)â†’0.501                       R:0.8\n",
      "(0, 0)   0.0000    0.3944 0.1555         none â†’(0, 1):0.206,â†’(1, 0):0.188\n",
      "(1, 1)   0.2243    0.5011 0.0766 (1, 0)â†’0.224               â†’(2, 1):0.501\n",
      "(2, 0)   0.2343    0.6112 0.1421 (1, 0)â†’0.234               â†’(3, 0):0.611\n",
      "(3, 0)   0.6112    1.0000 0.1511 (2, 0)â†’0.611                       R:1.0\n",
      "(0, 2)   0.2794    0.3579 0.0062 (0, 1)â†’0.279               â†’(1, 2):0.358\n",
      "(1, 0)   0.1882    0.4586 0.0731 (0, 0)â†’0.188 â†’(2, 0):0.234,â†’(1, 1):0.224\n",
      "\n",
      "Total Loss: 0.719530\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1966    0.2746 0.0061 (0, 0)â†’0.197               â†’(0, 2):0.275\n",
      "(1, 2)   0.3566    0.5000 0.0206 (0, 2)â†’0.357                       R:0.5\n",
      "(2, 1)   0.4994    0.8000 0.0903 (1, 1)â†’0.499                       R:0.8\n",
      "(0, 0)   0.0000    0.3758 0.1412         none â†’(0, 1):0.197,â†’(1, 0):0.179\n",
      "(1, 1)   0.2173    0.4994 0.0796 (1, 0)â†’0.217               â†’(2, 1):0.499\n",
      "(2, 0)   0.2277    0.6139 0.1492 (1, 0)â†’0.228               â†’(3, 0):0.614\n",
      "(3, 0)   0.6139    1.0000 0.1490 (2, 0)â†’0.614                       R:1.0\n",
      "(0, 2)   0.2746    0.3566 0.0067 (0, 1)â†’0.275               â†’(1, 2):0.357\n",
      "(1, 0)   0.1792    0.4449 0.0706 (0, 0)â†’0.179 â†’(2, 0):0.228,â†’(1, 1):0.217\n",
      "\n",
      "Total Loss: 0.713406\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1877    0.2704 0.0068 (0, 0)â†’0.188               â†’(0, 2):0.270\n",
      "(1, 2)   0.3560    0.5000 0.0207 (0, 2)â†’0.356                       R:0.5\n",
      "(2, 1)   0.4985    0.8000 0.0909 (1, 1)â†’0.498                       R:0.8\n",
      "(0, 0)   0.0000    0.3586 0.1286         none â†’(0, 1):0.188,â†’(1, 0):0.171\n",
      "(1, 1)   0.2110    0.4985 0.0827 (1, 0)â†’0.211               â†’(2, 1):0.498\n",
      "(2, 0)   0.2219    0.6164 0.1557 (1, 0)â†’0.222               â†’(3, 0):0.616\n",
      "(3, 0)   0.6164    1.0000 0.1471 (2, 0)â†’0.616                       R:1.0\n",
      "(0, 2)   0.2704    0.3560 0.0073 (0, 1)â†’0.270               â†’(1, 2):0.356\n",
      "(1, 0)   0.1709    0.4329 0.0686 (0, 0)â†’0.171 â†’(2, 0):0.222,â†’(1, 1):0.211\n",
      "\n",
      "Total Loss: 0.708481\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1794    0.2667 0.0076 (0, 0)â†’0.179               â†’(0, 2):0.267\n",
      "(1, 2)   0.3561    0.5000 0.0207 (0, 2)â†’0.356                       R:0.5\n",
      "(2, 1)   0.4981    0.8000 0.0911 (1, 1)â†’0.498                       R:0.8\n",
      "(0, 0)   0.0000    0.3428 0.1175         none â†’(0, 1):0.179,â†’(1, 0):0.163\n",
      "(1, 1)   0.2055    0.4981 0.0856 (1, 0)â†’0.205               â†’(2, 1):0.498\n",
      "(2, 0)   0.2169    0.6184 0.1612 (1, 0)â†’0.217               â†’(3, 0):0.618\n",
      "(3, 0)   0.6184    1.0000 0.1456 (2, 0)â†’0.618                       R:1.0\n",
      "(0, 2)   0.2667    0.3561 0.0080 (0, 1)â†’0.267               â†’(1, 2):0.356\n",
      "(1, 0)   0.1634    0.4224 0.0671 (0, 0)â†’0.163 â†’(2, 0):0.217,â†’(1, 1):0.205\n",
      "\n",
      "Total Loss: 0.704495\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1717    0.2633 0.0084 (0, 0)â†’0.172               â†’(0, 2):0.263\n",
      "(1, 2)   0.3567    0.5000 0.0205 (0, 2)â†’0.357                       R:0.5\n",
      "(2, 1)   0.4981    0.8000 0.0912 (1, 1)â†’0.498                       R:0.8\n",
      "(0, 0)   0.0000    0.3282 0.1077         none â†’(0, 1):0.172,â†’(1, 0):0.156\n",
      "(1, 1)   0.2007    0.4981 0.0885 (1, 0)â†’0.201               â†’(2, 1):0.498\n",
      "(2, 0)   0.2127    0.6199 0.1658 (1, 0)â†’0.213               â†’(3, 0):0.620\n",
      "(3, 0)   0.6199    1.0000 0.1445 (2, 0)â†’0.620                       R:1.0\n",
      "(0, 2)   0.2633    0.3567 0.0087 (0, 1)â†’0.263               â†’(1, 2):0.357\n",
      "(1, 0)   0.1564    0.4133 0.0660 (0, 0)â†’0.156 â†’(2, 0):0.213,â†’(1, 1):0.201\n",
      "\n",
      "Total Loss: 0.701255\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1647    0.2604 0.0092 (0, 0)â†’0.165               â†’(0, 2):0.260\n",
      "(1, 2)   0.3578    0.5000 0.0202 (0, 2)â†’0.358                       R:0.5\n",
      "(2, 1)   0.4983    0.8000 0.0910 (1, 1)â†’0.498                       R:0.8\n",
      "(0, 0)   0.0000    0.3147 0.0990         none â†’(0, 1):0.165,â†’(1, 0):0.150\n",
      "(1, 1)   0.1965    0.4983 0.0911 (1, 0)â†’0.197               â†’(2, 1):0.498\n",
      "(2, 0)   0.2092    0.6207 0.1693 (1, 0)â†’0.209               â†’(3, 0):0.621\n",
      "(3, 0)   0.6207    1.0000 0.1439 (2, 0)â†’0.621                       R:1.0\n",
      "(0, 2)   0.2604    0.3578 0.0095 (0, 1)â†’0.260               â†’(1, 2):0.358\n",
      "(1, 0)   0.1500    0.4057 0.0654 (0, 0)â†’0.150 â†’(2, 0):0.209,â†’(1, 1):0.197\n",
      "\n",
      "Total Loss: 0.698582\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1582    0.2579 0.0099 (0, 0)â†’0.158               â†’(0, 2):0.258\n",
      "(1, 2)   0.3593    0.5000 0.0198 (0, 2)â†’0.359                       R:0.5\n",
      "(2, 1)   0.4985    0.8000 0.0909 (1, 1)â†’0.498                       R:0.8\n",
      "(0, 0)   0.0000    0.3024 0.0915         none â†’(0, 1):0.158,â†’(1, 0):0.144\n",
      "(1, 1)   0.1930    0.4985 0.0933 (1, 0)â†’0.193               â†’(2, 1):0.498\n",
      "(2, 0)   0.2064    0.6209 0.1718 (1, 0)â†’0.206               â†’(3, 0):0.621\n",
      "(3, 0)   0.6209    1.0000 0.1437 (2, 0)â†’0.621                       R:1.0\n",
      "(0, 2)   0.2579    0.3593 0.0103 (0, 1)â†’0.258               â†’(1, 2):0.359\n",
      "(1, 0)   0.1442    0.3994 0.0651 (0, 0)â†’0.144 â†’(2, 0):0.206,â†’(1, 1):0.193\n",
      "\n",
      "Total Loss: 0.696352\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1524    0.2556 0.0107 (0, 0)â†’0.152               â†’(0, 2):0.256\n",
      "(1, 2)   0.3612    0.5000 0.0193 (0, 2)â†’0.361                       R:0.5\n",
      "(2, 1)   0.4985    0.8000 0.0909 (1, 1)â†’0.498                       R:0.8\n",
      "(0, 0)   0.0000    0.2913 0.0848         none â†’(0, 1):0.152,â†’(1, 0):0.139\n",
      "(1, 1)   0.1902    0.4985 0.0950 (1, 0)â†’0.190               â†’(2, 1):0.498\n",
      "(2, 0)   0.2042    0.6202 0.1730 (1, 0)â†’0.204               â†’(3, 0):0.620\n",
      "(3, 0)   0.6202    1.0000 0.1443 (2, 0)â†’0.620                       R:1.0\n",
      "(0, 2)   0.2556    0.3612 0.0112 (0, 1)â†’0.256               â†’(1, 2):0.361\n",
      "(1, 0)   0.1389    0.3944 0.0653 (0, 0)â†’0.139 â†’(2, 0):0.204,â†’(1, 1):0.190\n",
      "\n",
      "Total Loss: 0.694435\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1470    0.2537 0.0114 (0, 0)â†’0.147               â†’(0, 2):0.254\n",
      "(1, 2)   0.3634    0.5000 0.0187 (0, 2)â†’0.363                       R:0.5\n",
      "(2, 1)   0.4981    0.8000 0.0912 (1, 1)â†’0.498                       R:0.8\n",
      "(0, 0)   0.0000    0.2812 0.0791         none â†’(0, 1):0.147,â†’(1, 0):0.134\n",
      "(1, 1)   0.1878    0.4981 0.0963 (1, 0)â†’0.188               â†’(2, 1):0.498\n",
      "(2, 0)   0.2027    0.6188 0.1731 (1, 0)â†’0.203               â†’(3, 0):0.619\n",
      "(3, 0)   0.6188    1.0000 0.1453 (2, 0)â†’0.619                       R:1.0\n",
      "(0, 2)   0.2537    0.3634 0.0120 (0, 1)â†’0.254               â†’(1, 2):0.363\n",
      "(1, 0)   0.1342    0.3905 0.0657 (0, 0)â†’0.134 â†’(2, 0):0.203,â†’(1, 1):0.188\n",
      "\n",
      "Total Loss: 0.692736\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1422    0.2522 0.0121 (0, 0)â†’0.142               â†’(0, 2):0.252\n",
      "(1, 2)   0.3657    0.5000 0.0180 (0, 2)â†’0.366                       R:0.5\n",
      "(2, 1)   0.4973    0.8000 0.0916 (1, 1)â†’0.497                       R:0.8\n",
      "(0, 0)   0.0000    0.2720 0.0740         none â†’(0, 1):0.142,â†’(1, 0):0.130\n",
      "(1, 1)   0.1860    0.4973 0.0969 (1, 0)â†’0.186               â†’(2, 1):0.497\n",
      "(2, 0)   0.2017    0.6168 0.1723 (1, 0)â†’0.202               â†’(3, 0):0.617\n",
      "(3, 0)   0.6168    1.0000 0.1469 (2, 0)â†’0.617                       R:1.0\n",
      "(0, 2)   0.2522    0.3657 0.0129 (0, 1)â†’0.252               â†’(1, 2):0.366\n",
      "(1, 0)   0.1299    0.3877 0.0665 (0, 0)â†’0.130 â†’(2, 0):0.202,â†’(1, 1):0.186\n",
      "\n",
      "Total Loss: 0.691203\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1378    0.2511 0.0128 (0, 0)â†’0.138               â†’(0, 2):0.251\n",
      "(1, 2)   0.3681    0.5000 0.0174 (0, 2)â†’0.368                       R:0.5\n",
      "(2, 1)   0.4959    0.8000 0.0925 (1, 1)â†’0.496                       R:0.8\n",
      "(0, 0)   0.0000    0.2638 0.0696         none â†’(0, 1):0.138,â†’(1, 0):0.126\n",
      "(1, 1)   0.1846    0.4959 0.0969 (1, 0)â†’0.185               â†’(2, 1):0.496\n",
      "(2, 0)   0.2011    0.6142 0.1707 (1, 0)â†’0.201               â†’(3, 0):0.614\n",
      "(3, 0)   0.6142    1.0000 0.1488 (2, 0)â†’0.614                       R:1.0\n",
      "(0, 2)   0.2511    0.3681 0.0137 (0, 1)â†’0.251               â†’(1, 2):0.368\n",
      "(1, 0)   0.1260    0.3857 0.0674 (0, 0)â†’0.126 â†’(2, 0):0.201,â†’(1, 1):0.185\n",
      "\n",
      "Total Loss: 0.689847\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1339    0.2504 0.0136 (0, 0)â†’0.134               â†’(0, 2):0.250\n",
      "(1, 2)   0.3706    0.5000 0.0167 (0, 2)â†’0.371                       R:0.5\n",
      "(2, 1)   0.4943    0.8000 0.0935 (1, 1)â†’0.494                       R:0.8\n",
      "(0, 0)   0.0000    0.2565 0.0658         none â†’(0, 1):0.134,â†’(1, 0):0.123\n",
      "(1, 1)   0.1836    0.4943 0.0965 (1, 0)â†’0.184               â†’(2, 1):0.494\n",
      "(2, 0)   0.2010    0.6114 0.1684 (1, 0)â†’0.201               â†’(3, 0):0.611\n",
      "(3, 0)   0.6114    1.0000 0.1510 (2, 0)â†’0.611                       R:1.0\n",
      "(0, 2)   0.2504    0.3706 0.0145 (0, 1)â†’0.250               â†’(1, 2):0.371\n",
      "(1, 0)   0.1226    0.3847 0.0687 (0, 0)â†’0.123 â†’(2, 0):0.201,â†’(1, 1):0.184\n",
      "\n",
      "Total Loss: 0.688616\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1304    0.2500 0.0143 (0, 0)â†’0.130               â†’(0, 2):0.250\n",
      "(1, 2)   0.3731    0.5000 0.0161 (0, 2)â†’0.373                       R:0.5\n",
      "(2, 1)   0.4926    0.8000 0.0945 (1, 1)â†’0.493                       R:0.8\n",
      "(0, 0)   0.0000    0.2500 0.0625         none â†’(0, 1):0.130,â†’(1, 0):0.120\n",
      "(1, 1)   0.1831    0.4926 0.0958 (1, 0)â†’0.183               â†’(2, 1):0.493\n",
      "(2, 0)   0.2014    0.6083 0.1656 (1, 0)â†’0.201               â†’(3, 0):0.608\n",
      "(3, 0)   0.6083    1.0000 0.1534 (2, 0)â†’0.608                       R:1.0\n",
      "(0, 2)   0.2500    0.3731 0.0151 (0, 1)â†’0.250               â†’(1, 2):0.373\n",
      "(1, 0)   0.1196    0.3845 0.0702 (0, 0)â†’0.120 â†’(2, 0):0.201,â†’(1, 1):0.183\n",
      "\n",
      "Total Loss: 0.687521\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1273    0.2501 0.0151 (0, 0)â†’0.127               â†’(0, 2):0.250\n",
      "(1, 2)   0.3755    0.5000 0.0155 (0, 2)â†’0.375                       R:0.5\n",
      "(2, 1)   0.4910    0.8000 0.0955 (1, 1)â†’0.491                       R:0.8\n",
      "(0, 0)   0.0000    0.2442 0.0596         none â†’(0, 1):0.127,â†’(1, 0):0.117\n",
      "(1, 1)   0.1831    0.4910 0.0948 (1, 0)â†’0.183               â†’(2, 1):0.491\n",
      "(2, 0)   0.2022    0.6052 0.1624 (1, 0)â†’0.202               â†’(3, 0):0.605\n",
      "(3, 0)   0.6052    1.0000 0.1559 (2, 0)â†’0.605                       R:1.0\n",
      "(0, 2)   0.2501    0.3755 0.0157 (0, 1)â†’0.250               â†’(1, 2):0.375\n",
      "(1, 0)   0.1169    0.3853 0.0720 (0, 0)â†’0.117 â†’(2, 0):0.202,â†’(1, 1):0.183\n",
      "\n",
      "Total Loss: 0.686531\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1245    0.2504 0.0158 (0, 0)â†’0.124               â†’(0, 2):0.250\n",
      "(1, 2)   0.3777    0.5000 0.0149 (0, 2)â†’0.378                       R:0.5\n",
      "(2, 1)   0.4897    0.8000 0.0963 (1, 1)â†’0.490                       R:0.8\n",
      "(0, 0)   0.0000    0.2390 0.0571         none â†’(0, 1):0.124,â†’(1, 0):0.115\n",
      "(1, 1)   0.1834    0.4897 0.0938 (1, 0)â†’0.183               â†’(2, 1):0.490\n",
      "(2, 0)   0.2035    0.6024 0.1591 (1, 0)â†’0.204               â†’(3, 0):0.602\n",
      "(3, 0)   0.6024    1.0000 0.1581 (2, 0)â†’0.602                       R:1.0\n",
      "(0, 2)   0.2504    0.3777 0.0162 (0, 1)â†’0.250               â†’(1, 2):0.378\n",
      "(1, 0)   0.1146    0.3870 0.0742 (0, 0)â†’0.115 â†’(2, 0):0.204,â†’(1, 1):0.183\n",
      "\n",
      "Total Loss: 0.685627\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1220    0.2510 0.0166 (0, 0)â†’0.122               â†’(0, 2):0.251\n",
      "(1, 2)   0.3799    0.5000 0.0144 (0, 2)â†’0.380                       R:0.5\n",
      "(2, 1)   0.4890    0.8000 0.0967 (1, 1)â†’0.489                       R:0.8\n",
      "(0, 0)   0.0000    0.2346 0.0550         none â†’(0, 1):0.122,â†’(1, 0):0.113\n",
      "(1, 1)   0.1841    0.4890 0.0929 (1, 0)â†’0.184               â†’(2, 1):0.489\n",
      "(2, 0)   0.2052    0.6000 0.1558 (1, 0)â†’0.205               â†’(3, 0):0.600\n",
      "(3, 0)   0.6000    1.0000 0.1600 (2, 0)â†’0.600                       R:1.0\n",
      "(0, 2)   0.2510    0.3799 0.0166 (0, 1)â†’0.251               â†’(1, 2):0.380\n",
      "(1, 0)   0.1126    0.3894 0.0766 (0, 0)â†’0.113 â†’(2, 0):0.205,â†’(1, 1):0.184\n",
      "\n",
      "Total Loss: 0.684827\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1198    0.2517 0.0174 (0, 0)â†’0.120               â†’(0, 2):0.252\n",
      "(1, 2)   0.3818    0.5000 0.0140 (0, 2)â†’0.382                       R:0.5\n",
      "(2, 1)   0.4889    0.8000 0.0968 (1, 1)â†’0.489                       R:0.8\n",
      "(0, 0)   0.0000    0.2307 0.0532         none â†’(0, 1):0.120,â†’(1, 0):0.111\n",
      "(1, 1)   0.1851    0.4889 0.0923 (1, 0)â†’0.185               â†’(2, 1):0.489\n",
      "(2, 0)   0.2072    0.5980 0.1528 (1, 0)â†’0.207               â†’(3, 0):0.598\n",
      "(3, 0)   0.5980    1.0000 0.1616 (2, 0)â†’0.598                       R:1.0\n",
      "(0, 2)   0.2517    0.3818 0.0169 (0, 1)â†’0.252               â†’(1, 2):0.382\n",
      "(1, 0)   0.1108    0.3923 0.0792 (0, 0)â†’0.111 â†’(2, 0):0.207,â†’(1, 1):0.185\n",
      "\n",
      "Total Loss: 0.684121\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "Step 60: Loss = 0.684121\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1179    0.2524 0.0181 (0, 0)â†’0.118               â†’(0, 2):0.252\n",
      "(1, 2)   0.3835    0.5000 0.0136 (0, 2)â†’0.383                       R:0.5\n",
      "(2, 1)   0.4894    0.8000 0.0965 (1, 1)â†’0.489                       R:0.8\n",
      "(0, 0)   0.0000    0.2273 0.0516         none â†’(0, 1):0.118,â†’(1, 0):0.109\n",
      "(1, 1)   0.1863    0.4894 0.0919 (1, 0)â†’0.186               â†’(2, 1):0.489\n",
      "(2, 0)   0.2094    0.5967 0.1500 (1, 0)â†’0.209               â†’(3, 0):0.597\n",
      "(3, 0)   0.5967    1.0000 0.1626 (2, 0)â†’0.597                       R:1.0\n",
      "(0, 2)   0.2524    0.3835 0.0172 (0, 1)â†’0.252               â†’(1, 2):0.383\n",
      "(1, 0)   0.1094    0.3958 0.0820 (0, 0)â†’0.109 â†’(2, 0):0.209,â†’(1, 1):0.186\n",
      "\n",
      "Total Loss: 0.683473\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1162    0.2530 0.0187 (0, 0)â†’0.116               â†’(0, 2):0.253\n",
      "(1, 2)   0.3850    0.5000 0.0132 (0, 2)â†’0.385                       R:0.5\n",
      "(2, 1)   0.4906    0.8000 0.0957 (1, 1)â†’0.491                       R:0.8\n",
      "(0, 0)   0.0000    0.2243 0.0503         none â†’(0, 1):0.116,â†’(1, 0):0.108\n",
      "(1, 1)   0.1877    0.4906 0.0917 (1, 0)â†’0.188               â†’(2, 1):0.491\n",
      "(2, 0)   0.2119    0.5961 0.1476 (1, 0)â†’0.212               â†’(3, 0):0.596\n",
      "(3, 0)   0.5961    1.0000 0.1631 (2, 0)â†’0.596                       R:1.0\n",
      "(0, 2)   0.2530    0.3850 0.0174 (0, 1)â†’0.253               â†’(1, 2):0.385\n",
      "(1, 0)   0.1081    0.3996 0.0850 (0, 0)â†’0.108 â†’(2, 0):0.212,â†’(1, 1):0.188\n",
      "\n",
      "Total Loss: 0.682866\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1147    0.2534 0.0192 (0, 0)â†’0.115               â†’(0, 2):0.253\n",
      "(1, 2)   0.3862    0.5000 0.0130 (0, 2)â†’0.386                       R:0.5\n",
      "(2, 1)   0.4923    0.8000 0.0947 (1, 1)â†’0.492                       R:0.8\n",
      "(0, 0)   0.0000    0.2219 0.0492         none â†’(0, 1):0.115,â†’(1, 0):0.107\n",
      "(1, 1)   0.1893    0.4923 0.0918 (1, 0)â†’0.189               â†’(2, 1):0.492\n",
      "(2, 0)   0.2145    0.5962 0.1457 (1, 0)â†’0.215               â†’(3, 0):0.596\n",
      "(3, 0)   0.5962    1.0000 0.1630 (2, 0)â†’0.596                       R:1.0\n",
      "(0, 2)   0.2534    0.3862 0.0176 (0, 1)â†’0.253               â†’(1, 2):0.386\n",
      "(1, 0)   0.1071    0.4038 0.0880 (0, 0)â†’0.107 â†’(2, 0):0.215,â†’(1, 1):0.189\n",
      "\n",
      "Total Loss: 0.682285\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1135    0.2535 0.0196 (0, 0)â†’0.113               â†’(0, 2):0.254\n",
      "(1, 2)   0.3871    0.5000 0.0127 (0, 2)â†’0.387                       R:0.5\n",
      "(2, 1)   0.4943    0.8000 0.0934 (1, 1)â†’0.494                       R:0.8\n",
      "(0, 0)   0.0000    0.2198 0.0483         none â†’(0, 1):0.113,â†’(1, 0):0.106\n",
      "(1, 1)   0.1909    0.4943 0.0920 (1, 0)â†’0.191               â†’(2, 1):0.494\n",
      "(2, 0)   0.2173    0.5970 0.1442 (1, 0)â†’0.217               â†’(3, 0):0.597\n",
      "(3, 0)   0.5970    1.0000 0.1624 (2, 0)â†’0.597                       R:1.0\n",
      "(0, 2)   0.2535    0.3871 0.0178 (0, 1)â†’0.254               â†’(1, 2):0.387\n",
      "(1, 0)   0.1063    0.4083 0.0912 (0, 0)â†’0.106 â†’(2, 0):0.217,â†’(1, 1):0.191\n",
      "\n",
      "Total Loss: 0.681726\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1124    0.2534 0.0199 (0, 0)â†’0.112               â†’(0, 2):0.253\n",
      "(1, 2)   0.3879    0.5000 0.0126 (0, 2)â†’0.388                       R:0.5\n",
      "(2, 1)   0.4965    0.8000 0.0921 (1, 1)â†’0.496                       R:0.8\n",
      "(0, 0)   0.0000    0.2180 0.0475         none â†’(0, 1):0.112,â†’(1, 0):0.106\n",
      "(1, 1)   0.1927    0.4965 0.0923 (1, 0)â†’0.193               â†’(2, 1):0.496\n",
      "(2, 0)   0.2201    0.5985 0.1432 (1, 0)â†’0.220               â†’(3, 0):0.598\n",
      "(3, 0)   0.5985    1.0000 0.1612 (2, 0)â†’0.598                       R:1.0\n",
      "(0, 2)   0.2534    0.3879 0.0181 (0, 1)â†’0.253               â†’(1, 2):0.388\n",
      "(1, 0)   0.1057    0.4129 0.0944 (0, 0)â†’0.106 â†’(2, 0):0.220,â†’(1, 1):0.193\n",
      "\n",
      "Total Loss: 0.681207\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1114    0.2531 0.0201 (0, 0)â†’0.111               â†’(0, 2):0.253\n",
      "(1, 2)   0.3885    0.5000 0.0124 (0, 2)â†’0.388                       R:0.5\n",
      "(2, 1)   0.4986    0.8000 0.0909 (1, 1)â†’0.499                       R:0.8\n",
      "(0, 0)   0.0000    0.2166 0.0469         none â†’(0, 1):0.111,â†’(1, 0):0.105\n",
      "(1, 1)   0.1945    0.4986 0.0925 (1, 0)â†’0.194               â†’(2, 1):0.499\n",
      "(2, 0)   0.2229    0.6005 0.1426 (1, 0)â†’0.223               â†’(3, 0):0.601\n",
      "(3, 0)   0.6005    1.0000 0.1596 (2, 0)â†’0.601                       R:1.0\n",
      "(0, 2)   0.2531    0.3885 0.0183 (0, 1)â†’0.253               â†’(1, 2):0.388\n",
      "(1, 0)   0.1052    0.4174 0.0974 (0, 0)â†’0.105 â†’(2, 0):0.223,â†’(1, 1):0.194\n",
      "\n",
      "Total Loss: 0.680727\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1106    0.2525 0.0201 (0, 0)â†’0.111               â†’(0, 2):0.253\n",
      "(1, 2)   0.3886    0.5000 0.0124 (0, 2)â†’0.389                       R:0.5\n",
      "(2, 1)   0.5005    0.8000 0.0897 (1, 1)â†’0.500                       R:0.8\n",
      "(0, 0)   0.0000    0.2155 0.0464         none â†’(0, 1):0.111,â†’(1, 0):0.105\n",
      "(1, 1)   0.1962    0.5005 0.0926 (1, 0)â†’0.196               â†’(2, 1):0.500\n",
      "(2, 0)   0.2257    0.6030 0.1424 (1, 0)â†’0.226               â†’(3, 0):0.603\n",
      "(3, 0)   0.6030    1.0000 0.1576 (2, 0)â†’0.603                       R:1.0\n",
      "(0, 2)   0.2525    0.3886 0.0185 (0, 1)â†’0.253               â†’(1, 2):0.389\n",
      "(1, 0)   0.1049    0.4219 0.1005 (0, 0)â†’0.105 â†’(2, 0):0.226,â†’(1, 1):0.196\n",
      "\n",
      "Total Loss: 0.680261\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1099    0.2517 0.0201 (0, 0)â†’0.110               â†’(0, 2):0.252\n",
      "(1, 2)   0.3883    0.5000 0.0125 (0, 2)â†’0.388                       R:0.5\n",
      "(2, 1)   0.5019    0.8000 0.0889 (1, 1)â†’0.502                       R:0.8\n",
      "(0, 0)   0.0000    0.2146 0.0460         none â†’(0, 1):0.110,â†’(1, 0):0.105\n",
      "(1, 1)   0.1979    0.5019 0.0924 (1, 0)â†’0.198               â†’(2, 1):0.502\n",
      "(2, 0)   0.2285    0.6059 0.1424 (1, 0)â†’0.228               â†’(3, 0):0.606\n",
      "(3, 0)   0.6059    1.0000 0.1553 (2, 0)â†’0.606                       R:1.0\n",
      "(0, 2)   0.2517    0.3883 0.0187 (0, 1)â†’0.252               â†’(1, 2):0.388\n",
      "(1, 0)   0.1047    0.4264 0.1035 (0, 0)â†’0.105 â†’(2, 0):0.228,â†’(1, 1):0.198\n",
      "\n",
      "Total Loss: 0.679819\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1093    0.2508 0.0200 (0, 0)â†’0.109               â†’(0, 2):0.251\n",
      "(1, 2)   0.3878    0.5000 0.0126 (0, 2)â†’0.388                       R:0.5\n",
      "(2, 1)   0.5029    0.8000 0.0883 (1, 1)â†’0.503                       R:0.8\n",
      "(0, 0)   0.0000    0.2139 0.0458         none â†’(0, 1):0.109,â†’(1, 0):0.105\n",
      "(1, 1)   0.1994    0.5029 0.0921 (1, 0)â†’0.199               â†’(2, 1):0.503\n",
      "(2, 0)   0.2313    0.6089 0.1426 (1, 0)â†’0.231               â†’(3, 0):0.609\n",
      "(3, 0)   0.6089    1.0000 0.1529 (2, 0)â†’0.609                       R:1.0\n",
      "(0, 2)   0.2508    0.3878 0.0188 (0, 1)â†’0.251               â†’(1, 2):0.388\n",
      "(1, 0)   0.1046    0.4307 0.1064 (0, 0)â†’0.105 â†’(2, 0):0.231,â†’(1, 1):0.199\n",
      "\n",
      "Total Loss: 0.679397\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1089    0.2497 0.0198 (0, 0)â†’0.109               â†’(0, 2):0.250\n",
      "(1, 2)   0.3869    0.5000 0.0128 (0, 2)â†’0.387                       R:0.5\n",
      "(2, 1)   0.5034    0.8000 0.0880 (1, 1)â†’0.503                       R:0.8\n",
      "(0, 0)   0.0000    0.2135 0.0456         none â†’(0, 1):0.109,â†’(1, 0):0.105\n",
      "(1, 1)   0.2008    0.5034 0.0915 (1, 0)â†’0.201               â†’(2, 1):0.503\n",
      "(2, 0)   0.2340    0.6121 0.1430 (1, 0)â†’0.234               â†’(3, 0):0.612\n",
      "(3, 0)   0.6121    1.0000 0.1505 (2, 0)â†’0.612                       R:1.0\n",
      "(0, 2)   0.2497    0.3869 0.0188 (0, 1)â†’0.250               â†’(1, 2):0.387\n",
      "(1, 0)   0.1046    0.4348 0.1090 (0, 0)â†’0.105 â†’(2, 0):0.234,â†’(1, 1):0.201\n",
      "\n",
      "Total Loss: 0.679006\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1084    0.2485 0.0196 (0, 0)â†’0.108               â†’(0, 2):0.249\n",
      "(1, 2)   0.3857    0.5000 0.0131 (0, 2)â†’0.386                       R:0.5\n",
      "(2, 1)   0.5035    0.8000 0.0879 (1, 1)â†’0.503                       R:0.8\n",
      "(0, 0)   0.0000    0.2132 0.0454         none â†’(0, 1):0.108,â†’(1, 0):0.105\n",
      "(1, 1)   0.2021    0.5035 0.0908 (1, 0)â†’0.202               â†’(2, 1):0.503\n",
      "(2, 0)   0.2365    0.6152 0.1434 (1, 0)â†’0.237               â†’(3, 0):0.615\n",
      "(3, 0)   0.6152    1.0000 0.1480 (2, 0)â†’0.615                       R:1.0\n",
      "(0, 2)   0.2485    0.3857 0.0188 (0, 1)â†’0.249               â†’(1, 2):0.386\n",
      "(1, 0)   0.1048    0.4386 0.1115 (0, 0)â†’0.105 â†’(2, 0):0.237,â†’(1, 1):0.202\n",
      "\n",
      "Total Loss: 0.678641\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1080    0.2473 0.0194 (0, 0)â†’0.108               â†’(0, 2):0.247\n",
      "(1, 2)   0.3842    0.5000 0.0134 (0, 2)â†’0.384                       R:0.5\n",
      "(2, 1)   0.5032    0.8000 0.0881 (1, 1)â†’0.503                       R:0.8\n",
      "(0, 0)   0.0000    0.2130 0.0454         none â†’(0, 1):0.108,â†’(1, 0):0.105\n",
      "(1, 1)   0.2032    0.5032 0.0900 (1, 0)â†’0.203               â†’(2, 1):0.503\n",
      "(2, 0)   0.2390    0.6183 0.1439 (1, 0)â†’0.239               â†’(3, 0):0.618\n",
      "(3, 0)   0.6183    1.0000 0.1457 (2, 0)â†’0.618                       R:1.0\n",
      "(0, 2)   0.2473    0.3842 0.0187 (0, 1)â†’0.247               â†’(1, 2):0.384\n",
      "(1, 0)   0.1050    0.4421 0.1137 (0, 0)â†’0.105 â†’(2, 0):0.239,â†’(1, 1):0.203\n",
      "\n",
      "Total Loss: 0.678296\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1077    0.2460 0.0191 (0, 0)â†’0.108               â†’(0, 2):0.246\n",
      "(1, 2)   0.3825    0.5000 0.0138 (0, 2)â†’0.382                       R:0.5\n",
      "(2, 1)   0.5028    0.8000 0.0883 (1, 1)â†’0.503                       R:0.8\n",
      "(0, 0)   0.0000    0.2130 0.0453         none â†’(0, 1):0.108,â†’(1, 0):0.105\n",
      "(1, 1)   0.2041    0.5028 0.0892 (1, 0)â†’0.204               â†’(2, 1):0.503\n",
      "(2, 0)   0.2413    0.6210 0.1442 (1, 0)â†’0.241               â†’(3, 0):0.621\n",
      "(3, 0)   0.6210    1.0000 0.1436 (2, 0)â†’0.621                       R:1.0\n",
      "(0, 2)   0.2460    0.3825 0.0186 (0, 1)â†’0.246               â†’(1, 2):0.382\n",
      "(1, 0)   0.1053    0.4453 0.1157 (0, 0)â†’0.105 â†’(2, 0):0.241,â†’(1, 1):0.204\n",
      "\n",
      "Total Loss: 0.677974\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1074    0.2448 0.0189 (0, 0)â†’0.107               â†’(0, 2):0.245\n",
      "(1, 2)   0.3806    0.5000 0.0143 (0, 2)â†’0.381                       R:0.5\n",
      "(2, 1)   0.5023    0.8000 0.0886 (1, 1)â†’0.502                       R:0.8\n",
      "(0, 0)   0.0000    0.2130 0.0454         none â†’(0, 1):0.107,â†’(1, 0):0.106\n",
      "(1, 1)   0.2047    0.5023 0.0885 (1, 0)â†’0.205               â†’(2, 1):0.502\n",
      "(2, 0)   0.2434    0.6235 0.1445 (1, 0)â†’0.243               â†’(3, 0):0.623\n",
      "(3, 0)   0.6235    1.0000 0.1418 (2, 0)â†’0.623                       R:1.0\n",
      "(0, 2)   0.2448    0.3806 0.0185 (0, 1)â†’0.245               â†’(1, 2):0.381\n",
      "(1, 0)   0.1056    0.4482 0.1173 (0, 0)â†’0.106 â†’(2, 0):0.243,â†’(1, 1):0.205\n",
      "\n",
      "Total Loss: 0.677671\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1072    0.2435 0.0186 (0, 0)â†’0.107               â†’(0, 2):0.244\n",
      "(1, 2)   0.3786    0.5000 0.0147 (0, 2)â†’0.379                       R:0.5\n",
      "(2, 1)   0.5018    0.8000 0.0889 (1, 1)â†’0.502                       R:0.8\n",
      "(0, 0)   0.0000    0.2132 0.0455         none â†’(0, 1):0.107,â†’(1, 0):0.106\n",
      "(1, 1)   0.2052    0.5018 0.0880 (1, 0)â†’0.205               â†’(2, 1):0.502\n",
      "(2, 0)   0.2454    0.6256 0.1445 (1, 0)â†’0.245               â†’(3, 0):0.626\n",
      "(3, 0)   0.6256    1.0000 0.1402 (2, 0)â†’0.626                       R:1.0\n",
      "(0, 2)   0.2435    0.3786 0.0183 (0, 1)â†’0.244               â†’(1, 2):0.379\n",
      "(1, 0)   0.1060    0.4507 0.1188 (0, 0)â†’0.106 â†’(2, 0):0.245,â†’(1, 1):0.205\n",
      "\n",
      "Total Loss: 0.677383\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1070    0.2423 0.0183 (0, 0)â†’0.107               â†’(0, 2):0.242\n",
      "(1, 2)   0.3766    0.5000 0.0152 (0, 2)â†’0.377                       R:0.5\n",
      "(2, 1)   0.5015    0.8000 0.0891 (1, 1)â†’0.501                       R:0.8\n",
      "(0, 0)   0.0000    0.2135 0.0456         none â†’(0, 1):0.107,â†’(1, 0):0.107\n",
      "(1, 1)   0.2055    0.5015 0.0876 (1, 0)â†’0.206               â†’(2, 1):0.501\n",
      "(2, 0)   0.2473    0.6273 0.1444 (1, 0)â†’0.247               â†’(3, 0):0.627\n",
      "(3, 0)   0.6273    1.0000 0.1389 (2, 0)â†’0.627                       R:1.0\n",
      "(0, 2)   0.2423    0.3766 0.0180 (0, 1)â†’0.242               â†’(1, 2):0.377\n",
      "(1, 0)   0.1065    0.4529 0.1200 (0, 0)â†’0.107 â†’(2, 0):0.247,â†’(1, 1):0.206\n",
      "\n",
      "Total Loss: 0.677100\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1069    0.2412 0.0180 (0, 0)â†’0.107               â†’(0, 2):0.241\n",
      "(1, 2)   0.3746    0.5000 0.0157 (0, 2)â†’0.375                       R:0.5\n",
      "(2, 1)   0.5013    0.8000 0.0892 (1, 1)â†’0.501                       R:0.8\n",
      "(0, 0)   0.0000    0.2139 0.0458         none â†’(0, 1):0.107,â†’(1, 0):0.107\n",
      "(1, 1)   0.2057    0.5013 0.0874 (1, 0)â†’0.206               â†’(2, 1):0.501\n",
      "(2, 0)   0.2491    0.6285 0.1440 (1, 0)â†’0.249               â†’(3, 0):0.629\n",
      "(3, 0)   0.6285    1.0000 0.1380 (2, 0)â†’0.629                       R:1.0\n",
      "(0, 2)   0.2412    0.3746 0.0178 (0, 1)â†’0.241               â†’(1, 2):0.375\n",
      "(1, 0)   0.1071    0.4548 0.1209 (0, 0)â†’0.107 â†’(2, 0):0.249,â†’(1, 1):0.206\n",
      "\n",
      "Total Loss: 0.676813\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1068    0.2401 0.0178 (0, 0)â†’0.107               â†’(0, 2):0.240\n",
      "(1, 2)   0.3726    0.5000 0.0162 (0, 2)â†’0.373                       R:0.5\n",
      "(2, 1)   0.5014    0.8000 0.0892 (1, 1)â†’0.501                       R:0.8\n",
      "(0, 0)   0.0000    0.2144 0.0460         none â†’(0, 1):0.107,â†’(1, 0):0.108\n",
      "(1, 1)   0.2057    0.5014 0.0874 (1, 0)â†’0.206               â†’(2, 1):0.501\n",
      "(2, 0)   0.2507    0.6294 0.1434 (1, 0)â†’0.251               â†’(3, 0):0.629\n",
      "(3, 0)   0.6294    1.0000 0.1373 (2, 0)â†’0.629                       R:1.0\n",
      "(0, 2)   0.2401    0.3726 0.0176 (0, 1)â†’0.240               â†’(1, 2):0.373\n",
      "(1, 0)   0.1077    0.4563 0.1216 (0, 0)â†’0.108 â†’(2, 0):0.251,â†’(1, 1):0.206\n",
      "\n",
      "Total Loss: 0.676519\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1067    0.2390 0.0175 (0, 0)â†’0.107               â†’(0, 2):0.239\n",
      "(1, 2)   0.3709    0.5000 0.0167 (0, 2)â†’0.371                       R:0.5\n",
      "(2, 1)   0.5016    0.8000 0.0891 (1, 1)â†’0.502                       R:0.8\n",
      "(0, 0)   0.0000    0.2150 0.0462         none â†’(0, 1):0.107,â†’(1, 0):0.108\n",
      "(1, 1)   0.2055    0.5016 0.0877 (1, 0)â†’0.205               â†’(2, 1):0.502\n",
      "(2, 0)   0.2522    0.6299 0.1427 (1, 0)â†’0.252               â†’(3, 0):0.630\n",
      "(3, 0)   0.6299    1.0000 0.1369 (2, 0)â†’0.630                       R:1.0\n",
      "(0, 2)   0.2390    0.3709 0.0174 (0, 1)â†’0.239               â†’(1, 2):0.371\n",
      "(1, 0)   0.1083    0.4576 0.1220 (0, 0)â†’0.108 â†’(2, 0):0.252,â†’(1, 1):0.205\n",
      "\n",
      "Total Loss: 0.676217\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1066    0.2380 0.0173 (0, 0)â†’0.107               â†’(0, 2):0.238\n",
      "(1, 2)   0.3693    0.5000 0.0171 (0, 2)â†’0.369                       R:0.5\n",
      "(2, 1)   0.5019    0.8000 0.0889 (1, 1)â†’0.502                       R:0.8\n",
      "(0, 0)   0.0000    0.2156 0.0465         none â†’(0, 1):0.107,â†’(1, 0):0.109\n",
      "(1, 1)   0.2052    0.5019 0.0881 (1, 0)â†’0.205               â†’(2, 1):0.502\n",
      "(2, 0)   0.2535    0.6301 0.1419 (1, 0)â†’0.254               â†’(3, 0):0.630\n",
      "(3, 0)   0.6301    1.0000 0.1368 (2, 0)â†’0.630                       R:1.0\n",
      "(0, 2)   0.2380    0.3693 0.0172 (0, 1)â†’0.238               â†’(1, 2):0.369\n",
      "(1, 0)   0.1090    0.4587 0.1223 (0, 0)â†’0.109 â†’(2, 0):0.254,â†’(1, 1):0.205\n",
      "\n",
      "Total Loss: 0.675906\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "Step 80: Loss = 0.675906\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1066    0.2371 0.0170 (0, 0)â†’0.107               â†’(0, 2):0.237\n",
      "(1, 2)   0.3678    0.5000 0.0175 (0, 2)â†’0.368                       R:0.5\n",
      "(2, 1)   0.5023    0.8000 0.0886 (1, 1)â†’0.502                       R:0.8\n",
      "(0, 0)   0.0000    0.2163 0.0468         none â†’(0, 1):0.107,â†’(1, 0):0.110\n",
      "(1, 1)   0.2047    0.5023 0.0885 (1, 0)â†’0.205               â†’(2, 1):0.502\n",
      "(2, 0)   0.2547    0.6301 0.1409 (1, 0)â†’0.255               â†’(3, 0):0.630\n",
      "(3, 0)   0.6301    1.0000 0.1368 (2, 0)â†’0.630                       R:1.0\n",
      "(0, 2)   0.2371    0.3678 0.0171 (0, 1)â†’0.237               â†’(1, 2):0.368\n",
      "(1, 0)   0.1097    0.4594 0.1223 (0, 0)â†’0.110 â†’(2, 0):0.255,â†’(1, 1):0.205\n",
      "\n",
      "Total Loss: 0.675590\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1065    0.2363 0.0168 (0, 0)â†’0.107               â†’(0, 2):0.236\n",
      "(1, 2)   0.3666    0.5000 0.0178 (0, 2)â†’0.367                       R:0.5\n",
      "(2, 1)   0.5026    0.8000 0.0885 (1, 1)â†’0.503                       R:0.8\n",
      "(0, 0)   0.0000    0.2170 0.0471         none â†’(0, 1):0.107,â†’(1, 0):0.111\n",
      "(1, 1)   0.2041    0.5026 0.0891 (1, 0)â†’0.204               â†’(2, 1):0.503\n",
      "(2, 0)   0.2558    0.6299 0.1399 (1, 0)â†’0.256               â†’(3, 0):0.630\n",
      "(3, 0)   0.6299    1.0000 0.1370 (2, 0)â†’0.630                       R:1.0\n",
      "(0, 2)   0.2363    0.3666 0.0170 (0, 1)â†’0.236               â†’(1, 2):0.367\n",
      "(1, 0)   0.1105    0.4600 0.1221 (0, 0)â†’0.111 â†’(2, 0):0.256,â†’(1, 1):0.204\n",
      "\n",
      "Total Loss: 0.675269\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1065    0.2356 0.0167 (0, 0)â†’0.107               â†’(0, 2):0.236\n",
      "(1, 2)   0.3655    0.5000 0.0181 (0, 2)â†’0.365                       R:0.5\n",
      "(2, 1)   0.5028    0.8000 0.0883 (1, 1)â†’0.503                       R:0.8\n",
      "(0, 0)   0.0000    0.2178 0.0475         none â†’(0, 1):0.107,â†’(1, 0):0.111\n",
      "(1, 1)   0.2035    0.5028 0.0896 (1, 0)â†’0.203               â†’(2, 1):0.503\n",
      "(2, 0)   0.2568    0.6295 0.1389 (1, 0)â†’0.257               â†’(3, 0):0.630\n",
      "(3, 0)   0.6295    1.0000 0.1372 (2, 0)â†’0.630                       R:1.0\n",
      "(0, 2)   0.2356    0.3655 0.0169 (0, 1)â†’0.236               â†’(1, 2):0.365\n",
      "(1, 0)   0.1113    0.4603 0.1218 (0, 0)â†’0.111 â†’(2, 0):0.257,â†’(1, 1):0.203\n",
      "\n",
      "Total Loss: 0.674946\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1065    0.2350 0.0165 (0, 0)â†’0.107               â†’(0, 2):0.235\n",
      "(1, 2)   0.3646    0.5000 0.0183 (0, 2)â†’0.365                       R:0.5\n",
      "(2, 1)   0.5028    0.8000 0.0883 (1, 1)â†’0.503                       R:0.8\n",
      "(0, 0)   0.0000    0.2187 0.0478         none â†’(0, 1):0.107,â†’(1, 0):0.112\n",
      "(1, 1)   0.2027    0.5028 0.0900 (1, 0)â†’0.203               â†’(2, 1):0.503\n",
      "(2, 0)   0.2577    0.6292 0.1380 (1, 0)â†’0.258               â†’(3, 0):0.629\n",
      "(3, 0)   0.6292    1.0000 0.1375 (2, 0)â†’0.629                       R:1.0\n",
      "(0, 2)   0.2350    0.3646 0.0168 (0, 1)â†’0.235               â†’(1, 2):0.365\n",
      "(1, 0)   0.1122    0.4604 0.1213 (0, 0)â†’0.112 â†’(2, 0):0.258,â†’(1, 1):0.203\n",
      "\n",
      "Total Loss: 0.674623\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1065    0.2346 0.0164 (0, 0)â†’0.107               â†’(0, 2):0.235\n",
      "(1, 2)   0.3639    0.5000 0.0185 (0, 2)â†’0.364                       R:0.5\n",
      "(2, 1)   0.5026    0.8000 0.0885 (1, 1)â†’0.503                       R:0.8\n",
      "(0, 0)   0.0000    0.2196 0.0482         none â†’(0, 1):0.107,â†’(1, 0):0.113\n",
      "(1, 1)   0.2020    0.5026 0.0904 (1, 0)â†’0.202               â†’(2, 1):0.503\n",
      "(2, 0)   0.2584    0.6288 0.1372 (1, 0)â†’0.258               â†’(3, 0):0.629\n",
      "(3, 0)   0.6288    1.0000 0.1378 (2, 0)â†’0.629                       R:1.0\n",
      "(0, 2)   0.2346    0.3639 0.0167 (0, 1)â†’0.235               â†’(1, 2):0.364\n",
      "(1, 0)   0.1131    0.4604 0.1207 (0, 0)â†’0.113 â†’(2, 0):0.258,â†’(1, 1):0.202\n",
      "\n",
      "Total Loss: 0.674298\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1066    0.2343 0.0163 (0, 0)â†’0.107               â†’(0, 2):0.234\n",
      "(1, 2)   0.3635    0.5000 0.0186 (0, 2)â†’0.363                       R:0.5\n",
      "(2, 1)   0.5022    0.8000 0.0887 (1, 1)â†’0.502                       R:0.8\n",
      "(0, 0)   0.0000    0.2205 0.0486         none â†’(0, 1):0.107,â†’(1, 0):0.114\n",
      "(1, 1)   0.2012    0.5022 0.0906 (1, 0)â†’0.201               â†’(2, 1):0.502\n",
      "(2, 0)   0.2592    0.6285 0.1364 (1, 0)â†’0.259               â†’(3, 0):0.629\n",
      "(3, 0)   0.6285    1.0000 0.1380 (2, 0)â†’0.629                       R:1.0\n",
      "(0, 2)   0.2343    0.3635 0.0167 (0, 1)â†’0.234               â†’(1, 2):0.363\n",
      "(1, 0)   0.1140    0.4604 0.1200 (0, 0)â†’0.114 â†’(2, 0):0.259,â†’(1, 1):0.201\n",
      "\n",
      "Total Loss: 0.673968\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1066    0.2341 0.0163 (0, 0)â†’0.107               â†’(0, 2):0.234\n",
      "(1, 2)   0.3632    0.5000 0.0187 (0, 2)â†’0.363                       R:0.5\n",
      "(2, 1)   0.5016    0.8000 0.0891 (1, 1)â†’0.502                       R:0.8\n",
      "(0, 0)   0.0000    0.2215 0.0491         none â†’(0, 1):0.107,â†’(1, 0):0.115\n",
      "(1, 1)   0.2004    0.5016 0.0907 (1, 0)â†’0.200               â†’(2, 1):0.502\n",
      "(2, 0)   0.2600    0.6284 0.1357 (1, 0)â†’0.260               â†’(3, 0):0.628\n",
      "(3, 0)   0.6284    1.0000 0.1381 (2, 0)â†’0.628                       R:1.0\n",
      "(0, 2)   0.2341    0.3632 0.0167 (0, 1)â†’0.234               â†’(1, 2):0.363\n",
      "(1, 0)   0.1149    0.4603 0.1193 (0, 0)â†’0.115 â†’(2, 0):0.260,â†’(1, 1):0.200\n",
      "\n",
      "Total Loss: 0.673633\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1066    0.2342 0.0163 (0, 0)â†’0.107               â†’(0, 2):0.234\n",
      "(1, 2)   0.3632    0.5000 0.0187 (0, 2)â†’0.363                       R:0.5\n",
      "(2, 1)   0.5009    0.8000 0.0895 (1, 1)â†’0.501                       R:0.8\n",
      "(0, 0)   0.0000    0.2225 0.0495         none â†’(0, 1):0.107,â†’(1, 0):0.116\n",
      "(1, 1)   0.1996    0.5009 0.0908 (1, 0)â†’0.200               â†’(2, 1):0.501\n",
      "(2, 0)   0.2607    0.6284 0.1352 (1, 0)â†’0.261               â†’(3, 0):0.628\n",
      "(3, 0)   0.6284    1.0000 0.1381 (2, 0)â†’0.628                       R:1.0\n",
      "(0, 2)   0.2342    0.3632 0.0166 (0, 1)â†’0.234               â†’(1, 2):0.363\n",
      "(1, 0)   0.1159    0.4602 0.1186 (0, 0)â†’0.116 â†’(2, 0):0.261,â†’(1, 1):0.200\n",
      "\n",
      "Total Loss: 0.673294\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1067    0.2344 0.0163 (0, 0)â†’0.107               â†’(0, 2):0.234\n",
      "(1, 2)   0.3633    0.5000 0.0187 (0, 2)â†’0.363                       R:0.5\n",
      "(2, 1)   0.5001    0.8000 0.0899 (1, 1)â†’0.500                       R:0.8\n",
      "(0, 0)   0.0000    0.2236 0.0500         none â†’(0, 1):0.107,â†’(1, 0):0.117\n",
      "(1, 1)   0.1987    0.5001 0.0908 (1, 0)â†’0.199               â†’(2, 1):0.500\n",
      "(2, 0)   0.2614    0.6285 0.1348 (1, 0)â†’0.261               â†’(3, 0):0.629\n",
      "(3, 0)   0.6285    1.0000 0.1380 (2, 0)â†’0.629                       R:1.0\n",
      "(0, 2)   0.2344    0.3633 0.0166 (0, 1)â†’0.234               â†’(1, 2):0.363\n",
      "(1, 0)   0.1169    0.4601 0.1178 (0, 0)â†’0.117 â†’(2, 0):0.261,â†’(1, 1):0.199\n",
      "\n",
      "Total Loss: 0.672955\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1068    0.2347 0.0164 (0, 0)â†’0.107               â†’(0, 2):0.235\n",
      "(1, 2)   0.3636    0.5000 0.0186 (0, 2)â†’0.364                       R:0.5\n",
      "(2, 1)   0.4994    0.8000 0.0904 (1, 1)â†’0.499                       R:0.8\n",
      "(0, 0)   0.0000    0.2247 0.0505         none â†’(0, 1):0.107,â†’(1, 0):0.118\n",
      "(1, 1)   0.1979    0.4994 0.0909 (1, 0)â†’0.198               â†’(2, 1):0.499\n",
      "(2, 0)   0.2620    0.6289 0.1346 (1, 0)â†’0.262               â†’(3, 0):0.629\n",
      "(3, 0)   0.6289    1.0000 0.1377 (2, 0)â†’0.629                       R:1.0\n",
      "(0, 2)   0.2347    0.3636 0.0166 (0, 1)â†’0.235               â†’(1, 2):0.364\n",
      "(1, 0)   0.1179    0.4600 0.1170 (0, 0)â†’0.118 â†’(2, 0):0.262,â†’(1, 1):0.198\n",
      "\n",
      "Total Loss: 0.672619\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1069    0.2351 0.0164 (0, 0)â†’0.107               â†’(0, 2):0.235\n",
      "(1, 2)   0.3641    0.5000 0.0185 (0, 2)â†’0.364                       R:0.5\n",
      "(2, 1)   0.4987    0.8000 0.0908 (1, 1)â†’0.499                       R:0.8\n",
      "(0, 0)   0.0000    0.2259 0.0510         none â†’(0, 1):0.107,â†’(1, 0):0.119\n",
      "(1, 1)   0.1972    0.4987 0.0909 (1, 0)â†’0.197               â†’(2, 1):0.499\n",
      "(2, 0)   0.2627    0.6294 0.1344 (1, 0)â†’0.263               â†’(3, 0):0.629\n",
      "(3, 0)   0.6294    1.0000 0.1374 (2, 0)â†’0.629                       R:1.0\n",
      "(0, 2)   0.2351    0.3641 0.0166 (0, 1)â†’0.235               â†’(1, 2):0.364\n",
      "(1, 0)   0.1190    0.4599 0.1162 (0, 0)â†’0.119 â†’(2, 0):0.263,â†’(1, 1):0.197\n",
      "\n",
      "Total Loss: 0.672283\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1070    0.2355 0.0165 (0, 0)â†’0.107               â†’(0, 2):0.235\n",
      "(1, 2)   0.3646    0.5000 0.0183 (0, 2)â†’0.365                       R:0.5\n",
      "(2, 1)   0.4981    0.8000 0.0911 (1, 1)â†’0.498                       R:0.8\n",
      "(0, 0)   0.0000    0.2270 0.0515         none â†’(0, 1):0.107,â†’(1, 0):0.120\n",
      "(1, 1)   0.1964    0.4981 0.0910 (1, 0)â†’0.196               â†’(2, 1):0.498\n",
      "(2, 0)   0.2634    0.6300 0.1344 (1, 0)â†’0.263               â†’(3, 0):0.630\n",
      "(3, 0)   0.6300    1.0000 0.1369 (2, 0)â†’0.630                       R:1.0\n",
      "(0, 2)   0.2355    0.3646 0.0167 (0, 1)â†’0.235               â†’(1, 2):0.365\n",
      "(1, 0)   0.1201    0.4598 0.1154 (0, 0)â†’0.120 â†’(2, 0):0.263,â†’(1, 1):0.196\n",
      "\n",
      "Total Loss: 0.671949\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1071    0.2360 0.0166 (0, 0)â†’0.107               â†’(0, 2):0.236\n",
      "(1, 2)   0.3653    0.5000 0.0181 (0, 2)â†’0.365                       R:0.5\n",
      "(2, 1)   0.4976    0.8000 0.0914 (1, 1)â†’0.498                       R:0.8\n",
      "(0, 0)   0.0000    0.2282 0.0521         none â†’(0, 1):0.107,â†’(1, 0):0.121\n",
      "(1, 1)   0.1957    0.4976 0.0912 (1, 0)â†’0.196               â†’(2, 1):0.498\n",
      "(2, 0)   0.2641    0.6308 0.1344 (1, 0)â†’0.264               â†’(3, 0):0.631\n",
      "(3, 0)   0.6308    1.0000 0.1363 (2, 0)â†’0.631                       R:1.0\n",
      "(0, 2)   0.2360    0.3653 0.0167 (0, 1)â†’0.236               â†’(1, 2):0.365\n",
      "(1, 0)   0.1212    0.4598 0.1147 (0, 0)â†’0.121 â†’(2, 0):0.264,â†’(1, 1):0.196\n",
      "\n",
      "Total Loss: 0.671619\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1071    0.2364 0.0167 (0, 0)â†’0.107               â†’(0, 2):0.236\n",
      "(1, 2)   0.3661    0.5000 0.0179 (0, 2)â†’0.366                       R:0.5\n",
      "(2, 1)   0.4973    0.8000 0.0916 (1, 1)â†’0.497                       R:0.8\n",
      "(0, 0)   0.0000    0.2294 0.0526         none â†’(0, 1):0.107,â†’(1, 0):0.122\n",
      "(1, 1)   0.1950    0.4973 0.0914 (1, 0)â†’0.195               â†’(2, 1):0.497\n",
      "(2, 0)   0.2648    0.6316 0.1345 (1, 0)â†’0.265               â†’(3, 0):0.632\n",
      "(3, 0)   0.6316    1.0000 0.1357 (2, 0)â†’0.632                       R:1.0\n",
      "(0, 2)   0.2364    0.3661 0.0168 (0, 1)â†’0.236               â†’(1, 2):0.366\n",
      "(1, 0)   0.1223    0.4599 0.1140 (0, 0)â†’0.122 â†’(2, 0):0.265,â†’(1, 1):0.195\n",
      "\n",
      "Total Loss: 0.671292\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1072    0.2369 0.0168 (0, 0)â†’0.107               â†’(0, 2):0.237\n",
      "(1, 2)   0.3669    0.5000 0.0177 (0, 2)â†’0.367                       R:0.5\n",
      "(2, 1)   0.4971    0.8000 0.0918 (1, 1)â†’0.497                       R:0.8\n",
      "(0, 0)   0.0000    0.2306 0.0532         none â†’(0, 1):0.107,â†’(1, 0):0.123\n",
      "(1, 1)   0.1944    0.4971 0.0916 (1, 0)â†’0.194               â†’(2, 1):0.497\n",
      "(2, 0)   0.2656    0.6324 0.1345 (1, 0)â†’0.266               â†’(3, 0):0.632\n",
      "(3, 0)   0.6324    1.0000 0.1351 (2, 0)â†’0.632                       R:1.0\n",
      "(0, 2)   0.2369    0.3669 0.0169 (0, 1)â†’0.237               â†’(1, 2):0.367\n",
      "(1, 0)   0.1234    0.4601 0.1134 (0, 0)â†’0.123 â†’(2, 0):0.266,â†’(1, 1):0.194\n",
      "\n",
      "Total Loss: 0.670972\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1073    0.2374 0.0169 (0, 0)â†’0.107               â†’(0, 2):0.237\n",
      "(1, 2)   0.3677    0.5000 0.0175 (0, 2)â†’0.368                       R:0.5\n",
      "(2, 1)   0.4969    0.8000 0.0919 (1, 1)â†’0.497                       R:0.8\n",
      "(0, 0)   0.0000    0.2317 0.0537         none â†’(0, 1):0.107,â†’(1, 0):0.124\n",
      "(1, 1)   0.1939    0.4969 0.0918 (1, 0)â†’0.194               â†’(2, 1):0.497\n",
      "(2, 0)   0.2665    0.6333 0.1345 (1, 0)â†’0.266               â†’(3, 0):0.633\n",
      "(3, 0)   0.6333    1.0000 0.1345 (2, 0)â†’0.633                       R:1.0\n",
      "(0, 2)   0.2374    0.3677 0.0170 (0, 1)â†’0.237               â†’(1, 2):0.368\n",
      "(1, 0)   0.1245    0.4604 0.1128 (0, 0)â†’0.124 â†’(2, 0):0.266,â†’(1, 1):0.194\n",
      "\n",
      "Total Loss: 0.670655\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1073    0.2378 0.0170 (0, 0)â†’0.107               â†’(0, 2):0.238\n",
      "(1, 2)   0.3685    0.5000 0.0173 (0, 2)â†’0.369                       R:0.5\n",
      "(2, 1)   0.4968    0.8000 0.0919 (1, 1)â†’0.497                       R:0.8\n",
      "(0, 0)   0.0000    0.2329 0.0542         none â†’(0, 1):0.107,â†’(1, 0):0.126\n",
      "(1, 1)   0.1934    0.4968 0.0921 (1, 0)â†’0.193               â†’(2, 1):0.497\n",
      "(2, 0)   0.2674    0.6341 0.1344 (1, 0)â†’0.267               â†’(3, 0):0.634\n",
      "(3, 0)   0.6341    1.0000 0.1339 (2, 0)â†’0.634                       R:1.0\n",
      "(0, 2)   0.2378    0.3685 0.0171 (0, 1)â†’0.238               â†’(1, 2):0.369\n",
      "(1, 0)   0.1256    0.4608 0.1123 (0, 0)â†’0.126 â†’(2, 0):0.267,â†’(1, 1):0.193\n",
      "\n",
      "Total Loss: 0.670343\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1073    0.2382 0.0171 (0, 0)â†’0.107               â†’(0, 2):0.238\n",
      "(1, 2)   0.3694    0.5000 0.0171 (0, 2)â†’0.369                       R:0.5\n",
      "(2, 1)   0.4967    0.8000 0.0920 (1, 1)â†’0.497                       R:0.8\n",
      "(0, 0)   0.0000    0.2339 0.0547         none â†’(0, 1):0.107,â†’(1, 0):0.127\n",
      "(1, 1)   0.1929    0.4967 0.0923 (1, 0)â†’0.193               â†’(2, 1):0.497\n",
      "(2, 0)   0.2683    0.6348 0.1343 (1, 0)â†’0.268               â†’(3, 0):0.635\n",
      "(3, 0)   0.6348    1.0000 0.1334 (2, 0)â†’0.635                       R:1.0\n",
      "(0, 2)   0.2382    0.3694 0.0172 (0, 1)â†’0.238               â†’(1, 2):0.369\n",
      "(1, 0)   0.1266    0.4612 0.1120 (0, 0)â†’0.127 â†’(2, 0):0.268,â†’(1, 1):0.193\n",
      "\n",
      "Total Loss: 0.670055\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "=== FLOW CONSERVATION ANALYSIS ===\n",
      " State  Flow_IN  Flow_OUT  Error   IN_Details                 OUT_Details\n",
      "(0, 1)   0.1073    0.2386 0.0172 (0, 0)â†’0.107               â†’(0, 2):0.239\n",
      "(1, 2)   0.3701    0.5000 0.0169 (0, 2)â†’0.370                       R:0.5\n",
      "(2, 1)   0.4966    0.8000 0.0920 (1, 1)â†’0.497                       R:0.8\n",
      "(0, 0)   0.0000    0.2349 0.0552         none â†’(0, 1):0.107,â†’(1, 0):0.128\n",
      "(1, 1)   0.1924    0.4966 0.0925 (1, 0)â†’0.192               â†’(2, 1):0.497\n",
      "(2, 0)   0.2693    0.6355 0.1341 (1, 0)â†’0.269               â†’(3, 0):0.635\n",
      "(3, 0)   0.6355    1.0000 0.1329 (2, 0)â†’0.635                       R:1.0\n",
      "(0, 2)   0.2386    0.3701 0.0173 (0, 1)â†’0.239               â†’(1, 2):0.370\n",
      "(1, 0)   0.1276    0.4617 0.1116 (0, 0)â†’0.128 â†’(2, 0):0.269,â†’(1, 1):0.192\n",
      "\n",
      "Total Loss: 0.669765\n",
      "Expected: Flow IN = Flow OUT for all states\n",
      "\n",
      "Flow predictions after training:\n",
      "Flow (1, 1) â†’ (2, 1): 0.4965\n",
      "Flow (1, 0) â†’ (2, 0): 0.2703\n",
      "Flow (1, 0) â†’ (1, 1): 0.1920\n",
      "Flow (0, 0) â†’ (0, 1): 0.1072\n",
      "Flow (0, 2) â†’ (1, 2): 0.3708\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def experiment_simple():\n",
    "    \"\"\"Everything else - network, training, data\"\"\"\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.optim as optim\n",
    "    # Setup for 8x8 grid\n",
    "    grid_size = 8\n",
    "    state_dim = grid_size * grid_size  # 64 states\n",
    "    \n",
    "    def encode_state(state):\n",
    "        \"\"\"Convert (x,y) state to one-hot vector\"\"\"\n",
    "        x, y = state\n",
    "        idx = y * grid_size + x\n",
    "        vec = torch.zeros(state_dim)\n",
    "        vec[idx] = 1.0\n",
    "        return vec\n",
    "    \n",
    "    # Create flow network \n",
    "    flow_network = nn.Sequential(\n",
    "        nn.Linear(state_dim * 2, 128),  # from_state + to_state\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 1),\n",
    "        nn.Softplus()  # Ensure positive flows\n",
    "    )\n",
    "    \n",
    "    optimizer = optim.Adam(flow_network.parameters(), lr=0.001)\n",
    "    \n",
    "    # Define example trajectories\n",
    "    trajectories = [\n",
    "        [(0, 0), (1, 0), (2, 0), (3, 0)],  # Moving right\n",
    "        [(0, 0), (0, 1), (0, 2), (1, 2)],  # Moving up then right\n",
    "        [(0, 0), (1, 0), (1, 1), (2, 1)],  # Mixed path\n",
    "    ]\n",
    "    \n",
    "    # Define rewards (only terminal states)\n",
    "    rewards = {\n",
    "        (3, 0): 1.0,\n",
    "        (1, 2): 0.5,\n",
    "        (2, 1): 0.8\n",
    "    }\n",
    "    \n",
    "    # Extract edges and states from trajectories\n",
    "    def extract_edges_from_trajectories(trajectories):\n",
    "        edges = set()\n",
    "        for traj in trajectories:\n",
    "            for i in range(len(traj) - 1):\n",
    "                edges.add((traj[i], traj[i + 1]))\n",
    "        return list(edges)\n",
    "    \n",
    "    def get_visited_states(trajectories):\n",
    "        states = set()\n",
    "        for traj in trajectories:\n",
    "            states.update(traj)\n",
    "        return list(states)\n",
    "    \n",
    "    edges = extract_edges_from_trajectories(trajectories)\n",
    "    visited_states = get_visited_states(trajectories)\n",
    "    \n",
    "    print(\"Training GFlowNet...\")\n",
    "    print(f\"Grid size: {grid_size}x{grid_size}\")\n",
    "    print(f\"State encoding: one-hot vectors of size {state_dim}\")\n",
    "    print(f\"Flow network input: concatenated states (size {state_dim * 2})\")\n",
    "    print(f\"Trajectories: {len(trajectories)}\")\n",
    "    print(f\"Edges: {len(edges)}\")\n",
    "    print(f\"Visited states: {len(visited_states)}\")\n",
    "    print(f\"Rewards: {rewards}\")\n",
    "    \n",
    "    # Training loop\n",
    "    for step in range(100):\n",
    "        # Compute flow conservation loss\n",
    "        loss = flow_conservation_loss(flow_network, visited_states, edges, rewards, encode_state)\n",
    "        \n",
    "        # Update network\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 20 == 0:\n",
    "            print(f\"Step {step}: Loss = {loss:.6f}\")\n",
    "    \n",
    "    # Test predictions after training\n",
    "    print(\"\\nFlow predictions after training:\")\n",
    "    for from_state, to_state in edges[:5]:  # Show first 5 edges\n",
    "        from_vec = encode_state(from_state)\n",
    "        to_vec = encode_state(to_state)\n",
    "        edge_input = torch.cat([from_vec, to_vec])\n",
    "        flow = flow_network(edge_input).squeeze()\n",
    "        print(f\"Flow {from_state} â†’ {to_state}: {flow.item():.4f}\")\n",
    "    \n",
    "    print(\"\\nDone!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b867d1-47d5-4e18-9826-1afb194c5ed3",
   "metadata": {},
   "source": [
    "### Define Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0c22c2a6-95f1-48d4-814a-75aff681c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ======================================================================\n",
    "# Data Vis utilites\n",
    "# ======================================================================\n",
    "def draw_trajectories_on_grid(trajectories, env, title=\"Trajectories\", save_path=None, max_trajectories=10):\n",
    "    \"\"\"\n",
    "    Utility function to draw trajectories on grid\n",
    "    \n",
    "    Args:\n",
    "        trajectories: List of trajectories (each trajectory is list of (x,y) states)\n",
    "        env: Environment with reward_states and start_state\n",
    "        title: Plot title\n",
    "        save_path: If provided, saves plot to this path\n",
    "        max_trajectories: Maximum number of trajectories to show\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    grid_size = env.size\n",
    "    \n",
    "    # Create base grid\n",
    "    ax.set_xlim(-0.5, grid_size - 0.5)\n",
    "    ax.set_ylim(-0.5, grid_size - 0.5)\n",
    "    \n",
    "    # Add grid lines\n",
    "    for i in range(grid_size + 1):\n",
    "        ax.axhline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "        ax.axvline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "    \n",
    "    # Mark start state\n",
    "    ax.scatter(env.start_state[0], env.start_state[1], c='green', s=300, \n",
    "              marker='s', label='Start', zorder=5, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Mark reward region\n",
    "    for state in env.reward_states:\n",
    "        ax.add_patch(plt.Rectangle((state[0]-0.4, state[1]-0.4), 0.8, 0.8, \n",
    "                                 facecolor='red', alpha=0.3, zorder=1))\n",
    "    ax.scatter([], [], c='red', s=200, marker='s', alpha=0.3, label='Reward Region')\n",
    "    \n",
    "    # Plot trajectories\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, min(len(trajectories), max_trajectories)))\n",
    "    \n",
    "    for i, (traj, color) in enumerate(zip(trajectories[:max_trajectories], colors)):\n",
    "        if len(traj) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Extract x, y coordinates\n",
    "        xs, ys = zip(*traj)\n",
    "        \n",
    "        # Determine if successful\n",
    "        success = traj[-1] in env.reward_states\n",
    "        linestyle = '-' if success else '--'\n",
    "        alpha = 0.8 if success else 0.5\n",
    "        linewidth = 3 if success else 2\n",
    "        \n",
    "        # Plot trajectory line\n",
    "        ax.plot(xs, ys, color=color, linewidth=linewidth, alpha=alpha, \n",
    "               linestyle=linestyle, label=f'Traj {i+1} ({\"âœ“\" if success else \"âœ—\"}, len={len(traj)})')\n",
    "        \n",
    "        # Mark trajectory points (smaller for intermediate points)\n",
    "        ax.scatter(xs[1:-1], ys[1:-1], color=color, s=20, alpha=0.6, zorder=3)\n",
    "        \n",
    "        # Mark end point\n",
    "        if success:\n",
    "            ax.scatter(xs[-1], ys[-1], color=color, s=150, marker='o', \n",
    "                      edgecolor='black', linewidth=2, zorder=4)\n",
    "        else:\n",
    "            ax.scatter(xs[-1], ys[-1], color=color, s=100, marker='x', \n",
    "                      linewidth=3, zorder=4)\n",
    "    \n",
    "    ax.set_xlabel('X Position')\n",
    "    ax.set_ylabel('Y Position')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Add grid coordinates for reference\n",
    "    ax.set_xticks(range(grid_size))\n",
    "    ax.set_yticks(range(grid_size))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# ======================================================================\n",
    "# **Start MLFLOW Experiment**\n",
    "# ======================================================================\n",
    "\n",
    "def mlflow_experiment(lr=0.001, hidden_dim=128, n_steps=100, batch_size=32):\n",
    "    \"\"\"MLflow tracked experiment\"\"\"\n",
    "    \n",
    "\n",
    "    with mlflow.start_run():\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"hidden_dim\", hidden_dim)\n",
    "        mlflow.log_param(\"n_steps\", n_steps)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        \n",
    "        # Setup for 8x8 grid\n",
    "        grid_size = 8\n",
    "        state_dim = grid_size * grid_size  # 64 states\n",
    "        \n",
    "        mlflow.log_param(\"grid_size\", grid_size)\n",
    "        mlflow.log_param(\"state_dim\", state_dim)\n",
    "        \n",
    "        def encode_state(state):\n",
    "            \"\"\"Convert (x,y) state to one-hot vector\"\"\"\n",
    "            x, y = state\n",
    "            idx = y * grid_size + x\n",
    "            vec = torch.zeros(state_dim)\n",
    "            vec[idx] = 1.0\n",
    "            return vec\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Initialize Grid World\n",
    "        # ======================================================================\n",
    "        \n",
    "        env = HyperGrid(size=grid_size, reward_region_size=2)\n",
    "        trajectory_sampler = GridTrajectorySampler(env)\n",
    "        \n",
    "        # Get rewards from environment\n",
    "        rewards = {}\n",
    "        for state in env.reward_states:\n",
    "            rewards[state] = env.get_reward(state)\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Create flow forward network \n",
    "        # ======================================================================\n",
    "        flow_network = nn.Sequential(\n",
    "            nn.Linear(state_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        optimizer = optim.Adam(flow_network.parameters(), lr=lr)\n",
    "        \n",
    "        mlflow.log_param(\"num_reward_states\", len(rewards))\n",
    "        \n",
    "        # Extract edges and states from trajectories helper functions\n",
    "        def extract_edges_from_trajectories(trajectories):\n",
    "            edges = set()\n",
    "            for traj in trajectories:\n",
    "                for i in range(len(traj) - 1):\n",
    "                    edges.add((traj[i], traj[i + 1]))\n",
    "            return list(edges)\n",
    "        \n",
    "        def get_visited_states(trajectories):\n",
    "            states = set()\n",
    "            for traj in trajectories:\n",
    "                states.update(traj)\n",
    "            return list(states)\n",
    "        \n",
    "        print(f\"Training GFlowNet with lr={lr}, hidden_dim={hidden_dim}\")\n",
    "        print(f\"Grid: {grid_size}x{grid_size}, Reward region: {sorted(env.reward_states)}\")\n",
    "        \n",
    "        # Training loop with logging\n",
    "        losses = []\n",
    "        all_trajectories = []\n",
    "        successful_trajectories = []  # Track successful trajectories separately\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Start Training\n",
    "        # ======================================================================\n",
    "        for step in range(n_steps):\n",
    "            step_trajectories = []\n",
    "            \n",
    "            # ======================================================================\n",
    "            # Sample grid world\n",
    "            # ======================================================================\n",
    "            step_trajectories = trajectory_sampler.sample_batch(batch_size, max_steps=15)\n",
    "            all_trajectories.extend(step_trajectories)\n",
    "            \n",
    "            # Collect successful trajectories\n",
    "            for traj in step_trajectories:\n",
    "                if env.is_terminal(traj[-1]):\n",
    "                    successful_trajectories.append(traj)\n",
    "            \n",
    "            edges = extract_edges_from_trajectories(step_trajectories)\n",
    "            visited_states = get_visited_states(step_trajectories)\n",
    "            \n",
    "            if not edges:  # Skip if no edges (shouldn't happen)\n",
    "                continue\n",
    "            \n",
    "            # ======================================================================\n",
    "            # Compute Loss\n",
    "            # ======================================================================\n",
    "            loss = flow_conservation_loss(flow_network, visited_states, edges, rewards, encode_state)\n",
    "            \n",
    "            # Update network\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_value = loss.item()\n",
    "            losses.append(loss_value)\n",
    "            \n",
    "            # ======================================================================\n",
    "            # Log metrics\n",
    "            # ======================================================================\n",
    "            if step % 10 == 0:\n",
    "                mlflow.log_metric(\"loss\", loss_value, step=step)\n",
    "                \n",
    "                # Calculate success rate from recent trajectories\n",
    "                success_count = sum(1 for traj in step_trajectories if traj[-1] in rewards)\n",
    "                success_rate = success_count / len(step_trajectories)\n",
    "                mlflow.log_metric(\"success_rate\", success_rate, step=step)\n",
    "                \n",
    "                avg_length = sum(len(traj) for traj in step_trajectories) / len(step_trajectories)\n",
    "                mlflow.log_metric(\"avg_trajectory_length\", avg_length, step=step)\n",
    "                \n",
    "                print(f\"Step {step}: Loss={loss_value:.6f}, Success={success_rate:.2%}, Avg Length={avg_length:.1f}\")\n",
    "        \n",
    "        # ======================================================================\n",
    "        # End Experiment\n",
    "        # ======================================================================\n",
    "        final_loss = losses[-1]\n",
    "        avg_loss = sum(losses) / len(losses)\n",
    "        min_loss = min(losses)\n",
    "        \n",
    "        mlflow.log_metric(\"final_loss\", final_loss)\n",
    "        mlflow.log_metric(\"avg_loss\", avg_loss)\n",
    "        mlflow.log_metric(\"min_loss\", min_loss)\n",
    "        \n",
    "        # Calculate overall success rate\n",
    "        total_successful = sum(1 for traj in all_trajectories if traj[-1] in rewards)\n",
    "        overall_success_rate = total_successful / len(all_trajectories)\n",
    "        mlflow.log_metric(\"overall_success_rate\", overall_success_rate)\n",
    "        mlflow.log_metric(\"total_trajectories_sampled\", len(all_trajectories))\n",
    "        \n",
    "        # Create and log loss plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(losses)\n",
    "        plt.title('Training Loss Over Time')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Flow Conservation Loss')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"loss_curve.png\", dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact(\"loss_curve.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Test final flow predictions on a sample of edges\n",
    "        final_edges = extract_edges_from_trajectories(all_trajectories[-100:])  # Last 100 trajectories\n",
    "        print(f\"\\nFlow predictions after training (sample of {min(10, len(final_edges))} edges):\")\n",
    "        \n",
    "        for i, (from_state, to_state) in enumerate(final_edges[:10]):\n",
    "            from_vec = encode_state(from_state)\n",
    "            to_vec = encode_state(to_state)\n",
    "            edge_input = torch.cat([from_vec, to_vec])\n",
    "            flow = flow_network(edge_input).squeeze()\n",
    "            flow_value = flow.item()\n",
    "            print(f\"Flow {from_state} â†’ {to_state}: {flow_value:.4f}\")\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Log successful trajectories as artifact\n",
    "        # ======================================================================\n",
    "        if successful_trajectories:\n",
    "            # Remove duplicates\n",
    "            unique_successful = []\n",
    "            seen_paths = set()\n",
    "            for traj in successful_trajectories:\n",
    "                path_tuple = tuple(traj)\n",
    "                if path_tuple not in seen_paths:\n",
    "                    unique_successful.append(traj)\n",
    "                    seen_paths.add(path_tuple)\n",
    "            \n",
    "            # Create trajectories text file\n",
    "            with open(\"successful_trajectories.txt\", \"w\") as f:\n",
    "                f.write(f\"Successful Trajectories Found During Training\\n\")\n",
    "                f.write(f\"=\"*50 + \"\\n\")\n",
    "                f.write(f\"Total successful: {len(successful_trajectories)}\\n\")\n",
    "                f.write(f\"Unique successful: {len(unique_successful)}\\n\")\n",
    "                f.write(f\"Success rate: {len(successful_trajectories)/len(all_trajectories)*100:.1f}%\\n\\n\")\n",
    "                \n",
    "                for i, traj in enumerate(unique_successful[:20]):  # Show top 20\n",
    "                    f.write(f\"Trajectory {i+1}: {traj}\\n\")\n",
    "                    f.write(f\"  Length: {len(traj)} steps\\n\")\n",
    "                    f.write(f\"  End state: {traj[-1]} (reward: {env.get_reward(traj[-1])})\\n\\n\")\n",
    "            \n",
    "            mlflow.log_artifact(\"successful_trajectories.txt\")\n",
    "            mlflow.log_metric(\"unique_successful_trajectories\", len(unique_successful))\n",
    "            \n",
    "            # ======================================================================\n",
    "            # Visualize successful trajectories\n",
    "            # ======================================================================\n",
    "            if len(unique_successful) > 0:\n",
    "                # Draw successful trajectories\n",
    "                draw_trajectories_on_grid(\n",
    "                    unique_successful[:10],  # Show top 10 successful trajectories\n",
    "                    env,\n",
    "                    title=f\"Successful Trajectories (showing {min(10, len(unique_successful))} of {len(unique_successful)})\",\n",
    "                    save_path=\"successful_trajectories_viz.png\",\n",
    "                    max_trajectories=10\n",
    "                )\n",
    "                mlflow.log_artifact(\"successful_trajectories_viz.png\")\n",
    "                \n",
    "                # Also draw a comparison with some failed trajectories\n",
    "                failed_trajectories = [traj for traj in all_trajectories[-50:] if traj[-1] not in env.reward_states]\n",
    "                if failed_trajectories:\n",
    "                    mixed_trajectories = unique_successful[:5] + failed_trajectories[:5]\n",
    "                    draw_trajectories_on_grid(\n",
    "                        mixed_trajectories,\n",
    "                        env,\n",
    "                        title=\"Successful vs Failed Trajectories\",\n",
    "                        save_path=\"success_vs_failed_trajectories.png\",\n",
    "                        max_trajectories=10\n",
    "                    )\n",
    "                    mlflow.log_artifact(\"success_vs_failed_trajectories.png\")\n",
    "            \n",
    "            print(f\"Found {len(successful_trajectories)} successful trajectories ({len(unique_successful)} unique)\")\n",
    "        else:\n",
    "            print(\"No successful trajectories found!\")\n",
    "            \n",
    "            # Still draw some failed trajectories to see what's happening\n",
    "            recent_trajectories = all_trajectories[-10:]\n",
    "            draw_trajectories_on_grid(\n",
    "                recent_trajectories,\n",
    "                env,\n",
    "                title=\"Recent Trajectories (No Successful Found)\",\n",
    "                save_path=\"recent_trajectories.png\",\n",
    "                max_trajectories=10\n",
    "            )\n",
    "            mlflow.log_artifact(\"recent_trajectories.png\")\n",
    "        \n",
    "        # Create example input for model logging\n",
    "        example_from_state = encode_state((0, 0))\n",
    "        example_to_state = encode_state((1, 0))\n",
    "        example_input = torch.cat([example_from_state, example_to_state]).unsqueeze(0)\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.pytorch.log_model(\n",
    "            flow_network,\n",
    "            \"flow_model\",\n",
    "            input_example=example_input.numpy()\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFinal Loss: {final_loss:.6f}\")\n",
    "        print(f\"Overall Success Rate: {overall_success_rate:.2%}\")\n",
    "        print(f\"Total Trajectories: {len(all_trajectories)}\")\n",
    "        \n",
    "        return final_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a1bb8-39e0-4128-9812-11fd9086043e",
   "metadata": {},
   "source": [
    "### Run Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc87bd6-2677-4757-85c2-6d2252b2605b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def run_hyperparameter_sweep():\n",
    "    \"\"\"Run hyperparameter sweep with MLflow - ALL RUNS IN ONE EXPERIMENT\"\"\"\n",
    "    \n",
    "    # NOTE: Experiment should already be set before calling this function\n",
    "    \n",
    "    # Hyperparameter grid\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    hidden_dims = [64, 128, 256]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Running: lr={lr}, hidden_dim={hidden_dim}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            final_loss = mlflow_experiment(lr=lr, hidden_dim=hidden_dim, n_steps=50000)\n",
    "            \n",
    "            results.append({\n",
    "                'lr': lr,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'final_loss': final_loss\n",
    "            })\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"HYPERPARAMETER SWEEP RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for result in results:\n",
    "        print(f\"lr={result['lr']}, hidden_dim={result['hidden_dim']}, final_loss={result['final_loss']:.6f}\")\n",
    "    \n",
    "    # Find best configuration\n",
    "    best_result = min(results, key=lambda x: x['final_loss'])\n",
    "    print(f\"\\nBest configuration:\")\n",
    "    print(f\"  Learning Rate: {best_result['lr']}\")\n",
    "    print(f\"  Hidden Dim: {best_result['hidden_dim']}\")\n",
    "    print(f\"  Final Loss: {best_result['final_loss']:.6f}\")\n",
    "    \n",
    "    # Log summary as artifact (will go to last run, which is fine)\n",
    "    with open(\"sweep_summary.txt\", \"w\") as f:\n",
    "        f.write(\"Hyperparameter Sweep Summary\\n\")\n",
    "        f.write(\"=\"*40 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"All Results:\\n\")\n",
    "        for result in results:\n",
    "            f.write(f\"lr={result['lr']}, hidden_dim={result['hidden_dim']}, final_loss={result['final_loss']:.6f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Configuration:\\n\")\n",
    "        f.write(f\"Learning Rate: {best_result['lr']}\\n\")\n",
    "        f.write(f\"Hidden Dim: {best_result['hidden_dim']}\\n\")\n",
    "        f.write(f\"Final Loss: {best_result['final_loss']:.6f}\\n\")\n",
    "    \n",
    "    print(\"Sweep completed! Check MLflow UI for detailed results.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ======================================================================\n",
    "    # Jupyter Notebook Safe MLflow Setup\n",
    "    # ======================================================================\n",
    "    \n",
    "    # End any existing runs (important for Jupyter notebooks)\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass  # No active run to end\n",
    "    \n",
    "    # Set experiment ONCE before running anything\n",
    "    mlflow.set_experiment(\"GFlowNet_Flow_Conservation\")\n",
    "    \n",
    "    # Run single experiment\n",
    "    # mlflow_experiment(lr=0.001, hidden_dim=128, n_steps=100)\n",
    "    \n",
    "    # Or run hyperparameter sweep\n",
    "    run_hyperparameter_sweep()\n",
    "    \n",
    "    # Clean up after sweep (good practice for notebooks)\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6482d102-70bf-438d-8464-362be93305e9",
   "metadata": {},
   "source": [
    "## Trajectory Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5fc2d-5157-4982-804d-7671468093b6",
   "metadata": {},
   "source": [
    "### Experiment Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79834d-2429-4641-82ac-2bf218f0d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypergrid_trajectory_balance_experiment import trajectory_balance_experiment\n",
    "\n",
    "# ====================================================\n",
    "# Main Execution\n",
    "# ====================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # MLflow setup\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mlflow.set_experiment(\"Trajectory_Balance_GFlowNet\")\n",
    "    \n",
    "    # Run single experiment\n",
    "    trajectory_balance_experiment(lr=0.001, hidden_dim=128, n_steps=1000)\n",
    "    \n",
    "    # Or run hyperparameter sweep\n",
    "    # run_trajectory_balance_sweep()\n",
    "    \n",
    "    # Clean up\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb24bd80-0ff2-4029-b8f7-c2192538fbad",
   "metadata": {},
   "source": [
    "# sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2028ff15-efa7-42f7-8564-a3eff36d0fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Running: lr=0.01, hidden_dim=64\n",
      "==================================================\n",
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Training GFlowNet with lr=0.01, hidden_dim=64, n_steps=10000\n",
      "Grid: 8x8, Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (lr=0.01, hid=64): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:30<00:00, 66.33it/s, Loss=0.0000, Success=0.0%, AvgLen=16.0, TotalSucc=467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed!\n",
      "\n",
      "Flow predictions after training (sample of 10 edges):\n",
      "Flow (5, 0) â†’ (4, 0): 0.0000\n",
      "Flow (0, 5) â†’ (0, 6): 0.0000\n",
      "Flow (6, 0) â†’ (6, 1): 0.0000\n",
      "Flow (2, 6) â†’ (1, 6): 0.0000\n",
      "Flow (2, 2) â†’ (3, 2): 0.0000\n",
      "Flow (2, 7) â†’ (3, 7): 0.0000\n",
      "Flow (3, 2) â†’ (4, 2): 0.0000\n",
      "Flow (3, 4) â†’ (2, 4): 0.0000\n",
      "Flow (1, 0) â†’ (2, 0): 0.0000\n",
      "Flow (5, 5) â†’ (6, 5): 0.0000\n",
      "Found 467 successful trajectories (463 unique)\n",
      "\n",
      "Final Loss: 0.000000\n",
      "Overall Success Rate: 0.15%\n",
      "Total Trajectories: 320000\n",
      "\n",
      "==================================================\n",
      "Running: lr=0.01, hidden_dim=128\n",
      "==================================================\n",
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Training GFlowNet with lr=0.01, hidden_dim=128, n_steps=10000\n",
      "Grid: 8x8, Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (lr=0.01, hid=128): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:35<00:00, 64.43it/s, Loss=0.0000, Success=0.0%, AvgLen=16.0, TotalSucc=459]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed!\n",
      "\n",
      "Flow predictions after training (sample of 10 edges):\n",
      "Flow (5, 0) â†’ (4, 0): 0.0000\n",
      "Flow (0, 5) â†’ (0, 6): 0.0000\n",
      "Flow (6, 0) â†’ (6, 1): 0.0000\n",
      "Flow (2, 2) â†’ (3, 2): 0.0000\n",
      "Flow (2, 4) â†’ (1, 4): 0.0000\n",
      "Flow (2, 7) â†’ (3, 7): 0.0000\n",
      "Flow (3, 2) â†’ (4, 2): 0.0000\n",
      "Flow (3, 4) â†’ (2, 4): 0.0000\n",
      "Flow (1, 0) â†’ (2, 0): 0.0000\n",
      "Flow (3, 1) â†’ (4, 1): 0.0000\n",
      "Found 459 successful trajectories (456 unique)\n",
      "\n",
      "Final Loss: 0.000000\n",
      "Overall Success Rate: 0.14%\n",
      "Total Trajectories: 320000\n",
      "\n",
      "==================================================\n",
      "Running: lr=0.01, hidden_dim=256\n",
      "==================================================\n",
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Training GFlowNet with lr=0.01, hidden_dim=256, n_steps=10000\n",
      "Grid: 8x8, Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (lr=0.01, hid=256): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:52<00:00, 58.00it/s, Loss=0.0000, Success=0.0%, AvgLen=16.0, TotalSucc=417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed!\n",
      "\n",
      "Flow predictions after training (sample of 10 edges):\n",
      "Flow (5, 0) â†’ (4, 0): 0.0000\n",
      "Flow (0, 5) â†’ (0, 6): 0.0000\n",
      "Flow (2, 6) â†’ (1, 6): 0.0000\n",
      "Flow (2, 2) â†’ (3, 2): 0.0000\n",
      "Flow (2, 4) â†’ (1, 4): 0.0000\n",
      "Flow (3, 2) â†’ (4, 2): 0.0000\n",
      "Flow (1, 0) â†’ (2, 0): 0.0000\n",
      "Flow (3, 1) â†’ (4, 1): 0.0000\n",
      "Flow (0, 2) â†’ (0, 3): 0.0000\n",
      "Flow (4, 1) â†’ (4, 2): 0.0000\n",
      "Found 417 successful trajectories (414 unique)\n",
      "\n",
      "Final Loss: 0.000000\n",
      "Overall Success Rate: 0.13%\n",
      "Total Trajectories: 320000\n",
      "\n",
      "==================================================\n",
      "Running: lr=0.001, hidden_dim=64\n",
      "==================================================\n",
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Training GFlowNet with lr=0.001, hidden_dim=64, n_steps=10000\n",
      "Grid: 8x8, Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (lr=0.001, hid=64): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:33<00:00, 65.15it/s, Loss=0.0000, Success=0.0%, AvgLen=16.0, TotalSucc=462]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed!\n",
      "\n",
      "Flow predictions after training (sample of 10 edges):\n",
      "Flow (5, 0) â†’ (4, 0): 0.0001\n",
      "Flow (0, 5) â†’ (0, 6): 0.0002\n",
      "Flow (6, 0) â†’ (6, 1): 0.0001\n",
      "Flow (2, 6) â†’ (1, 6): 0.0003\n",
      "Flow (2, 2) â†’ (3, 2): 0.0003\n",
      "Flow (2, 4) â†’ (1, 4): 0.0002\n",
      "Flow (3, 4) â†’ (2, 4): 0.0002\n",
      "Flow (3, 2) â†’ (4, 2): 0.0001\n",
      "Flow (2, 7) â†’ (3, 7): 0.0012\n",
      "Flow (1, 0) â†’ (2, 0): 0.0070\n",
      "Found 462 successful trajectories (456 unique)\n",
      "\n",
      "Final Loss: 0.000005\n",
      "Overall Success Rate: 0.14%\n",
      "Total Trajectories: 320000\n",
      "\n",
      "==================================================\n",
      "Running: lr=0.001, hidden_dim=128\n",
      "==================================================\n",
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Training GFlowNet with lr=0.001, hidden_dim=128, n_steps=10000\n",
      "Grid: 8x8, Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (lr=0.001, hid=128): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:35<00:00, 64.31it/s, Loss=0.0000, Success=0.0%, AvgLen=16.0, TotalSucc=409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed!\n",
      "\n",
      "Flow predictions after training (sample of 10 edges):\n",
      "Flow (5, 0) â†’ (4, 0): 0.0000\n",
      "Flow (6, 0) â†’ (6, 1): 0.0000\n",
      "Flow (2, 6) â†’ (1, 6): 0.0001\n",
      "Flow (2, 2) â†’ (3, 2): 0.0001\n",
      "Flow (2, 4) â†’ (1, 4): 0.0000\n",
      "Flow (3, 2) â†’ (4, 2): 0.0000\n",
      "Flow (1, 0) â†’ (2, 0): 0.0040\n",
      "Flow (3, 1) â†’ (4, 1): 0.0000\n",
      "Flow (0, 2) â†’ (0, 3): 0.0004\n",
      "Flow (4, 1) â†’ (4, 2): 0.0000\n",
      "Found 409 successful trajectories (403 unique)\n",
      "\n",
      "Final Loss: 0.000001\n",
      "Overall Success Rate: 0.13%\n",
      "Total Trajectories: 320000\n",
      "\n",
      "==================================================\n",
      "Running: lr=0.001, hidden_dim=256\n",
      "==================================================\n",
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Training GFlowNet with lr=0.001, hidden_dim=256, n_steps=10000\n",
      "Grid: 8x8, Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (lr=0.001, hid=256): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:51<00:00, 58.19it/s, Loss=0.0003, Success=0.0%, AvgLen=16.0, TotalSucc=414]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed!\n",
      "\n",
      "Flow predictions after training (sample of 10 edges):\n",
      "Flow (5, 0) â†’ (4, 0): 0.0001\n",
      "Flow (0, 5) â†’ (0, 6): 0.0001\n",
      "Flow (6, 0) â†’ (6, 1): 0.0001\n",
      "Flow (2, 6) â†’ (1, 6): 0.0002\n",
      "Flow (2, 2) â†’ (3, 2): 0.0001\n",
      "Flow (2, 4) â†’ (1, 4): 0.0001\n",
      "Flow (2, 7) â†’ (3, 7): 0.0020\n",
      "Flow (3, 2) â†’ (4, 2): 0.0001\n",
      "Flow (1, 0) â†’ (2, 0): 0.0111\n",
      "Flow (3, 1) â†’ (4, 1): 0.0001\n",
      "Found 414 successful trajectories (410 unique)\n",
      "\n",
      "Final Loss: 0.000254\n",
      "Overall Success Rate: 0.13%\n",
      "Total Trajectories: 320000\n",
      "\n",
      "==================================================\n",
      "Running: lr=0.0001, hidden_dim=64\n",
      "==================================================\n",
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Training GFlowNet with lr=0.0001, hidden_dim=64, n_steps=10000\n",
      "Grid: 8x8, Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (lr=0.0001, hid=64): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:31<00:00, 65.89it/s, Loss=0.3963, Success=3.1%, AvgLen=15.9, TotalSucc=433]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed!\n",
      "\n",
      "Flow predictions after training (sample of 10 edges):\n",
      "Flow (5, 0) â†’ (4, 0): 0.0038\n",
      "Flow (0, 5) â†’ (0, 6): 0.0041\n",
      "Flow (6, 0) â†’ (6, 1): 0.0039\n",
      "Flow (2, 6) â†’ (1, 6): 0.0040\n",
      "Flow (2, 4) â†’ (1, 4): 0.0033\n",
      "Flow (2, 2) â†’ (3, 2): 0.0076\n",
      "Flow (3, 4) â†’ (2, 4): 0.0035\n",
      "Flow (3, 2) â†’ (4, 2): 0.0045\n",
      "Flow (1, 0) â†’ (2, 0): 0.0266\n",
      "Flow (3, 1) â†’ (4, 1): 0.0050\n",
      "Found 433 successful trajectories (431 unique)\n",
      "\n",
      "Final Loss: 0.396338\n",
      "Overall Success Rate: 0.14%\n",
      "Total Trajectories: 320000\n",
      "\n",
      "==================================================\n",
      "Running: lr=0.0001, hidden_dim=128\n",
      "==================================================\n",
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Training GFlowNet with lr=0.0001, hidden_dim=128, n_steps=10000\n",
      "Grid: 8x8, Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (lr=0.0001, hid=128): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:36<00:00, 63.87it/s, Loss=0.0001, Success=0.0%, AvgLen=16.0, TotalSucc=421]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed!\n",
      "\n",
      "Flow predictions after training (sample of 10 edges):\n",
      "Flow (5, 0) â†’ (4, 0): 0.0018\n",
      "Flow (0, 5) â†’ (0, 6): 0.0023\n",
      "Flow (6, 0) â†’ (6, 1): 0.0017\n",
      "Flow (2, 6) â†’ (1, 6): 0.0022\n",
      "Flow (2, 4) â†’ (1, 4): 0.0019\n",
      "Flow (2, 2) â†’ (3, 2): 0.0035\n",
      "Flow (3, 4) â†’ (2, 4): 0.0020\n",
      "Flow (3, 2) â†’ (4, 2): 0.0024\n",
      "Flow (1, 0) â†’ (2, 0): 0.0192\n",
      "Flow (3, 1) â†’ (4, 1): 0.0027\n",
      "Found 421 successful trajectories (416 unique)\n",
      "\n",
      "Final Loss: 0.000088\n",
      "Overall Success Rate: 0.13%\n",
      "Total Trajectories: 320000\n",
      "\n",
      "==================================================\n",
      "Running: lr=0.0001, hidden_dim=256\n",
      "==================================================\n",
      "Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n",
      "Training GFlowNet with lr=0.0001, hidden_dim=256, n_steps=10000\n",
      "Grid: 8x8, Reward region: [(6, 6), (6, 7), (7, 6), (7, 7)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (lr=0.0001, hid=256): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10000/10000 [02:50<00:00, 58.52it/s, Loss=0.0005, Success=0.0%, AvgLen=16.0, TotalSucc=426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Training completed!\n",
      "\n",
      "Flow predictions after training (sample of 10 edges):\n",
      "Flow (5, 0) â†’ (4, 0): 0.0019\n",
      "Flow (0, 5) â†’ (0, 6): 0.0025\n",
      "Flow (6, 0) â†’ (6, 1): 0.0022\n",
      "Flow (2, 2) â†’ (3, 2): 0.0037\n",
      "Flow (2, 4) â†’ (1, 4): 0.0021\n",
      "Flow (3, 4) â†’ (2, 4): 0.0021\n",
      "Flow (3, 2) â†’ (4, 2): 0.0027\n",
      "Flow (1, 0) â†’ (2, 0): 0.0244\n",
      "Flow (3, 1) â†’ (4, 1): 0.0026\n",
      "Flow (0, 2) â†’ (0, 3): 0.0095\n",
      "Found 426 successful trajectories (420 unique)\n",
      "\n",
      "Final Loss: 0.000522\n",
      "Overall Success Rate: 0.13%\n",
      "Total Trajectories: 320000\n",
      "\n",
      "============================================================\n",
      "HYPERPARAMETER SWEEP RESULTS\n",
      "============================================================\n",
      "lr=0.01, hidden_dim=64, final_loss=0.000000\n",
      "lr=0.01, hidden_dim=128, final_loss=0.000000\n",
      "lr=0.01, hidden_dim=256, final_loss=0.000000\n",
      "lr=0.001, hidden_dim=64, final_loss=0.000005\n",
      "lr=0.001, hidden_dim=128, final_loss=0.000001\n",
      "lr=0.001, hidden_dim=256, final_loss=0.000254\n",
      "lr=0.0001, hidden_dim=64, final_loss=0.396338\n",
      "lr=0.0001, hidden_dim=128, final_loss=0.000088\n",
      "lr=0.0001, hidden_dim=256, final_loss=0.000522\n",
      "\n",
      "Best configuration:\n",
      "  Learning Rate: 0.01\n",
      "  Hidden Dim: 64\n",
      "  Final Loss: 0.000000\n",
      "Sweep completed! Check MLflow UI for detailed results.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "\n",
    "def draw_trajectories_on_grid(trajectories, env, title=\"Trajectories\", save_path=None, max_trajectories=10):\n",
    "    \"\"\"\n",
    "    Utility function to draw trajectories on grid\n",
    "    \n",
    "    Args:\n",
    "        trajectories: List of trajectories (each trajectory is list of (x,y) states)\n",
    "        env: Environment with reward_states and start_state\n",
    "        title: Plot title\n",
    "        save_path: If provided, saves plot to this path\n",
    "        max_trajectories: Maximum number of trajectories to show\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    grid_size = env.size\n",
    "    \n",
    "    # Create base grid\n",
    "    ax.set_xlim(-0.5, grid_size - 0.5)\n",
    "    ax.set_ylim(-0.5, grid_size - 0.5)\n",
    "    \n",
    "    # Add grid lines\n",
    "    for i in range(grid_size + 1):\n",
    "        ax.axhline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "        ax.axvline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "    \n",
    "    # Mark start state\n",
    "    ax.scatter(env.start_state[0], env.start_state[1], c='green', s=300, \n",
    "              marker='s', label='Start', zorder=5, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Mark reward region\n",
    "    for state in env.reward_states:\n",
    "        ax.add_patch(plt.Rectangle((state[0]-0.4, state[1]-0.4), 0.8, 0.8, \n",
    "                                 facecolor='red', alpha=0.3, zorder=1))\n",
    "    ax.scatter([], [], c='red', s=200, marker='s', alpha=0.3, label='Reward Region')\n",
    "    \n",
    "    # Plot trajectories\n",
    "    colors = plt.cm.Set1(np.linspace(0, 1, min(len(trajectories), max_trajectories)))\n",
    "    \n",
    "    for i, (traj, color) in enumerate(zip(trajectories[:max_trajectories], colors)):\n",
    "        if len(traj) < 2:\n",
    "            continue\n",
    "            \n",
    "        # Extract x, y coordinates\n",
    "        xs, ys = zip(*traj)\n",
    "        \n",
    "        # Determine if successful\n",
    "        success = traj[-1] in env.reward_states\n",
    "        linestyle = '-' if success else '--'\n",
    "        alpha = 0.8 if success else 0.5\n",
    "        linewidth = 3 if success else 2\n",
    "        \n",
    "        # Plot trajectory line\n",
    "        ax.plot(xs, ys, color=color, linewidth=linewidth, alpha=alpha, \n",
    "               linestyle=linestyle, label=f'Traj {i+1} ({\"âœ“\" if success else \"âœ—\"}, len={len(traj)})')\n",
    "        \n",
    "        # Mark trajectory points (smaller for intermediate points)\n",
    "        ax.scatter(xs[1:-1], ys[1:-1], color=color, s=20, alpha=0.6, zorder=3)\n",
    "        \n",
    "        # Mark end point\n",
    "        if success:\n",
    "            ax.scatter(xs[-1], ys[-1], color=color, s=150, marker='o', \n",
    "                      edgecolor='black', linewidth=2, zorder=4)\n",
    "        else:\n",
    "            ax.scatter(xs[-1], ys[-1], color=color, s=100, marker='x', \n",
    "                      linewidth=3, zorder=4)\n",
    "    \n",
    "    ax.set_xlabel('X Position')\n",
    "    ax.set_ylabel('Y Position')\n",
    "    ax.set_title(title)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.set_aspect('equal')\n",
    "    \n",
    "    # Add grid coordinates for reference\n",
    "    ax.set_xticks(range(grid_size))\n",
    "    ax.set_yticks(range(grid_size))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def flow_conservation_loss(flow_network, visited_states, edges, rewards, encode_state_fn):\n",
    "    \"\"\"Flow conservation loss - physics constraint\"\"\"\n",
    "    total_loss = torch.tensor(0.0)\n",
    "    \n",
    "    for state in visited_states:\n",
    "        flow_in = torch.tensor(0.0)\n",
    "        flow_out = torch.tensor(0.0)\n",
    "        \n",
    "        # Flow IN - sum all flows coming into this state\n",
    "        for from_state, to_state in edges:\n",
    "            if to_state == state:\n",
    "                from_vec = encode_state_fn(from_state)\n",
    "                to_vec = encode_state_fn(to_state)\n",
    "                edge_input = torch.cat([from_vec, to_vec])\n",
    "                flow_in += flow_network(edge_input).squeeze()\n",
    "        \n",
    "        # Flow OUT - rewards + outgoing flows\n",
    "        if state in rewards:\n",
    "            flow_out += torch.tensor(rewards[state])\n",
    "        \n",
    "        for from_state, to_state in edges:\n",
    "            if from_state == state:\n",
    "                from_vec = encode_state_fn(from_state)\n",
    "                to_vec = encode_state_fn(to_state)\n",
    "                edge_input = torch.cat([from_vec, to_vec])\n",
    "                flow_out += flow_network(edge_input).squeeze()\n",
    "        \n",
    "        # Conservation constraint: Flow IN = Flow OUT\n",
    "        conservation_error = (flow_in - flow_out) ** 2\n",
    "        total_loss += conservation_error\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "class GridTrajectorySampler:\n",
    "    \"\"\"Samples random trajectories using environment API\"\"\"\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "    \n",
    "    def sample_trajectory(self, max_steps=15):\n",
    "        \"\"\"Sample a single random trajectory using environment\"\"\"\n",
    "        trajectory = [self.env.start_state]\n",
    "        state = self.env.start_state\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if self.env.is_terminal(state):\n",
    "                break\n",
    "            \n",
    "            valid_actions = self.env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break\n",
    "            \n",
    "            # Random action selection\n",
    "            action = random.choice(valid_actions)\n",
    "            next_state = self.env.take_action(state, action)\n",
    "            trajectory.append(next_state)\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def sample_batch(self, batch_size, max_steps=15):\n",
    "        \"\"\"Sample a batch of trajectories\"\"\"\n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            traj = self.sample_trajectory(max_steps)\n",
    "            trajectories.append(traj)\n",
    "        return trajectories\n",
    "\n",
    "def mlflow_experiment(lr=0.001, hidden_dim=128, n_steps=100, batch_size=32):\n",
    "    \"\"\"MLflow tracked experiment - NOTE: Experiment must be set before calling this\"\"\"\n",
    "    \n",
    "    # ======================================================================\n",
    "    # Start MLFLOW Run (not experiment - that should be set already)\n",
    "    # ======================================================================\n",
    "    with mlflow.start_run():\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"hidden_dim\", hidden_dim)\n",
    "        mlflow.log_param(\"n_steps\", n_steps)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        \n",
    "        # Setup for 8x8 grid\n",
    "        grid_size = 8\n",
    "        state_dim = grid_size * grid_size  # 64 states\n",
    "        \n",
    "        mlflow.log_param(\"grid_size\", grid_size)\n",
    "        mlflow.log_param(\"state_dim\", state_dim)\n",
    "        \n",
    "        def encode_state(state):\n",
    "            \"\"\"Convert (x,y) state to one-hot vector\"\"\"\n",
    "            x, y = state\n",
    "            idx = y * grid_size + x\n",
    "            vec = torch.zeros(state_dim)\n",
    "            vec[idx] = 1.0\n",
    "            return vec\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Experiment's Sampling methodology for gridworld env\n",
    "        # ======================================================================\n",
    "        \n",
    "        # Import environment and create trajectory sampler\n",
    "        env = HyperGrid(size=grid_size, reward_region_size=2)\n",
    "        trajectory_sampler = GridTrajectorySampler(env)\n",
    "        \n",
    "        # Get rewards from environment\n",
    "        rewards = {}\n",
    "        for state in env.reward_states:\n",
    "            rewards[state] = env.get_reward(state)\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Create flow network \n",
    "        # ======================================================================\n",
    "        flow_network = nn.Sequential(\n",
    "            nn.Linear(state_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Softplus()\n",
    "        )\n",
    "        \n",
    "        optimizer = optim.Adam(flow_network.parameters(), lr=lr)\n",
    "        \n",
    "        mlflow.log_param(\"num_reward_states\", len(rewards))\n",
    "        \n",
    "        # Extract edges and states from trajectories helper functions\n",
    "        def extract_edges_from_trajectories(trajectories):\n",
    "            edges = set()\n",
    "            for traj in trajectories:\n",
    "                for i in range(len(traj) - 1):\n",
    "                    edges.add((traj[i], traj[i + 1]))\n",
    "            return list(edges)\n",
    "        \n",
    "        def get_visited_states(trajectories):\n",
    "            states = set()\n",
    "            for traj in trajectories:\n",
    "                states.update(traj)\n",
    "            return list(states)\n",
    "        \n",
    "        print(f\"Training GFlowNet with lr={lr}, hidden_dim={hidden_dim}, n_steps={n_steps}\")\n",
    "        print(f\"Grid: {grid_size}x{grid_size}, Reward region: {sorted(env.reward_states)}\")\n",
    "        \n",
    "        # Training loop with logging\n",
    "        losses = []\n",
    "        all_trajectories = []\n",
    "        successful_trajectories = []  # Track successful trajectories separately\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Start Training with Progress Bar\n",
    "        # ======================================================================\n",
    "        \n",
    "        # Create progress bar\n",
    "        pbar = tqdm(range(n_steps), desc=f\"Training (lr={lr}, hid={hidden_dim})\")\n",
    "        \n",
    "        for step in pbar:\n",
    "            step_trajectories = []\n",
    "            \n",
    "            # ======================================================================\n",
    "            # Sample grid world\n",
    "            # ======================================================================\n",
    "            step_trajectories = trajectory_sampler.sample_batch(batch_size, max_steps=15)\n",
    "            all_trajectories.extend(step_trajectories)\n",
    "            \n",
    "            # Collect successful trajectories\n",
    "            for traj in step_trajectories:\n",
    "                if env.is_terminal(traj[-1]):\n",
    "                    successful_trajectories.append(traj)\n",
    "            \n",
    "            edges = extract_edges_from_trajectories(step_trajectories)\n",
    "            visited_states = get_visited_states(step_trajectories)\n",
    "            \n",
    "            if not edges:  # Skip if no edges (shouldn't happen)\n",
    "                continue\n",
    "            \n",
    "            # ======================================================================\n",
    "            # Compute Loss\n",
    "            # ======================================================================\n",
    "            loss = flow_conservation_loss(flow_network, visited_states, edges, rewards, encode_state)\n",
    "            \n",
    "            # Update network\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_value = loss.item()\n",
    "            losses.append(loss_value)\n",
    "            \n",
    "            # Update progress bar with current stats\n",
    "            success_count = sum(1 for traj in step_trajectories if env.is_terminal(traj[-1]))\n",
    "            success_rate = success_count / len(step_trajectories)\n",
    "            avg_length = sum(len(traj) for traj in step_trajectories) / len(step_trajectories)\n",
    "            \n",
    "            # Update progress bar description with current metrics\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss_value:.4f}',\n",
    "                'Success': f'{success_rate:.1%}',\n",
    "                'AvgLen': f'{avg_length:.1f}',\n",
    "                'TotalSucc': len(successful_trajectories)\n",
    "            })\n",
    "            \n",
    "            # ======================================================================\n",
    "            # Log metrics (less frequently for long runs)\n",
    "            # ======================================================================\n",
    "            log_interval = max(1, n_steps // 50)  # Log ~50 times total, minimum every step\n",
    "            if step % log_interval == 0:\n",
    "                mlflow.log_metric(\"loss\", loss_value, step=step)\n",
    "                mlflow.log_metric(\"success_rate\", success_rate, step=step)\n",
    "                mlflow.log_metric(\"avg_trajectory_length\", avg_length, step=step)\n",
    "        \n",
    "        pbar.close()\n",
    "        print(f\"âœ“ Training completed!\")\n",
    "        \n",
    "        # ======================================================================\n",
    "        # End Experiment\n",
    "        # ======================================================================\n",
    "        final_loss = losses[-1]\n",
    "        avg_loss = sum(losses) / len(losses)\n",
    "        min_loss = min(losses)\n",
    "        \n",
    "        mlflow.log_metric(\"final_loss\", final_loss)\n",
    "        mlflow.log_metric(\"avg_loss\", avg_loss)\n",
    "        mlflow.log_metric(\"min_loss\", min_loss)\n",
    "        \n",
    "        # Calculate overall success rate\n",
    "        total_successful = sum(1 for traj in all_trajectories if traj[-1] in rewards)\n",
    "        overall_success_rate = total_successful / len(all_trajectories)\n",
    "        mlflow.log_metric(\"overall_success_rate\", overall_success_rate)\n",
    "        mlflow.log_metric(\"total_trajectories_sampled\", len(all_trajectories))\n",
    "        \n",
    "        # Create and log loss plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(losses)\n",
    "        plt.title('Training Loss Over Time')\n",
    "        plt.xlabel('Step')\n",
    "        plt.ylabel('Flow Conservation Loss')\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"loss_curve.png\", dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact(\"loss_curve.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Test final flow predictions on a sample of edges\n",
    "        final_edges = extract_edges_from_trajectories(all_trajectories[-100:])  # Last 100 trajectories\n",
    "        print(f\"\\nFlow predictions after training (sample of {min(10, len(final_edges))} edges):\")\n",
    "        \n",
    "        for i, (from_state, to_state) in enumerate(final_edges[:10]):\n",
    "            from_vec = encode_state(from_state)\n",
    "            to_vec = encode_state(to_state)\n",
    "            edge_input = torch.cat([from_vec, to_vec])\n",
    "            flow = flow_network(edge_input).squeeze()\n",
    "            flow_value = flow.item()\n",
    "            print(f\"Flow {from_state} â†’ {to_state}: {flow_value:.4f}\")\n",
    "        \n",
    "        # ======================================================================\n",
    "        # Log successful trajectories as artifact\n",
    "        # ======================================================================\n",
    "        if successful_trajectories:\n",
    "            # Remove duplicates\n",
    "            unique_successful = []\n",
    "            seen_paths = set()\n",
    "            for traj in successful_trajectories:\n",
    "                path_tuple = tuple(traj)\n",
    "                if path_tuple not in seen_paths:\n",
    "                    unique_successful.append(traj)\n",
    "                    seen_paths.add(path_tuple)\n",
    "            \n",
    "            # Create trajectories text file\n",
    "            with open(\"successful_trajectories.txt\", \"w\") as f:\n",
    "                f.write(f\"Successful Trajectories Found During Training\\n\")\n",
    "                f.write(f\"=\"*50 + \"\\n\")\n",
    "                f.write(f\"Total successful: {len(successful_trajectories)}\\n\")\n",
    "                f.write(f\"Unique successful: {len(unique_successful)}\\n\")\n",
    "                f.write(f\"Success rate: {len(successful_trajectories)/len(all_trajectories)*100:.1f}%\\n\\n\")\n",
    "                \n",
    "                for i, traj in enumerate(unique_successful[:20]):  # Show top 20\n",
    "                    f.write(f\"Trajectory {i+1}: {traj}\\n\")\n",
    "                    f.write(f\"  Length: {len(traj)} steps\\n\")\n",
    "                    f.write(f\"  End state: {traj[-1]} (reward: {env.get_reward(traj[-1])})\\n\\n\")\n",
    "            \n",
    "            mlflow.log_artifact(\"successful_trajectories.txt\")\n",
    "            mlflow.log_metric(\"unique_successful_trajectories\", len(unique_successful))\n",
    "            \n",
    "            # ======================================================================\n",
    "            # Visualize successful trajectories\n",
    "            # ======================================================================\n",
    "            if len(unique_successful) > 0:\n",
    "                # Draw successful trajectories\n",
    "                draw_trajectories_on_grid(\n",
    "                    unique_successful[:10],  # Show top 10 successful trajectories\n",
    "                    env,\n",
    "                    title=f\"Successful Trajectories (showing {min(10, len(unique_successful))} of {len(unique_successful)})\",\n",
    "                    save_path=\"successful_trajectories_viz.png\",\n",
    "                    max_trajectories=10\n",
    "                )\n",
    "                mlflow.log_artifact(\"successful_trajectories_viz.png\")\n",
    "                \n",
    "                # Also draw a comparison with some failed trajectories\n",
    "                failed_trajectories = [traj for traj in all_trajectories[-50:] if traj[-1] not in env.reward_states]\n",
    "                if failed_trajectories:\n",
    "                    mixed_trajectories = unique_successful[:5] + failed_trajectories[:5]\n",
    "                    draw_trajectories_on_grid(\n",
    "                        mixed_trajectories,\n",
    "                        env,\n",
    "                        title=\"Successful vs Failed Trajectories\",\n",
    "                        save_path=\"success_vs_failed_trajectories.png\",\n",
    "                        max_trajectories=10\n",
    "                    )\n",
    "                    mlflow.log_artifact(\"success_vs_failed_trajectories.png\")\n",
    "            \n",
    "            print(f\"Found {len(successful_trajectories)} successful trajectories ({len(unique_successful)} unique)\")\n",
    "        else:\n",
    "            print(\"No successful trajectories found!\")\n",
    "            \n",
    "            # Still draw some failed trajectories to see what's happening\n",
    "            recent_trajectories = all_trajectories[-10:]\n",
    "            draw_trajectories_on_grid(\n",
    "                recent_trajectories,\n",
    "                env,\n",
    "                title=\"Recent Trajectories (No Successful Found)\",\n",
    "                save_path=\"recent_trajectories.png\",\n",
    "                max_trajectories=10\n",
    "            )\n",
    "            mlflow.log_artifact(\"recent_trajectories.png\")\n",
    "        \n",
    "        # Create example input for model logging\n",
    "        example_from_state = encode_state((0, 0))\n",
    "        example_to_state = encode_state((1, 0))\n",
    "        example_input = torch.cat([example_from_state, example_to_state]).unsqueeze(0)\n",
    "        \n",
    "        # Log the model\n",
    "        mlflow.pytorch.log_model(\n",
    "            flow_network,\n",
    "            \"flow_model\",\n",
    "            input_example=example_input.numpy()\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nFinal Loss: {final_loss:.6f}\")\n",
    "        print(f\"Overall Success Rate: {overall_success_rate:.2%}\")\n",
    "        print(f\"Total Trajectories: {len(all_trajectories)}\")\n",
    "        \n",
    "        return final_loss\n",
    "\n",
    "def run_hyperparameter_sweep():\n",
    "    \"\"\"Run hyperparameter sweep with MLflow - ALL RUNS IN ONE EXPERIMENT\"\"\"\n",
    "    \n",
    "    # NOTE: Experiment should already be set before calling this function\n",
    "    \n",
    "    # Hyperparameter grid\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    hidden_dims = [64, 128, 256]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Running: lr={lr}, hidden_dim={hidden_dim}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            final_loss = mlflow_experiment(lr=lr, hidden_dim=hidden_dim, n_steps=10000)\n",
    "            \n",
    "            results.append({\n",
    "                'lr': lr,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'final_loss': final_loss\n",
    "            })\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"HYPERPARAMETER SWEEP RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for result in results:\n",
    "        print(f\"lr={result['lr']}, hidden_dim={result['hidden_dim']}, final_loss={result['final_loss']:.6f}\")\n",
    "    \n",
    "    # Find best configuration\n",
    "    best_result = min(results, key=lambda x: x['final_loss'])\n",
    "    print(f\"\\nBest configuration:\")\n",
    "    print(f\"  Learning Rate: {best_result['lr']}\")\n",
    "    print(f\"  Hidden Dim: {best_result['hidden_dim']}\")\n",
    "    print(f\"  Final Loss: {best_result['final_loss']:.6f}\")\n",
    "    \n",
    "    # Log summary as artifact (will go to last run, which is fine)\n",
    "    with open(\"sweep_summary.txt\", \"w\") as f:\n",
    "        f.write(\"Hyperparameter Sweep Summary\\n\")\n",
    "        f.write(\"=\"*40 + \"\\n\\n\")\n",
    "        \n",
    "        f.write(\"All Results:\\n\")\n",
    "        for result in results:\n",
    "            f.write(f\"lr={result['lr']}, hidden_dim={result['hidden_dim']}, final_loss={result['final_loss']:.6f}\\n\")\n",
    "        \n",
    "        f.write(f\"\\nBest Configuration:\\n\")\n",
    "        f.write(f\"Learning Rate: {best_result['lr']}\\n\")\n",
    "        f.write(f\"Hidden Dim: {best_result['hidden_dim']}\\n\")\n",
    "        f.write(f\"Final Loss: {best_result['final_loss']:.6f}\\n\")\n",
    "    \n",
    "    print(\"Sweep completed! Check MLflow UI for detailed results.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ======================================================================\n",
    "    # Jupyter Notebook Safe MLflow Setup\n",
    "    # ======================================================================\n",
    "    \n",
    "    # End any existing runs (important for Jupyter notebooks)\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass  # No active run to end\n",
    "    \n",
    "    # Set experiment ONCE before running anything\n",
    "    mlflow.set_experiment(\"GFlowNet_Flow_Conservation\")\n",
    "    \n",
    "    # Run single experiment\n",
    "    # mlflow_experiment(lr=0.001, hidden_dim=128, n_steps=100)\n",
    "    \n",
    "    # Or run hyperparameter sweep\n",
    "    run_hyperparameter_sweep()\n",
    "    \n",
    "    # Clean up after sweep (good practice for notebooks)\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5199ee5-ac3d-48e1-afdc-429ef3467c04",
   "metadata": {},
   "source": [
    "## v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5cc59bfd-34cc-4f53-850e-01720d134cf2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Running TB: lr=0.01, hidden_dim=64\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hypergrid_env_only'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 461\u001b[0m\n\u001b[1;32m    455\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGFlowNet_Trajectory_Balance\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;66;03m# Run single experiment\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# trajectory_balance_experiment(lr=0.001, hidden_dim=128, n_steps=500)\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Or run hyperparameter sweep\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m \u001b[43mrun_tb_hyperparameter_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Clean up\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[31], line 421\u001b[0m, in \u001b[0;36mrun_tb_hyperparameter_sweep\u001b[0;34m()\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning TB: lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, hidden_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhidden_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 421\u001b[0m         final_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrajectory_balance_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m    429\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: lr,\n\u001b[1;32m    430\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m: hidden_dim,\n\u001b[1;32m    431\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfinal_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: final_loss\n\u001b[1;32m    432\u001b[0m         })\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# Print summary\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[31], line 210\u001b[0m, in \u001b[0;36mtrajectory_balance_experiment\u001b[0;34m(lr, hidden_dim, n_steps, batch_size)\u001b[0m\n\u001b[1;32m    207\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_param(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m, state_dim)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;66;03m# Import your environment\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhypergrid_env_only\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HyperGrid  \u001b[38;5;66;03m# Your updated environment\u001b[39;00m\n\u001b[1;32m    211\u001b[0m env \u001b[38;5;241m=\u001b[39m HyperGrid(size\u001b[38;5;241m=\u001b[39mgrid_size, reward_region_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# Create trajectory balance model\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hypergrid_env_only'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "# ====================================================\n",
    "# Trajectory Balance Model\n",
    "# ====================================================\n",
    "class TBModel(nn.Module):\n",
    "    def __init__(self, state_dim, num_hid=128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Forward policy: current state -> next action probabilities\n",
    "        self.forward_policy = nn.Sequential(\n",
    "            nn.Linear(state_dim, num_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hid, 4)  # 4 actions: right, up, left, down\n",
    "        )\n",
    "        \n",
    "        # Backward policy: current state -> previous action probabilities\n",
    "        self.backward_policy = nn.Sequential(\n",
    "            nn.Linear(state_dim, num_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hid, 4)  # 4 actions\n",
    "        )\n",
    "        \n",
    "        # Log partition function\n",
    "        self.logZ = nn.Parameter(torch.tensor(5.0))\n",
    "\n",
    "    def forward(self, state):\n",
    "        P_F_logits = self.forward_policy(state)\n",
    "        P_B_logits = self.backward_policy(state)\n",
    "        return P_F_logits, P_B_logits\n",
    "\n",
    "# ====================================================\n",
    "# Trajectory Balance Loss\n",
    "# ====================================================\n",
    "def trajectory_balance_loss(model, trajectories, env):\n",
    "    \"\"\"\n",
    "    Trajectory Balance Loss from paper equation (1):\n",
    "    L_TB = [log(Z_Î¸ * âˆP_F) - log(R(x) * âˆP_B)]Â²\n",
    "    \"\"\"\n",
    "    total_loss = torch.tensor(0.0, requires_grad=True)\n",
    "    count = 0\n",
    "    \n",
    "    for traj in trajectories:\n",
    "        if len(traj) < 2:\n",
    "            continue\n",
    "            \n",
    "        final_state = traj[-1]\n",
    "        reward = env.get_reward(final_state)\n",
    "        if reward <= 0:\n",
    "            continue\n",
    "        \n",
    "        # Forward path: Z_Î¸ * âˆP_F(s_t|s_{t-1})\n",
    "        log_forward = model.logZ\n",
    "        for i in range(len(traj) - 1):\n",
    "            current_state = traj[i]\n",
    "            next_state = traj[i + 1]\n",
    "            \n",
    "            # Encode current state\n",
    "            current_encoding = torch.tensor(env.encode_state(current_state), dtype=torch.float)\n",
    "            \n",
    "            # Get forward policy logits\n",
    "            P_F_logits, _ = model(current_encoding)\n",
    "            \n",
    "            # Mask invalid actions\n",
    "            action_mask = torch.tensor(env.get_valid_action_mask(current_state))\n",
    "            masked_logits = P_F_logits + (action_mask - 1) * 100\n",
    "            \n",
    "            # Get probabilities\n",
    "            probs = F.softmax(masked_logits, dim=0)\n",
    "            \n",
    "            # Find which action was taken\n",
    "            for action_str in env.get_valid_actions(current_state):\n",
    "                if env.take_action(current_state, action_str) == next_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    log_forward = log_forward + torch.log(probs[action_idx] + 1e-8)\n",
    "                    break\n",
    "        \n",
    "        # Backward path: R(x) * âˆP_B(s_{t-1}|s_t)\n",
    "        log_backward = torch.log(torch.tensor(reward, dtype=torch.float, requires_grad=True))\n",
    "        for i in range(len(traj) - 1, 0, -1):\n",
    "            current_state = traj[i]\n",
    "            prev_state = traj[i - 1]\n",
    "            \n",
    "            # Encode current state\n",
    "            current_encoding = torch.tensor(env.encode_state(current_state), dtype=torch.float)\n",
    "            \n",
    "            # Get backward policy logits\n",
    "            _, P_B_logits = model(current_encoding)\n",
    "            \n",
    "            # For backward policy, valid actions are those that could have led here\n",
    "            # This is trickier - we need to check which actions from neighboring states lead here\n",
    "            valid_prev_actions = []\n",
    "            for action_str in env.get_action_list():\n",
    "                action_idx = env.action_to_index(action_str)\n",
    "                if env.take_action(prev_state, action_str) == current_state:\n",
    "                    valid_prev_actions.append(action_idx)\n",
    "            \n",
    "            # Create mask for valid previous actions\n",
    "            prev_action_mask = torch.zeros(4)\n",
    "            for action_idx in valid_prev_actions:\n",
    "                prev_action_mask[action_idx] = 1.0\n",
    "            \n",
    "            masked_logits = P_B_logits + (prev_action_mask - 1) * 100\n",
    "            probs = F.softmax(masked_logits, dim=0)\n",
    "            \n",
    "            # Find which action led to current state\n",
    "            for action_str in env.get_action_list():\n",
    "                if env.take_action(prev_state, action_str) == current_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    log_backward = log_backward + torch.log(probs[action_idx] + 1e-8)\n",
    "                    break\n",
    "        \n",
    "        # Trajectory balance loss\n",
    "        loss = (log_forward - log_backward) ** 2\n",
    "        total_loss = total_loss + loss\n",
    "        count += 1\n",
    "    \n",
    "    if count == 0:\n",
    "        return torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "    return total_loss / count\n",
    "\n",
    "# ====================================================\n",
    "# Policy-based Trajectory Sampler\n",
    "# ====================================================\n",
    "class PolicyTrajectorySampler:\n",
    "    \"\"\"Sample trajectories using learned policy\"\"\"\n",
    "    \n",
    "    def __init__(self, env, model=None, epsilon=0.2):\n",
    "        self.env = env\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_trajectory(self, max_steps=15):\n",
    "        \"\"\"Sample trajectory using policy with epsilon-greedy exploration\"\"\"\n",
    "        trajectory = [self.env.start_state]\n",
    "        state = self.env.start_state\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if self.env.is_terminal(state):\n",
    "                break\n",
    "            \n",
    "            valid_actions = self.env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break\n",
    "            \n",
    "            if self.model is None or random.random() < self.epsilon:\n",
    "                # Random exploration\n",
    "                action = random.choice(valid_actions)\n",
    "            else:\n",
    "                # Use learned policy\n",
    "                state_encoding = torch.tensor(self.env.encode_state(state), dtype=torch.float)\n",
    "                P_F_logits, _ = self.model(state_encoding)\n",
    "                \n",
    "                # Mask invalid actions\n",
    "                action_mask = torch.tensor(self.env.get_valid_action_mask(state))\n",
    "                masked_logits = P_F_logits + (action_mask - 1) * 100\n",
    "                \n",
    "                # Sample from policy\n",
    "                probs = F.softmax(masked_logits, dim=0)\n",
    "                action_idx = torch.multinomial(probs, 1).item()\n",
    "                action = self.env.index_to_action(action_idx)\n",
    "            \n",
    "            next_state = self.env.take_action(state, action)\n",
    "            trajectory.append(next_state)\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def sample_batch(self, batch_size, max_steps=15):\n",
    "        \"\"\"Sample batch of trajectories\"\"\"\n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            traj = self.sample_trajectory(max_steps)\n",
    "            trajectories.append(traj)\n",
    "        return trajectories\n",
    "\n",
    "# ====================================================\n",
    "# Trajectory Balance Experiment\n",
    "# ====================================================\n",
    "def trajectory_balance_experiment(lr=0.001, hidden_dim=128, n_steps=500, batch_size=32):\n",
    "    \"\"\"Trajectory Balance GFlowNet experiment with MLflow tracking\"\"\"\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"hidden_dim\", hidden_dim)\n",
    "        mlflow.log_param(\"n_steps\", n_steps)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"method\", \"trajectory_balance\")\n",
    "        \n",
    "        # Setup environment\n",
    "        grid_size = 8\n",
    "        state_dim = grid_size * grid_size\n",
    "        \n",
    "        mlflow.log_param(\"grid_size\", grid_size)\n",
    "        mlflow.log_param(\"state_dim\", state_dim)\n",
    "        \n",
    "        # Import your environment\n",
    "        from hypergrid_env_only import HyperGrid  # Your updated environment\n",
    "        env = HyperGrid(size=grid_size, reward_region_size=2)\n",
    "        \n",
    "        # Create trajectory balance model\n",
    "        model = TBModel(state_dim, hidden_dim)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Create policy-based sampler\n",
    "        sampler = PolicyTrajectorySampler(env, model, epsilon=0.3)\n",
    "        \n",
    "        mlflow.log_param(\"epsilon\", sampler.epsilon)\n",
    "        mlflow.log_param(\"initial_logZ\", model.logZ.item())\n",
    "        \n",
    "        print(f\"Training Trajectory Balance GFlowNet with lr={lr}, hidden_dim={hidden_dim}\")\n",
    "        print(f\"Grid: {grid_size}x{grid_size}\")\n",
    "        print(f\"Initial logZ: {model.logZ.item():.4f}\")\n",
    "        \n",
    "        # Training loop\n",
    "        losses = []\n",
    "        log_z_values = []\n",
    "        all_trajectories = []\n",
    "        successful_trajectories = []\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar = tqdm(range(n_steps), desc=f\"TB Training (lr={lr}, hid={hidden_dim})\")\n",
    "        \n",
    "        for step in pbar:\n",
    "            # Sample trajectories using current policy\n",
    "            step_trajectories = sampler.sample_batch(batch_size, max_steps=20)\n",
    "            all_trajectories.extend(step_trajectories)\n",
    "            \n",
    "            # Collect successful trajectories\n",
    "            for traj in step_trajectories:\n",
    "                if env.is_terminal(traj[-1]):\n",
    "                    successful_trajectories.append(traj)\n",
    "            \n",
    "            # Compute trajectory balance loss\n",
    "            loss = trajectory_balance_loss(model, step_trajectories, env)\n",
    "            \n",
    "            # Update model\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_value = loss.item()\n",
    "            losses.append(loss_value)\n",
    "            log_z_values.append(model.logZ.item())\n",
    "            \n",
    "            # Update progress bar\n",
    "            success_count = sum(1 for traj in step_trajectories if env.is_terminal(traj[-1]))\n",
    "            success_rate = success_count / len(step_trajectories)\n",
    "            avg_length = sum(len(traj) for traj in step_trajectories) / len(step_trajectories)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss_value:.4f}',\n",
    "                'LogZ': f'{model.logZ.item():.3f}',\n",
    "                'Success': f'{success_rate:.1%}',\n",
    "                'AvgLen': f'{avg_length:.1f}',\n",
    "                'TotalSucc': len(successful_trajectories)\n",
    "            })\n",
    "            \n",
    "            # Log metrics\n",
    "            log_interval = max(1, n_steps // 50)\n",
    "            if step % log_interval == 0:\n",
    "                mlflow.log_metric(\"loss\", loss_value, step=step)\n",
    "                mlflow.log_metric(\"logZ\", model.logZ.item(), step=step)\n",
    "                mlflow.log_metric(\"success_rate\", success_rate, step=step)\n",
    "                mlflow.log_metric(\"avg_trajectory_length\", avg_length, step=step)\n",
    "        \n",
    "        pbar.close()\n",
    "        \n",
    "        # Final metrics\n",
    "        final_loss = losses[-1]\n",
    "        final_logZ = log_z_values[-1]\n",
    "        final_Z = math.exp(final_logZ)\n",
    "        \n",
    "        mlflow.log_metric(\"final_loss\", final_loss)\n",
    "        mlflow.log_metric(\"final_logZ\", final_logZ)\n",
    "        mlflow.log_metric(\"final_Z\", final_Z)\n",
    "        \n",
    "        # Overall success rate\n",
    "        total_successful = sum(1 for traj in all_trajectories if env.is_terminal(traj[-1]))\n",
    "        overall_success_rate = total_successful / len(all_trajectories)\n",
    "        mlflow.log_metric(\"overall_success_rate\", overall_success_rate)\n",
    "        mlflow.log_metric(\"total_trajectories_sampled\", len(all_trajectories))\n",
    "        \n",
    "        # Create training plots\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(losses)\n",
    "        ax1.set_title('Trajectory Balance Loss')\n",
    "        ax1.set_xlabel('Step')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # LogZ evolution\n",
    "        ax2.plot(log_z_values)\n",
    "        ax2.set_title('Log Partition Function Evolution')\n",
    "        ax2.set_xlabel('Step')\n",
    "        ax2.set_ylabel('Log Z')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        # Success rate over time\n",
    "        window_size = max(1, len(all_trajectories) // 20)\n",
    "        success_rates = []\n",
    "        for i in range(0, len(all_trajectories), window_size):\n",
    "            window_trajs = all_trajectories[i:i+window_size]\n",
    "            window_success = sum(1 for traj in window_trajs if env.is_terminal(traj[-1])) / len(window_trajs)\n",
    "            success_rates.append(window_success)\n",
    "        \n",
    "        ax3.plot(success_rates)\n",
    "        ax3.set_title('Success Rate Over Training')\n",
    "        ax3.set_xlabel('Window')\n",
    "        ax3.set_ylabel('Success Rate')\n",
    "        ax3.grid(True)\n",
    "        \n",
    "        # Trajectory length distribution\n",
    "        lengths = [len(traj) for traj in all_trajectories[-200:]]\n",
    "        ax4.hist(lengths, bins=15, alpha=0.7)\n",
    "        ax4.set_title('Trajectory Length Distribution (Recent)')\n",
    "        ax4.set_xlabel('Length')\n",
    "        ax4.set_ylabel('Count')\n",
    "        ax4.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"tb_training_summary.png\", dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact(\"tb_training_summary.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Test final policy\n",
    "        print(f\"\\nðŸŽ¯ Testing final policy...\")\n",
    "        model.eval()\n",
    "        \n",
    "        # Sample with learned policy (no exploration)\n",
    "        test_sampler = PolicyTrajectorySampler(env, model, epsilon=0.0)\n",
    "        test_trajectories = test_sampler.sample_batch(100, max_steps=20)\n",
    "        \n",
    "        test_successful = sum(1 for traj in test_trajectories if env.is_terminal(traj[-1]))\n",
    "        test_success_rate = test_successful / len(test_trajectories)\n",
    "        \n",
    "        mlflow.log_metric(\"test_success_rate\", test_success_rate)\n",
    "        \n",
    "        # Log results\n",
    "        if successful_trajectories:\n",
    "            unique_successful = []\n",
    "            seen_paths = set()\n",
    "            for traj in successful_trajectories:\n",
    "                path_tuple = tuple(traj)\n",
    "                if path_tuple not in seen_paths:\n",
    "                    unique_successful.append(traj)\n",
    "                    seen_paths.add(path_tuple)\n",
    "            \n",
    "            mlflow.log_metric(\"unique_successful_trajectories\", len(unique_successful))\n",
    "            \n",
    "            # Save trajectory analysis\n",
    "            with open(\"tb_trajectory_analysis.txt\", \"w\") as f:\n",
    "                f.write(\"Trajectory Balance GFlowNet Results\\n\")\n",
    "                f.write(\"=\"*50 + \"\\n\\n\")\n",
    "                f.write(f\"Final Loss: {final_loss:.6f}\\n\")\n",
    "                f.write(f\"Final LogZ: {final_logZ:.4f}\\n\")\n",
    "                f.write(f\"Final Z: {final_Z:.4f}\\n\")\n",
    "                f.write(f\"Training Success Rate: {overall_success_rate:.2%}\\n\")\n",
    "                f.write(f\"Test Success Rate: {test_success_rate:.2%}\\n\")\n",
    "                f.write(f\"Total Successful: {len(successful_trajectories)}\\n\")\n",
    "                f.write(f\"Unique Successful: {len(unique_successful)}\\n\\n\")\n",
    "                \n",
    "                f.write(\"Sample successful trajectories:\\n\")\n",
    "                for i, traj in enumerate(unique_successful[:10]):\n",
    "                    f.write(f\"  {i+1}: {traj} (length: {len(traj)})\\n\")\n",
    "            \n",
    "            mlflow.log_artifact(\"tb_trajectory_analysis.txt\")\n",
    "            \n",
    "            print(f\"Found {len(successful_trajectories)} successful trajectories ({len(unique_successful)} unique)\")\n",
    "        else:\n",
    "            print(\"No successful trajectories found!\")\n",
    "        \n",
    "        # Save model weights\n",
    "        torch.save(model.state_dict(), \"tb_model_weights.pth\")\n",
    "        mlflow.log_artifact(\"tb_model_weights.pth\")\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Final Results:\")\n",
    "        print(f\"   Loss: {final_loss:.6f}\")\n",
    "        print(f\"   LogZ: {final_logZ:.4f} (Z = {final_Z:.4f})\")\n",
    "        print(f\"   Training Success: {overall_success_rate:.2%}\")\n",
    "        print(f\"   Test Success: {test_success_rate:.2%}\")\n",
    "        \n",
    "        return final_loss\n",
    "\n",
    "# ====================================================\n",
    "# Hyperparameter Sweep\n",
    "# ====================================================\n",
    "def run_tb_hyperparameter_sweep():\n",
    "    \"\"\"Run trajectory balance hyperparameter sweep\"\"\"\n",
    "    \n",
    "    # Hyperparameter grid\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    hidden_dims = [64, 128, 256]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"Running TB: lr={lr}, hidden_dim={hidden_dim}\")\n",
    "            print(f\"{'='*50}\")\n",
    "            \n",
    "            final_loss = trajectory_balance_experiment(\n",
    "                lr=lr, \n",
    "                hidden_dim=hidden_dim, \n",
    "                n_steps=1000,\n",
    "                batch_size=32\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'lr': lr,\n",
    "                'hidden_dim': hidden_dim,\n",
    "                'final_loss': final_loss\n",
    "            })\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TRAJECTORY BALANCE HYPERPARAMETER SWEEP RESULTS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    for result in results:\n",
    "        print(f\"lr={result['lr']}, hidden_dim={result['hidden_dim']}, final_loss={result['final_loss']:.6f}\")\n",
    "    \n",
    "    # Find best configuration\n",
    "    best_result = min(results, key=lambda x: x['final_loss'])\n",
    "    print(f\"\\nBest configuration:\")\n",
    "    print(f\"  Learning Rate: {best_result['lr']}\")\n",
    "    print(f\"  Hidden Dim: {best_result['hidden_dim']}\")\n",
    "    print(f\"  Final Loss: {best_result['final_loss']:.6f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # MLflow setup\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mlflow.set_experiment(\"GFlowNet_Trajectory_Balance\")\n",
    "    \n",
    "    # Run single experiment\n",
    "    # trajectory_balance_experiment(lr=0.001, hidden_dim=128, n_steps=500)\n",
    "    \n",
    "    # Or run hyperparameter sweep\n",
    "    run_tb_hyperparameter_sweep()\n",
    "    \n",
    "    # Clean up\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ad867-2acc-4279-8bf9-2b699d3a0567",
   "metadata": {},
   "source": [
    "## v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1392cc6a-e647-467f-ab59-edda2507bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid size: 8x8\n",
      "Goal region: x >= 6, y >= 6\n",
      "State encoding dimension: 64\n",
      "ðŸš€ Training Trajectory Balance GFlowNet\n",
      "   Grid: 8x8\n",
      "   State dim: 64\n",
      "   Hidden dim: 128\n",
      "   Learning rate: 0.001\n",
      "   Initial logZ: 5.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TB Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [01:01<00:00, 16.38it/s, Loss=148.7403, LogZ=6.007, Success=46.9%, AvgLen=19.7, TotalSucc=10786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Final evaluation...\n",
      "âœ… Found 10786 successful trajectories (10596 unique)\n",
      "\n",
      "ðŸ“Š Final Results:\n",
      "   Loss: 148.740280\n",
      "   LogZ: 6.0068 (Z = 406.1627)\n",
      "   Training Success: 33.71%\n",
      "   Test Success: 81.00%\n",
      "   Total Trajectories: 32000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from typing import List, Tuple, Dict, Union\n",
    "\n",
    "# ====================================================\n",
    "# Enhanced HyperGrid Environment (with bounds checking)\n",
    "# ====================================================\n",
    "class HyperGrid:\n",
    "    \"\"\"8x8 HyperGrid environment for GFlowNet - All methods use encoded states\"\"\"\n",
    "    \n",
    "    def __init__(self, size: int = 8, reward_region_size: int = 2) -> None:\n",
    "        self.size = size\n",
    "        self.reward_region_size = reward_region_size\n",
    "        \n",
    "        # Define goal region bounds (computed, not stored)\n",
    "        self.goal_min_x = size - reward_region_size\n",
    "        self.goal_min_y = size - reward_region_size\n",
    "        \n",
    "        # Start state as encoded\n",
    "        self.start_state = tuple(self.encode_raw_state((0, 0)))\n",
    "        \n",
    "        print(f\"Grid size: {size}x{size}\")\n",
    "        print(f\"Goal region: x >= {self.goal_min_x}, y >= {self.goal_min_y}\")\n",
    "        print(f\"State encoding dimension: {self.get_state_dim()}\")\n",
    "    \n",
    "    # ====================================================\n",
    "    # State encoding utilities\n",
    "    # ====================================================\n",
    "    \n",
    "    def encode_raw_state(self, raw_state: Tuple[int, int]) -> List[float]:\n",
    "        \"\"\"Convert raw (x,y) state to encoded one-hot vector\"\"\"\n",
    "        x, y = raw_state\n",
    "        idx = y * self.size + x\n",
    "        encoding = [0.0] * (self.size * self.size)\n",
    "        encoding[idx] = 1.0\n",
    "        return encoding\n",
    "    \n",
    "    def decode_state_to_raw(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> Tuple[int, int]:\n",
    "        \"\"\"Convert encoded state back to raw (x,y) tuple\"\"\"\n",
    "        if isinstance(encoded_state, tuple):\n",
    "            encoded_state = list(encoded_state)\n",
    "        \n",
    "        idx = encoded_state.index(1.0)\n",
    "        x = idx % self.size\n",
    "        y = idx // self.size\n",
    "        return (x, y)\n",
    "    \n",
    "    def get_state_dim(self) -> int:\n",
    "        \"\"\"Get the dimension of encoded states\"\"\"\n",
    "        return self.size * self.size\n",
    "    \n",
    "    # ====================================================\n",
    "    # Actions (work with encoded states + bounds checking)\n",
    "    # ====================================================    \n",
    "    \n",
    "    def get_valid_actions(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[str]:\n",
    "        \"\"\"Get valid actions from an encoded state\"\"\"\n",
    "        # Convert to raw to check boundaries\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        actions = []\n",
    "        \n",
    "        if x + 1 < self.size:\n",
    "            actions.append('right')\n",
    "        if y + 1 < self.size:\n",
    "            actions.append('up')\n",
    "        if x - 1 >= 0:\n",
    "            actions.append('left')\n",
    "        if y - 1 >= 0:\n",
    "            actions.append('down')\n",
    "            \n",
    "        return actions\n",
    "    \n",
    "    def take_action(self, encoded_state: Union[List[float], Tuple[float, ...]], action: str) -> Tuple[float, ...]:\n",
    "        \"\"\"Take action from encoded state to get next encoded state (with bounds checking)\"\"\"\n",
    "        # Convert to raw, take action with bounds checking, convert back\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        \n",
    "        if action == 'right' and x + 1 < self.size:\n",
    "            new_raw = (x + 1, y)\n",
    "        elif action == 'up' and y + 1 < self.size:\n",
    "            new_raw = (x, y + 1)\n",
    "        elif action == 'left' and x - 1 >= 0:\n",
    "            new_raw = (x - 1, y)\n",
    "        elif action == 'down' and y - 1 >= 0:\n",
    "            new_raw = (x, y - 1)\n",
    "        else:\n",
    "            # Invalid action - stay in same state\n",
    "            new_raw = (x, y)\n",
    "        \n",
    "        return tuple(self.encode_raw_state(new_raw))\n",
    "    \n",
    "    # ====================================================\n",
    "    # Action encoding\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_action_list(self) -> List[str]:\n",
    "        \"\"\"Get list of all possible actions\"\"\"\n",
    "        return ['right', 'up', 'left', 'down']\n",
    "    \n",
    "    def action_to_index(self, action: str) -> int:\n",
    "        \"\"\"Convert action string to index\"\"\"\n",
    "        action_map = {'right': 0, 'up': 1, 'left': 2, 'down': 3}\n",
    "        return action_map.get(action, -1)\n",
    "    \n",
    "    def index_to_action(self, index: int) -> str:\n",
    "        \"\"\"Convert action index to string\"\"\"\n",
    "        actions = ['right', 'up', 'left', 'down']\n",
    "        return actions[index] if 0 <= index < len(actions) else 'right'\n",
    "    \n",
    "    def get_action_dim(self) -> int:\n",
    "        \"\"\"Get number of possible actions\"\"\"\n",
    "        return 4\n",
    "    \n",
    "    # ====================================================\n",
    "    # Action masking (work with encoded states)\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_valid_action_mask(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[float]:\n",
    "        \"\"\"Get binary mask for valid actions\"\"\"\n",
    "        valid_actions = self.get_valid_actions(encoded_state)\n",
    "        mask = [0.0] * 4\n",
    "        for action in valid_actions:\n",
    "            idx = self.action_to_index(action)\n",
    "            if idx >= 0:\n",
    "                mask[idx] = 1.0\n",
    "        return mask\n",
    "    \n",
    "    # ====================================================\n",
    "    # REWARD (work with encoded states using bounds checking)\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_reward(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> float:\n",
    "        \"\"\"Get reward for an encoded state using bounds checking\"\"\"\n",
    "        # Convert to raw coordinates for bounds checking\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        \n",
    "        # Check if in goal region using bounds\n",
    "        if x >= self.goal_min_x and y >= self.goal_min_y:\n",
    "            return 1.0\n",
    "        return 0.0\n",
    "    \n",
    "    def is_terminal(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> bool:\n",
    "        \"\"\"Check if encoded state is terminal\"\"\"\n",
    "        return self.get_reward(encoded_state) > 0.0\n",
    "\n",
    "# ====================================================\n",
    "# Trajectory Balance Model\n",
    "# ====================================================\n",
    "class TBModel(nn.Module):\n",
    "    \"\"\"Trajectory Balance GFlowNet Model\"\"\"\n",
    "    \n",
    "    def __init__(self, state_dim: int, num_hid: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Forward policy: current state -> next action probabilities\n",
    "        self.forward_policy = nn.Sequential(\n",
    "            nn.Linear(state_dim, num_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hid, 4)  # 4 actions: right, up, left, down\n",
    "        )\n",
    "        \n",
    "        # Backward policy: current state -> previous action probabilities\n",
    "        self.backward_policy = nn.Sequential(\n",
    "            nn.Linear(state_dim, num_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hid, 4)  # 4 actions\n",
    "        )\n",
    "        \n",
    "        # Log partition function\n",
    "        self.logZ = nn.Parameter(torch.tensor(5.0))\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        P_F_logits = self.forward_policy(state)\n",
    "        P_B_logits = self.backward_policy(state)\n",
    "        return P_F_logits, P_B_logits\n",
    "\n",
    "# ====================================================\n",
    "# Trajectory Balance Loss Function\n",
    "# ====================================================\n",
    "def trajectory_balance_loss(model: TBModel, trajectories: List[List[Tuple[float, ...]]], env: HyperGrid) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Optimized Trajectory Balance Loss with early filtering\n",
    "    \"\"\"\n",
    "    # Early check: Filter for rewarded trajectories upfront\n",
    "    rewarded_trajectories = []\n",
    "    for traj in trajectories:\n",
    "        if len(traj) >= 2:  # Valid length\n",
    "            final_state = traj[-1]\n",
    "            reward = env.get_reward(final_state)\n",
    "            if reward > 0:  # Has reward\n",
    "                rewarded_trajectories.append((traj, reward))\n",
    "    \n",
    "    # Early exit if no valid trajectories\n",
    "    if len(rewarded_trajectories) == 0:\n",
    "        return torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "    # Process only rewarded trajectories\n",
    "    total_loss = torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "    for traj, reward in rewarded_trajectories:\n",
    "        \n",
    "        # FORWARD path: Z_Î¸ * âˆP_F(s_t|s_{t-1})\n",
    "        log_forward = model.logZ\n",
    "        \n",
    "        for step in range(len(traj) - 1):\n",
    "            current_state = traj[step]\n",
    "            next_state = traj[step + 1]\n",
    "            \n",
    "            # Encode current state for neural network\n",
    "            current_tensor = torch.tensor(list(current_state), dtype=torch.float)\n",
    "            \n",
    "            # Get forward policy logits\n",
    "            P_F_logits, _ = model(current_tensor)\n",
    "            \n",
    "            # Mask invalid actions using vectorized operation\n",
    "            action_mask = torch.tensor(env.get_valid_action_mask(current_state))\n",
    "            masked_logits = P_F_logits.where(action_mask.bool(), torch.tensor(-100.0))\n",
    "            \n",
    "            # Get probabilities\n",
    "            probs = F.softmax(masked_logits, dim=0)\n",
    "            \n",
    "            # Find which action was taken\n",
    "            for action_str in env.get_valid_actions(current_state):\n",
    "                if env.take_action(current_state, action_str) == next_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    log_forward = log_forward + torch.log(probs[action_idx].clamp(min=1e-8))\n",
    "                    break\n",
    "        \n",
    "        # BACKWARD path: R(x) * âˆP_B(s_{t-1}|s_t)\n",
    "        log_backward = torch.log(torch.tensor(reward, dtype=torch.float, requires_grad=True))\n",
    "        \n",
    "        for step in range(len(traj) - 1, 0, -1):\n",
    "            current_state = traj[step]\n",
    "            prev_state = traj[step - 1]\n",
    "            \n",
    "            # Encode current state\n",
    "            current_tensor = torch.tensor(list(current_state), dtype=torch.float)\n",
    "            \n",
    "            # Get backward policy logits\n",
    "            _, P_B_logits = model(current_tensor)\n",
    "            \n",
    "            # Find valid previous actions (safely with bounds checking)\n",
    "            valid_prev_actions = []\n",
    "            for action_str in env.get_action_list():\n",
    "                # Check if taking this action from prev_state leads to current_state\n",
    "                test_next_state = env.take_action(prev_state, action_str)\n",
    "                if test_next_state == current_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    valid_prev_actions.append(action_idx)\n",
    "            \n",
    "            # Create mask and apply vectorized masking\n",
    "            prev_action_mask = torch.zeros(4)\n",
    "            for action_idx in valid_prev_actions:\n",
    "                prev_action_mask[action_idx] = 1.0\n",
    "            \n",
    "            masked_logits = P_B_logits.where(prev_action_mask.bool(), torch.tensor(-100.0))\n",
    "            probs = F.softmax(masked_logits, dim=0)\n",
    "            \n",
    "            # Find which action led to current state\n",
    "            for action_str in env.get_action_list():\n",
    "                test_next_state = env.take_action(prev_state, action_str)\n",
    "                if test_next_state == current_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    log_backward = log_backward + torch.log(probs[action_idx].clamp(min=1e-8))\n",
    "                    break\n",
    "        \n",
    "        # Apply trajectory balance equation\n",
    "        trajectory_loss = (log_forward - log_backward) ** 2\n",
    "        total_loss = total_loss + trajectory_loss\n",
    "    \n",
    "    return total_loss / len(rewarded_trajectories)\n",
    "\n",
    "# ====================================================\n",
    "# Policy-based Trajectory Sampler\n",
    "# ====================================================\n",
    "class PolicyTrajectorySampler:\n",
    "    \"\"\"Sample trajectories using learned policy with encoded states\"\"\"\n",
    "    \n",
    "    def __init__(self, env: HyperGrid, model: TBModel = None, epsilon: float = 0.2):\n",
    "        self.env = env\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_trajectory(self, max_steps: int = 20) -> List[Tuple[float, ...]]:\n",
    "        \"\"\"Sample trajectory using policy with epsilon-greedy exploration\"\"\"\n",
    "        trajectory = [self.env.start_state]\n",
    "        state = self.env.start_state\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if self.env.is_terminal(state):\n",
    "                break\n",
    "            \n",
    "            valid_actions = self.env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break\n",
    "            \n",
    "            if self.model is None or random.random() < self.epsilon:\n",
    "                # Random exploration\n",
    "                action = random.choice(valid_actions)\n",
    "            else:\n",
    "                # Use learned policy\n",
    "                state_tensor = torch.tensor(list(state), dtype=torch.float)\n",
    "                P_F_logits, _ = self.model(state_tensor)\n",
    "                \n",
    "                # Mask invalid actions\n",
    "                action_mask = torch.tensor(self.env.get_valid_action_mask(state))\n",
    "                masked_logits = P_F_logits.where(action_mask.bool(), torch.tensor(-100.0))\n",
    "                \n",
    "                # Sample from policy\n",
    "                probs = F.softmax(masked_logits, dim=0)\n",
    "                action_idx = torch.multinomial(probs, 1).item()\n",
    "                action = self.env.index_to_action(action_idx)\n",
    "            \n",
    "            next_state = self.env.take_action(state, action)\n",
    "            trajectory.append(next_state)\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def sample_batch(self, batch_size: int, max_steps: int = 20) -> List[List[Tuple[float, ...]]]:\n",
    "        \"\"\"Sample batch of trajectories\"\"\"\n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            traj = self.sample_trajectory(max_steps)\n",
    "            trajectories.append(traj)\n",
    "        return trajectories\n",
    "\n",
    "# ====================================================\n",
    "# MLflow Trajectory Balance Experiment\n",
    "# ====================================================\n",
    "def trajectory_balance_experiment(\n",
    "    lr: float = 0.001, \n",
    "    hidden_dim: int = 128, \n",
    "    n_steps: int = 1000, \n",
    "    batch_size: int = 32,\n",
    "    grid_size: int = 8,\n",
    "    reward_region_size: int = 2,\n",
    "    epsilon: float = 0.3,\n",
    "    max_trajectory_steps: int = 20\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Complete trajectory balance experiment with MLflow tracking\n",
    "    \"\"\"\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        # ====================================================\n",
    "        # Log Hyperparameters\n",
    "        # ====================================================\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"hidden_dim\", hidden_dim)\n",
    "        mlflow.log_param(\"n_steps\", n_steps)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"grid_size\", grid_size)\n",
    "        mlflow.log_param(\"reward_region_size\", reward_region_size)\n",
    "        mlflow.log_param(\"epsilon\", epsilon)\n",
    "        mlflow.log_param(\"max_trajectory_steps\", max_trajectory_steps)\n",
    "        mlflow.log_param(\"method\", \"trajectory_balance\")\n",
    "        \n",
    "        # ====================================================\n",
    "        # Setup Environment and Model\n",
    "        # ====================================================\n",
    "        env = HyperGrid(size=grid_size, reward_region_size=reward_region_size)\n",
    "        state_dim = env.get_state_dim()\n",
    "        \n",
    "        mlflow.log_param(\"state_dim\", state_dim)\n",
    "        \n",
    "        # Create model and optimizer\n",
    "        model = TBModel(state_dim, hidden_dim)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Create policy-based sampler\n",
    "        sampler = PolicyTrajectorySampler(env, model, epsilon)\n",
    "        \n",
    "        mlflow.log_param(\"initial_logZ\", model.logZ.item())\n",
    "        \n",
    "        print(f\"ðŸš€ Training Trajectory Balance GFlowNet\")\n",
    "        print(f\"   Grid: {grid_size}x{grid_size}\")\n",
    "        print(f\"   State dim: {state_dim}\")\n",
    "        print(f\"   Hidden dim: {hidden_dim}\")\n",
    "        print(f\"   Learning rate: {lr}\")\n",
    "        print(f\"   Initial logZ: {model.logZ.item():.4f}\")\n",
    "        \n",
    "        # ====================================================\n",
    "        # Training Loop\n",
    "        # ====================================================\n",
    "        losses = []\n",
    "        log_z_values = []\n",
    "        all_trajectories = []\n",
    "        successful_trajectories = []\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar = tqdm(range(n_steps), desc=f\"TB Training\")\n",
    "        \n",
    "        for step in pbar:\n",
    "            # Sample trajectories using current policy\n",
    "            step_trajectories = sampler.sample_batch(batch_size, max_trajectory_steps)\n",
    "            all_trajectories.extend(step_trajectories)\n",
    "            \n",
    "            # Collect successful trajectories\n",
    "            for traj in step_trajectories:\n",
    "                if env.is_terminal(traj[-1]):\n",
    "                    successful_trajectories.append(traj)\n",
    "            \n",
    "            # Compute trajectory balance loss\n",
    "            loss = trajectory_balance_loss(model, step_trajectories, env)\n",
    "            \n",
    "            # Update model\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_value = loss.item()\n",
    "            losses.append(loss_value)\n",
    "            log_z_values.append(model.logZ.item())\n",
    "            \n",
    "            # Update progress bar\n",
    "            success_count = sum(1 for traj in step_trajectories if env.is_terminal(traj[-1]))\n",
    "            success_rate = success_count / len(step_trajectories)\n",
    "            avg_length = sum(len(traj) for traj in step_trajectories) / len(step_trajectories)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss_value:.4f}',\n",
    "                'LogZ': f'{model.logZ.item():.3f}',\n",
    "                'Success': f'{success_rate:.1%}',\n",
    "                'AvgLen': f'{avg_length:.1f}',\n",
    "                'TotalSucc': len(successful_trajectories)\n",
    "            })\n",
    "            \n",
    "            # Log metrics periodically\n",
    "            log_interval = max(1, n_steps // 50)\n",
    "            if step % log_interval == 0:\n",
    "                mlflow.log_metric(\"loss\", loss_value, step=step)\n",
    "                mlflow.log_metric(\"logZ\", model.logZ.item(), step=step)\n",
    "                mlflow.log_metric(\"success_rate\", success_rate, step=step)\n",
    "                mlflow.log_metric(\"avg_trajectory_length\", avg_length, step=step)\n",
    "        \n",
    "        pbar.close()\n",
    "        \n",
    "        # ====================================================\n",
    "        # Final Evaluation\n",
    "        # ====================================================\n",
    "        print(f\"ðŸŽ¯ Final evaluation...\")\n",
    "        \n",
    "        # Test final policy (no exploration)\n",
    "        model.eval()\n",
    "        test_sampler = PolicyTrajectorySampler(env, model, epsilon=0.0)\n",
    "        test_trajectories = test_sampler.sample_batch(100, max_trajectory_steps)\n",
    "        \n",
    "        test_successful = sum(1 for traj in test_trajectories if env.is_terminal(traj[-1]))\n",
    "        test_success_rate = test_successful / len(test_trajectories)\n",
    "        \n",
    "        # Final metrics\n",
    "        final_loss = losses[-1]\n",
    "        final_logZ = log_z_values[-1]\n",
    "        final_Z = math.exp(final_logZ)\n",
    "        \n",
    "        # Overall training success rate\n",
    "        total_successful = sum(1 for traj in all_trajectories if env.is_terminal(traj[-1]))\n",
    "        overall_success_rate = total_successful / len(all_trajectories)\n",
    "        \n",
    "        # Log final metrics\n",
    "        mlflow.log_metric(\"final_loss\", final_loss)\n",
    "        mlflow.log_metric(\"final_logZ\", final_logZ)\n",
    "        mlflow.log_metric(\"final_Z\", final_Z)\n",
    "        mlflow.log_metric(\"training_success_rate\", overall_success_rate)\n",
    "        mlflow.log_metric(\"test_success_rate\", test_success_rate)\n",
    "        mlflow.log_metric(\"total_trajectories_sampled\", len(all_trajectories))\n",
    "        \n",
    "        # ====================================================\n",
    "        # Create Visualizations\n",
    "        # ====================================================\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss curve\n",
    "        ax1.plot(losses)\n",
    "        ax1.set_title('Trajectory Balance Loss')\n",
    "        ax1.set_xlabel('Step')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # LogZ evolution\n",
    "        ax2.plot(log_z_values)\n",
    "        ax2.set_title('Log Partition Function Evolution')\n",
    "        ax2.set_xlabel('Step')\n",
    "        ax2.set_ylabel('Log Z')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        # Success rate over time\n",
    "        window_size = max(1, len(all_trajectories) // 20)\n",
    "        success_rates = []\n",
    "        for i in range(0, len(all_trajectories), window_size):\n",
    "            window_trajs = all_trajectories[i:i+window_size]\n",
    "            window_success = sum(1 for traj in window_trajs if env.is_terminal(traj[-1])) / len(window_trajs)\n",
    "            success_rates.append(window_success)\n",
    "        \n",
    "        ax3.plot(success_rates)\n",
    "        ax3.set_title('Success Rate Over Training')\n",
    "        ax3.set_xlabel('Window')\n",
    "        ax3.set_ylabel('Success Rate')\n",
    "        ax3.grid(True)\n",
    "        \n",
    "        # Trajectory length distribution\n",
    "        lengths = [len(traj) for traj in all_trajectories[-200:]]\n",
    "        ax4.hist(lengths, bins=15, alpha=0.7)\n",
    "        ax4.set_title('Trajectory Length Distribution (Recent)')\n",
    "        ax4.set_xlabel('Length')\n",
    "        ax4.set_ylabel('Count')\n",
    "        ax4.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"tb_training_summary.png\", dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact(\"tb_training_summary.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # ====================================================\n",
    "        # Log Results Summary\n",
    "        # ====================================================\n",
    "        if successful_trajectories:\n",
    "            unique_successful = []\n",
    "            seen_paths = set()\n",
    "            for traj in successful_trajectories:\n",
    "                # Convert to raw coordinates for deduplication\n",
    "                raw_path = tuple(env.decode_state_to_raw(state) for state in traj)\n",
    "                if raw_path not in seen_paths:\n",
    "                    unique_successful.append(traj)\n",
    "                    seen_paths.add(raw_path)\n",
    "            \n",
    "            mlflow.log_metric(\"unique_successful_trajectories\", len(unique_successful))\n",
    "            \n",
    "            # Save analysis\n",
    "            with open(\"tb_results.txt\", \"w\") as f:\n",
    "                f.write(\"Trajectory Balance GFlowNet Results\\n\")\n",
    "                f.write(\"=\"*50 + \"\\n\\n\")\n",
    "                f.write(f\"Hyperparameters:\\n\")\n",
    "                f.write(f\"  Learning Rate: {lr}\\n\")\n",
    "                f.write(f\"  Hidden Dim: {hidden_dim}\\n\")\n",
    "                f.write(f\"  Grid Size: {grid_size}x{grid_size}\\n\")\n",
    "                f.write(f\"  Training Steps: {n_steps}\\n\")\n",
    "                f.write(f\"  Batch Size: {batch_size}\\n\\n\")\n",
    "                f.write(f\"Results:\\n\")\n",
    "                f.write(f\"  Final Loss: {final_loss:.6f}\\n\")\n",
    "                f.write(f\"  Final LogZ: {final_logZ:.4f} (Z = {final_Z:.4f})\\n\")\n",
    "                f.write(f\"  Training Success Rate: {overall_success_rate:.2%}\\n\")\n",
    "                f.write(f\"  Test Success Rate: {test_success_rate:.2%}\\n\")\n",
    "                f.write(f\"  Total Trajectories: {len(all_trajectories)}\\n\")\n",
    "                f.write(f\"  Successful Trajectories: {len(successful_trajectories)}\\n\")\n",
    "                f.write(f\"  Unique Successful: {len(unique_successful)}\\n\\n\")\n",
    "                \n",
    "                f.write(\"Sample successful paths (raw coordinates):\\n\")\n",
    "                for i, traj in enumerate(unique_successful[:10]):\n",
    "                    raw_path = [env.decode_state_to_raw(state) for state in traj]\n",
    "                    f.write(f\"  {i+1}: {raw_path} (length: {len(traj)})\\n\")\n",
    "            \n",
    "            mlflow.log_artifact(\"tb_results.txt\")\n",
    "            \n",
    "            print(f\"âœ… Found {len(successful_trajectories)} successful trajectories ({len(unique_successful)} unique)\")\n",
    "        else:\n",
    "            print(\"âŒ No successful trajectories found!\")\n",
    "        \n",
    "        # Save model weights\n",
    "        torch.save(model.state_dict(), \"tb_model_weights.pth\")\n",
    "        mlflow.log_artifact(\"tb_model_weights.pth\")\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Final Results:\")\n",
    "        print(f\"   Loss: {final_loss:.6f}\")\n",
    "        print(f\"   LogZ: {final_logZ:.4f} (Z = {final_Z:.4f})\")\n",
    "        print(f\"   Training Success: {overall_success_rate:.2%}\")\n",
    "        print(f\"   Test Success: {test_success_rate:.2%}\")\n",
    "        print(f\"   Total Trajectories: {len(all_trajectories)}\")\n",
    "        \n",
    "        return final_loss\n",
    "\n",
    "# ====================================================\n",
    "# Hyperparameter Sweep\n",
    "# ====================================================\n",
    "def run_trajectory_balance_sweep():\n",
    "    \"\"\"Run systematic hyperparameter sweep\"\"\"\n",
    "    \n",
    "    # Hyperparameter grid\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    hidden_dims = [64, 128, 256]\n",
    "    grid_sizes = [6, 8]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            for grid_size in grid_sizes:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"ðŸ§ª Running: lr={lr}, hidden_dim={hidden_dim}, grid_size={grid_size}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                \n",
    "                final_loss = trajectory_balance_experiment(\n",
    "                    lr=lr,\n",
    "                    hidden_dim=hidden_dim,\n",
    "                    grid_size=grid_size,\n",
    "                    n_steps=500,  # Shorter for sweep\n",
    "                    batch_size=32\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    'lr': lr,\n",
    "                    'hidden_dim': hidden_dim,\n",
    "                    'grid_size': grid_size,\n",
    "                    'final_loss': final_loss\n",
    "                })\n",
    "    \n",
    "    # Print sweep summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ðŸ† TRAJECTORY BALANCE HYPERPARAMETER SWEEP RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Sort by final loss\n",
    "    results.sort(key=lambda x: x['final_loss'])\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"{i+1:2d}. lr={result['lr']:6.4f}, hidden_dim={result['hidden_dim']:3d}, \"\n",
    "              f\"grid_size={result['grid_size']:2d} -> loss={result['final_loss']:8.6f}\")\n",
    "    \n",
    "    # Best configuration\n",
    "    best = results[0]\n",
    "    print(f\"\\nðŸ¥‡ Best Configuration:\")\n",
    "    print(f\"   Learning Rate: {best['lr']}\")\n",
    "    print(f\"   Hidden Dim: {best['hidden_dim']}\")\n",
    "    print(f\"   Grid Size: {best['grid_size']}\")\n",
    "    print(f\"   Final Loss: {best['final_loss']:.6f}\")\n",
    "\n",
    "# ====================================================\n",
    "# Main Execution\n",
    "# ====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # MLflow setup\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mlflow.set_experiment(\"Trajectory_Balance_GFlowNet\")\n",
    "    \n",
    "    # Run single experiment\n",
    "    trajectory_balance_experiment(lr=0.001, hidden_dim=128, n_steps=1000)\n",
    "    \n",
    "    # Or run hyperparameter sweep\n",
    "    # run_trajectory_balance_sweep()\n",
    "    \n",
    "    # Clean up\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983e22ed-70c1-435b-8a21-c00b4a3674b1",
   "metadata": {},
   "source": [
    "## v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fbea50e7-5b69-4887-a7ad-5bc7d6cbf45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid size: 8x8\n",
      "Goal region: x >= 6, y >= 6\n",
      "State encoding dimension: 64\n",
      "ðŸš€ Training Trajectory Balance GFlowNet\n",
      "   Grid: 8x8\n",
      "   State dim: 64\n",
      "   Hidden dim: 128\n",
      "   Learning rate: 0.001\n",
      "   Initial logZ: 5.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TB Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [01:01<00:00, 16.35it/s, Loss=118.8017, LogZ=5.998, Success=40.6%, AvgLen=19.6, TotalSucc=10969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Final evaluation...\n",
      "âœ… Found 10969 successful trajectories (10737 unique)\n",
      "\n",
      "ðŸ“Š Final Results:\n",
      "   Loss: 118.801743\n",
      "   LogZ: 5.9979 (Z = 402.5785)\n",
      "   Training Success: 34.28%\n",
      "   Test Success: 74.00%\n",
      "   Total Trajectories: 32000\n"
     ]
    }
   ],
   "source": [
    "from hypergrid_trajectory_balance_experiment import trajectory_balance_experiment\n",
    "\n",
    "# ====================================================\n",
    "# Main Execution\n",
    "# ====================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # MLflow setup\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mlflow.set_experiment(\"Trajectory_Balance_GFlowNet\")\n",
    "    \n",
    "    # Run single experiment\n",
    "    trajectory_balance_experiment(lr=0.001, hidden_dim=128, n_steps=1000)\n",
    "    \n",
    "    # Or run hyperparameter sweep\n",
    "    # run_trajectory_balance_sweep()\n",
    "    \n",
    "    # Clean up\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "396872f1-a933-4368-857d-e58ea5cdeaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid size: 8x8\n",
      "Goal region: x >= 6, y >= 6\n",
      "State encoding dimension: 64\n",
      "ðŸš€ Training Trajectory Balance GFlowNet\n",
      "   Grid: 8x8\n",
      "   State dim: 64\n",
      "   Hidden dim: 128\n",
      "   Learning rate: 0.001\n",
      "   Initial logZ: 5.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TB Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [01:06<00:00, 14.97it/s, Loss=139.2724, LogZ=6.012, Success=34.4%, AvgLen=20.0, TotalSucc=10749]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Final evaluation...\n",
      "ðŸŽ¨ Generating comprehensive visualizations...\n",
      "âœ… Found 10749 successful trajectories (10524 unique)\n",
      "\n",
      "ðŸ“Š Final Results:\n",
      "   Loss: 139.272446\n",
      "   LogZ: 6.0118 (Z = 408.2217)\n",
      "   Training Success: 33.59%\n",
      "   Test Success: 85.00%\n",
      "   Total Trajectories: 32000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from collections import Counter, defaultdict\n",
    "import seaborn as sns\n",
    "\n",
    "# ====================================================\n",
    "# Enhanced HyperGrid Environment (with bounds checking)\n",
    "# ====================================================\n",
    "class HyperGrid:\n",
    "    \"\"\"8x8 HyperGrid environment for GFlowNet - All methods use encoded states\"\"\"\n",
    "    \n",
    "    def __init__(self, size: int = 8, reward_region_size: int = 2) -> None:\n",
    "        self.size = size\n",
    "        self.reward_region_size = reward_region_size\n",
    "        \n",
    "        # Define goal region bounds (computed, not stored)\n",
    "        self.goal_min_x = size - reward_region_size\n",
    "        self.goal_min_y = size - reward_region_size\n",
    "        \n",
    "        # Start state as encoded\n",
    "        self.start_state = tuple(self.encode_raw_state((0, 0)))\n",
    "        \n",
    "        print(f\"Grid size: {size}x{size}\")\n",
    "        print(f\"Goal region: x >= {self.goal_min_x}, y >= {self.goal_min_y}\")\n",
    "        print(f\"State encoding dimension: {self.get_state_dim()}\")\n",
    "    \n",
    "    # ====================================================\n",
    "    # State encoding utilities\n",
    "    # ====================================================\n",
    "    \n",
    "    def encode_raw_state(self, raw_state: Tuple[int, int]) -> List[float]:\n",
    "        \"\"\"Convert raw (x,y) state to encoded one-hot vector\"\"\"\n",
    "        x, y = raw_state\n",
    "        idx = y * self.size + x\n",
    "        encoding = [0.0] * (self.size * self.size)\n",
    "        encoding[idx] = 1.0\n",
    "        return encoding\n",
    "    \n",
    "    def decode_state_to_raw(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> Tuple[int, int]:\n",
    "        \"\"\"Convert encoded state back to raw (x,y) tuple\"\"\"\n",
    "        if isinstance(encoded_state, tuple):\n",
    "            encoded_state = list(encoded_state)\n",
    "        \n",
    "        idx = encoded_state.index(1.0)\n",
    "        x = idx % self.size\n",
    "        y = idx // self.size\n",
    "        return (x, y)\n",
    "    \n",
    "    def get_state_dim(self) -> int:\n",
    "        \"\"\"Get the dimension of encoded states\"\"\"\n",
    "        return self.size * self.size\n",
    "    \n",
    "    # ====================================================\n",
    "    # Actions (work with encoded states + bounds checking)\n",
    "    # ====================================================    \n",
    "    \n",
    "    def get_valid_actions(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[str]:\n",
    "        \"\"\"Get valid actions from an encoded state\"\"\"\n",
    "        # Convert to raw to check boundaries\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        actions = []\n",
    "        \n",
    "        if x + 1 < self.size:\n",
    "            actions.append('right')\n",
    "        if y + 1 < self.size:\n",
    "            actions.append('up')\n",
    "        if x - 1 >= 0:\n",
    "            actions.append('left')\n",
    "        if y - 1 >= 0:\n",
    "            actions.append('down')\n",
    "            \n",
    "        return actions\n",
    "    \n",
    "    def take_action(self, encoded_state: Union[List[float], Tuple[float, ...]], action: str) -> Tuple[float, ...]:\n",
    "        \"\"\"Take action from encoded state to get next encoded state (with bounds checking)\"\"\"\n",
    "        # Convert to raw, take action with bounds checking, convert back\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        \n",
    "        if action == 'right' and x + 1 < self.size:\n",
    "            new_raw = (x + 1, y)\n",
    "        elif action == 'up' and y + 1 < self.size:\n",
    "            new_raw = (x, y + 1)\n",
    "        elif action == 'left' and x - 1 >= 0:\n",
    "            new_raw = (x - 1, y)\n",
    "        elif action == 'down' and y - 1 >= 0:\n",
    "            new_raw = (x, y - 1)\n",
    "        else:\n",
    "            # Invalid action - stay in same state\n",
    "            new_raw = (x, y)\n",
    "        \n",
    "        return tuple(self.encode_raw_state(new_raw))\n",
    "    \n",
    "    # ====================================================\n",
    "    # Action encoding\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_action_list(self) -> List[str]:\n",
    "        \"\"\"Get list of all possible actions\"\"\"\n",
    "        return ['right', 'up', 'left', 'down']\n",
    "    \n",
    "    def action_to_index(self, action: str) -> int:\n",
    "        \"\"\"Convert action string to index\"\"\"\n",
    "        action_map = {'right': 0, 'up': 1, 'left': 2, 'down': 3}\n",
    "        return action_map.get(action, -1)\n",
    "    \n",
    "    def index_to_action(self, index: int) -> str:\n",
    "        \"\"\"Convert action index to string\"\"\"\n",
    "        actions = ['right', 'up', 'left', 'down']\n",
    "        return actions[index] if 0 <= index < len(actions) else 'right'\n",
    "    \n",
    "    def get_action_dim(self) -> int:\n",
    "        \"\"\"Get number of possible actions\"\"\"\n",
    "        return 4\n",
    "    \n",
    "    # ====================================================\n",
    "    # Action masking (work with encoded states)\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_valid_action_mask(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> List[float]:\n",
    "        \"\"\"Get binary mask for valid actions\"\"\"\n",
    "        valid_actions = self.get_valid_actions(encoded_state)\n",
    "        mask = [0.0] * 4\n",
    "        for action in valid_actions:\n",
    "            idx = self.action_to_index(action)\n",
    "            if idx >= 0:\n",
    "                mask[idx] = 1.0\n",
    "        return mask\n",
    "    \n",
    "    # ====================================================\n",
    "    # REWARD (work with encoded states using bounds checking)\n",
    "    # ====================================================\n",
    "    \n",
    "    def get_reward(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> float:\n",
    "        \"\"\"Get reward for an encoded state using bounds checking\"\"\"\n",
    "        # Convert to raw coordinates for bounds checking\n",
    "        x, y = self.decode_state_to_raw(encoded_state)\n",
    "        \n",
    "        # Check if in goal region using bounds\n",
    "        if x >= self.goal_min_x and y >= self.goal_min_y:\n",
    "            return 1.0\n",
    "        return 0.0\n",
    "    \n",
    "    def is_terminal(self, encoded_state: Union[List[float], Tuple[float, ...]]) -> bool:\n",
    "        \"\"\"Check if encoded state is terminal\"\"\"\n",
    "        return self.get_reward(encoded_state) > 0.0\n",
    "\n",
    "# ====================================================\n",
    "# Trajectory Balance Model\n",
    "# ====================================================\n",
    "class TBModel(nn.Module):\n",
    "    \"\"\"Trajectory Balance GFlowNet Model\"\"\"\n",
    "    \n",
    "    def __init__(self, state_dim: int, num_hid: int = 128):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Forward policy: current state -> next action probabilities\n",
    "        self.forward_policy = nn.Sequential(\n",
    "            nn.Linear(state_dim, num_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hid, 4)  # 4 actions: right, up, left, down\n",
    "        )\n",
    "        \n",
    "        # Backward policy: current state -> previous action probabilities\n",
    "        self.backward_policy = nn.Sequential(\n",
    "            nn.Linear(state_dim, num_hid),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hid, 4)  # 4 actions\n",
    "        )\n",
    "        \n",
    "        # Log partition function\n",
    "        self.logZ = nn.Parameter(torch.tensor(5.0))\n",
    "\n",
    "    def forward(self, state: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        P_F_logits = self.forward_policy(state)\n",
    "        P_B_logits = self.backward_policy(state)\n",
    "        return P_F_logits, P_B_logits\n",
    "\n",
    "# ====================================================\n",
    "# Trajectory Balance Loss Function\n",
    "# ====================================================\n",
    "def trajectory_balance_loss(model: TBModel, trajectories: List[List[Tuple[float, ...]]], env: HyperGrid) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Optimized Trajectory Balance Loss with early filtering\n",
    "    \"\"\"\n",
    "    # Early check: Filter for rewarded trajectories upfront\n",
    "    rewarded_trajectories = []\n",
    "    for traj in trajectories:\n",
    "        if len(traj) >= 2:  # Valid length\n",
    "            final_state = traj[-1]\n",
    "            reward = env.get_reward(final_state)\n",
    "            if reward > 0:  # Has reward\n",
    "                rewarded_trajectories.append((traj, reward))\n",
    "    \n",
    "    # Early exit if no valid trajectories\n",
    "    if len(rewarded_trajectories) == 0:\n",
    "        return torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "    # Process only rewarded trajectories\n",
    "    total_loss = torch.tensor(0.0, requires_grad=True)\n",
    "    \n",
    "    for traj, reward in rewarded_trajectories:\n",
    "        \n",
    "        # FORWARD path: Z_Î¸ * âˆP_F(s_t|s_{t-1})\n",
    "        log_forward = model.logZ\n",
    "        \n",
    "        for step in range(len(traj) - 1):\n",
    "            current_state = traj[step]\n",
    "            next_state = traj[step + 1]\n",
    "            \n",
    "            # Encode current state for neural network\n",
    "            current_tensor = torch.tensor(list(current_state), dtype=torch.float)\n",
    "            \n",
    "            # Get forward policy logits\n",
    "            P_F_logits, _ = model(current_tensor)\n",
    "            \n",
    "            # Mask invalid actions using vectorized operation\n",
    "            action_mask = torch.tensor(env.get_valid_action_mask(current_state))\n",
    "            masked_logits = P_F_logits.where(action_mask.bool(), torch.tensor(-100.0))\n",
    "            \n",
    "            # Get probabilities\n",
    "            probs = F.softmax(masked_logits, dim=0)\n",
    "            \n",
    "            # Find which action was taken\n",
    "            for action_str in env.get_valid_actions(current_state):\n",
    "                if env.take_action(current_state, action_str) == next_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    log_forward = log_forward + torch.log(probs[action_idx].clamp(min=1e-8))\n",
    "                    break\n",
    "        \n",
    "        # BACKWARD path: R(x) * âˆP_B(s_{t-1}|s_t)\n",
    "        log_backward = torch.log(torch.tensor(reward, dtype=torch.float, requires_grad=True))\n",
    "        \n",
    "        for step in range(len(traj) - 1, 0, -1):\n",
    "            current_state = traj[step]\n",
    "            prev_state = traj[step - 1]\n",
    "            \n",
    "            # Encode current state\n",
    "            current_tensor = torch.tensor(list(current_state), dtype=torch.float)\n",
    "            \n",
    "            # Get backward policy logits\n",
    "            _, P_B_logits = model(current_tensor)\n",
    "            \n",
    "            # Find valid previous actions (safely with bounds checking)\n",
    "            valid_prev_actions = []\n",
    "            for action_str in env.get_action_list():\n",
    "                # Check if taking this action from prev_state leads to current_state\n",
    "                test_next_state = env.take_action(prev_state, action_str)\n",
    "                if test_next_state == current_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    valid_prev_actions.append(action_idx)\n",
    "            \n",
    "            # Create mask and apply vectorized masking\n",
    "            prev_action_mask = torch.zeros(4)\n",
    "            for action_idx in valid_prev_actions:\n",
    "                prev_action_mask[action_idx] = 1.0\n",
    "            \n",
    "            masked_logits = P_B_logits.where(prev_action_mask.bool(), torch.tensor(-100.0))\n",
    "            probs = F.softmax(masked_logits, dim=0)\n",
    "            \n",
    "            # Find which action led to current state\n",
    "            for action_str in env.get_action_list():\n",
    "                test_next_state = env.take_action(prev_state, action_str)\n",
    "                if test_next_state == current_state:\n",
    "                    action_idx = env.action_to_index(action_str)\n",
    "                    log_backward = log_backward + torch.log(probs[action_idx].clamp(min=1e-8))\n",
    "                    break\n",
    "        \n",
    "        # Apply trajectory balance equation\n",
    "        trajectory_loss = (log_forward - log_backward) ** 2\n",
    "        total_loss = total_loss + trajectory_loss\n",
    "    \n",
    "    return total_loss / len(rewarded_trajectories)\n",
    "\n",
    "# ====================================================\n",
    "# Visualization Functions\n",
    "# ====================================================\n",
    "def visualize_trajectory_grid(trajectories: List[List[Tuple]], env, title: str = \"Trajectories\", \n",
    "                             max_trajectories: int = 10, save_path: str = None):\n",
    "    \"\"\"Visualize trajectories on the grid with success/failure distinction\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    # Create base grid\n",
    "    ax.set_xlim(-0.5, env.size - 0.5)\n",
    "    ax.set_ylim(-0.5, env.size - 0.5)\n",
    "    \n",
    "    # Add grid lines\n",
    "    for i in range(env.size + 1):\n",
    "        ax.axhline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "        ax.axvline(i - 0.5, color='lightgray', linewidth=0.5)\n",
    "    \n",
    "    # Mark start state\n",
    "    start_raw = env.decode_state_to_raw(env.start_state)\n",
    "    ax.scatter(start_raw[0], start_raw[1], c='green', s=400, \n",
    "              marker='s', label='Start', zorder=5, edgecolor='black', linewidth=2)\n",
    "    \n",
    "    # Mark goal region\n",
    "    for x in range(max(0, env.goal_min_x), env.size):\n",
    "        for y in range(max(0, env.goal_min_y), env.size):\n",
    "            ax.add_patch(plt.Rectangle((x-0.4, y-0.4), 0.8, 0.8, \n",
    "                                     facecolor='red', alpha=0.3, zorder=1))\n",
    "    ax.scatter([], [], c='red', s=200, marker='s', alpha=0.3, label='Goal Region')\n",
    "    \n",
    "    # Separate successful and failed trajectories\n",
    "    successful_trajs = []\n",
    "    failed_trajs = []\n",
    "    \n",
    "    for traj in trajectories[:max_trajectories]:\n",
    "        if len(traj) < 2:\n",
    "            continue\n",
    "        raw_traj = [env.decode_state_to_raw(state) for state in traj]\n",
    "        if env.is_terminal(traj[-1]):\n",
    "            successful_trajs.append(raw_traj)\n",
    "        else:\n",
    "            failed_trajs.append(raw_traj)\n",
    "    \n",
    "    # Plot failed trajectories first\n",
    "    for i, raw_traj in enumerate(failed_trajs):\n",
    "        xs, ys = zip(*raw_traj)\n",
    "        ax.plot(xs, ys, color='red', linewidth=2, alpha=0.6, linestyle='--',\n",
    "               label='Failed' if i == 0 else '')\n",
    "        ax.scatter(xs[-1], ys[-1], color='red', s=100, marker='x', \n",
    "                  linewidth=3, zorder=4)\n",
    "    \n",
    "    # Plot successful trajectories\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(successful_trajs)))\n",
    "    for i, (raw_traj, color) in enumerate(zip(successful_trajs, colors)):\n",
    "        xs, ys = zip(*raw_traj)\n",
    "        ax.plot(xs, ys, color=color, linewidth=3, alpha=0.8,\n",
    "               label=f'Success {i+1} (len={len(raw_traj)})')\n",
    "        \n",
    "        ax.scatter(xs[1:-1], ys[1:-1], color=color, s=30, alpha=0.7, zorder=3)\n",
    "        ax.scatter(xs[-1], ys[-1], color=color, s=150, marker='o', \n",
    "                  edgecolor='black', linewidth=2, zorder=4)\n",
    "    \n",
    "    ax.set_xlabel('X Position')\n",
    "    ax.set_ylabel('Y Position')\n",
    "    ax.set_title(f'{title}\\nSuccessful: {len(successful_trajs)}, Failed: {len(failed_trajs)}')\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xticks(range(env.size))\n",
    "    ax.set_yticks(range(env.size))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def analyze_trajectory_patterns(trajectories: List[List[Tuple]], env, save_path: str = None):\n",
    "    \"\"\"Analyze and visualize trajectory patterns and behaviors\"\"\"\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Convert all trajectories to raw coordinates\n",
    "    raw_trajectories = []\n",
    "    successful_indices = []\n",
    "    for i, traj in enumerate(trajectories):\n",
    "        raw_traj = [env.decode_state_to_raw(state) for state in traj]\n",
    "        raw_trajectories.append(raw_traj)\n",
    "        if env.is_terminal(traj[-1]):\n",
    "            successful_indices.append(i)\n",
    "    \n",
    "    # 1. Trajectory Length Distribution\n",
    "    lengths = [len(traj) for traj in raw_trajectories]\n",
    "    successful_lengths = [len(raw_trajectories[i]) for i in successful_indices]\n",
    "    failed_lengths = [len(traj) for i, traj in enumerate(raw_trajectories) if i not in successful_indices]\n",
    "    \n",
    "    ax1.hist(failed_lengths, bins=20, alpha=0.6, label=f'Failed ({len(failed_lengths)})', color='red')\n",
    "    ax1.hist(successful_lengths, bins=20, alpha=0.6, label=f'Successful ({len(successful_lengths)})', color='green')\n",
    "    ax1.set_xlabel('Trajectory Length')\n",
    "    ax1.set_ylabel('Count')\n",
    "    ax1.set_title('Trajectory Length Distribution')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. State Visit Heatmap\n",
    "    visit_counts = np.zeros((env.size, env.size))\n",
    "    for raw_traj in raw_trajectories:\n",
    "        for x, y in raw_traj:\n",
    "            visit_counts[y, x] += 1\n",
    "    \n",
    "    im = ax2.imshow(visit_counts, cmap='YlOrRd', origin='lower')\n",
    "    ax2.set_xlabel('X Position')\n",
    "    ax2.set_ylabel('Y Position')\n",
    "    ax2.set_title('State Visitation Heatmap')\n",
    "    \n",
    "    for i in range(env.size):\n",
    "        for j in range(env.size):\n",
    "            text = ax2.text(j, i, int(visit_counts[i, j]), ha=\"center\", va=\"center\", \n",
    "                           color=\"black\" if visit_counts[i, j] < visit_counts.max()/2 else \"white\")\n",
    "    \n",
    "    plt.colorbar(im, ax=ax2, label='Visit Count')\n",
    "    \n",
    "    # 3. Final State Distribution\n",
    "    final_states = [traj[-1] for traj in raw_trajectories]\n",
    "    final_state_counts = Counter(final_states)\n",
    "    \n",
    "    final_grid = np.zeros((env.size, env.size))\n",
    "    for (x, y), count in final_state_counts.items():\n",
    "        final_grid[y, x] = count\n",
    "    \n",
    "    im3 = ax3.imshow(final_grid, cmap='Blues', origin='lower')\n",
    "    ax3.set_xlabel('X Position')\n",
    "    ax3.set_ylabel('Y Position')\n",
    "    ax3.set_title('Final State Distribution')\n",
    "    \n",
    "    # Mark goal region\n",
    "    for x in range(max(0, env.goal_min_x), env.size):\n",
    "        for y in range(max(0, env.goal_min_y), env.size):\n",
    "            rect = plt.Rectangle((x-0.5, y-0.5), 1, 1, fill=False, \n",
    "                               edgecolor='red', linewidth=3)\n",
    "            ax3.add_patch(rect)\n",
    "    \n",
    "    for i in range(env.size):\n",
    "        for j in range(env.size):\n",
    "            if final_grid[i, j] > 0:\n",
    "                text = ax3.text(j, i, int(final_grid[i, j]), ha=\"center\", va=\"center\",\n",
    "                               color=\"black\" if final_grid[i, j] < final_grid.max()/2 else \"white\")\n",
    "    \n",
    "    plt.colorbar(im3, ax=ax3, label='Final State Count')\n",
    "    \n",
    "    # 4. Action Frequency Analysis\n",
    "    action_counts = defaultdict(int)\n",
    "    \n",
    "    for traj in trajectories:\n",
    "        for i in range(len(traj) - 1):\n",
    "            current_state = traj[i]\n",
    "            next_state = traj[i + 1]\n",
    "            \n",
    "            for action_str in env.get_valid_actions(current_state):\n",
    "                if env.take_action(current_state, action_str) == next_state:\n",
    "                    action_counts[action_str] += 1\n",
    "                    break\n",
    "    \n",
    "    actions = list(action_counts.keys())\n",
    "    counts = list(action_counts.values())\n",
    "    \n",
    "    bars = ax4.bar(actions, counts, color=['skyblue', 'lightgreen', 'lightcoral', 'lightsalmon'])\n",
    "    ax4.set_xlabel('Action')\n",
    "    ax4.set_ylabel('Count')\n",
    "    ax4.set_title('Action Frequency')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    for bar, count in zip(bars, counts):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + max(counts)*0.01,\n",
    "                f'{count}', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def visualize_policy_heatmaps(model, env, save_path: str = None):\n",
    "    \"\"\"Visualize learned forward and backward policies as heatmaps\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    action_names = ['Right', 'Up', 'Left', 'Down']\n",
    "    forward_policies = []\n",
    "    backward_policies = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x in range(env.size):\n",
    "            for y in range(env.size):\n",
    "                raw_state = (x, y)\n",
    "                encoded_state = env.encode_raw_state(raw_state)\n",
    "                state_tensor = torch.tensor(encoded_state, dtype=torch.float)\n",
    "                \n",
    "                P_F_logits, P_B_logits = model(state_tensor)\n",
    "                \n",
    "                action_mask = torch.tensor(env.get_valid_action_mask(tuple(encoded_state)))\n",
    "                masked_F_logits = P_F_logits.where(action_mask.bool(), torch.tensor(-100.0))\n",
    "                masked_B_logits = P_B_logits.where(action_mask.bool(), torch.tensor(-100.0))\n",
    "                \n",
    "                F_probs = F.softmax(masked_F_logits, dim=0).numpy()\n",
    "                B_probs = F.softmax(masked_B_logits, dim=0).numpy()\n",
    "                \n",
    "                forward_policies.append(F_probs)\n",
    "                backward_policies.append(B_probs)\n",
    "    \n",
    "    forward_policies = np.array(forward_policies).reshape(env.size, env.size, 4)\n",
    "    backward_policies = np.array(backward_policies).reshape(env.size, env.size, 4)\n",
    "    \n",
    "    # Forward policy dominant action\n",
    "    dominant_forward_action = np.argmax(forward_policies, axis=2)\n",
    "    im1 = ax1.imshow(dominant_forward_action, cmap='viridis', origin='lower')\n",
    "    ax1.set_title('Forward Policy - Dominant Action')\n",
    "    ax1.set_xlabel('X Position')\n",
    "    ax1.set_ylabel('Y Position')\n",
    "    \n",
    "    for i in range(env.size):\n",
    "        for j in range(env.size):\n",
    "            action_idx = dominant_forward_action[i, j]\n",
    "            ax1.text(j, i, action_names[action_idx][:1], ha=\"center\", va=\"center\", \n",
    "                    color=\"white\", fontweight='bold')\n",
    "    \n",
    "    cbar1 = plt.colorbar(im1, ax=ax1)\n",
    "    cbar1.set_ticks([0, 1, 2, 3])\n",
    "    cbar1.set_ticklabels(action_names)\n",
    "    \n",
    "    # Backward policy dominant action\n",
    "    dominant_backward_action = np.argmax(backward_policies, axis=2)\n",
    "    im2 = ax2.imshow(dominant_backward_action, cmap='plasma', origin='lower')\n",
    "    ax2.set_title('Backward Policy - Dominant Action')\n",
    "    ax2.set_xlabel('X Position')\n",
    "    ax2.set_ylabel('Y Position')\n",
    "    \n",
    "    for i in range(env.size):\n",
    "        for j in range(env.size):\n",
    "            action_idx = dominant_backward_action[i, j]\n",
    "            ax2.text(j, i, action_names[action_idx][:1], ha=\"center\", va=\"center\", \n",
    "                    color=\"white\", fontweight='bold')\n",
    "    \n",
    "    cbar2 = plt.colorbar(im2, ax=ax2)\n",
    "    cbar2.set_ticks([0, 1, 2, 3])\n",
    "    cbar2.set_ticklabels(action_names)\n",
    "    \n",
    "    # Policy uncertainty (entropy)\n",
    "    forward_entropy = -np.sum(forward_policies * np.log(forward_policies + 1e-8), axis=2)\n",
    "    backward_entropy = -np.sum(backward_policies * np.log(backward_policies + 1e-8), axis=2)\n",
    "    \n",
    "    im3 = ax3.imshow(forward_entropy, cmap='RdYlBu_r', origin='lower')\n",
    "    ax3.set_title('Forward Policy Uncertainty (Entropy)')\n",
    "    ax3.set_xlabel('X Position')\n",
    "    ax3.set_ylabel('Y Position')\n",
    "    plt.colorbar(im3, ax=ax3, label='Entropy (High = Uncertain)')\n",
    "    \n",
    "    im4 = ax4.imshow(backward_entropy, cmap='RdYlBu_r', origin='lower')\n",
    "    ax4.set_title('Backward Policy Uncertainty (Entropy)')\n",
    "    ax4.set_xlabel('X Position')\n",
    "    ax4.set_ylabel('Y Position')\n",
    "    plt.colorbar(im4, ax=ax4, label='Entropy (High = Uncertain)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "    \n",
    "    return fig\n",
    "class PolicyTrajectorySampler:\n",
    "    \"\"\"Sample trajectories using learned policy with encoded states\"\"\"\n",
    "    \n",
    "    def __init__(self, env: HyperGrid, model: TBModel = None, epsilon: float = 0.2):\n",
    "        self.env = env\n",
    "        self.model = model\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def sample_trajectory(self, max_steps: int = 20) -> List[Tuple[float, ...]]:\n",
    "        \"\"\"Sample trajectory using policy with epsilon-greedy exploration\"\"\"\n",
    "        trajectory = [self.env.start_state]\n",
    "        state = self.env.start_state\n",
    "        \n",
    "        for _ in range(max_steps):\n",
    "            if self.env.is_terminal(state):\n",
    "                break\n",
    "            \n",
    "            valid_actions = self.env.get_valid_actions(state)\n",
    "            if not valid_actions:\n",
    "                break\n",
    "            \n",
    "            if self.model is None or random.random() < self.epsilon:\n",
    "                # Random exploration\n",
    "                action = random.choice(valid_actions)\n",
    "            else:\n",
    "                # Use learned policy\n",
    "                state_tensor = torch.tensor(list(state), dtype=torch.float)\n",
    "                P_F_logits, _ = self.model(state_tensor)\n",
    "                \n",
    "                # Mask invalid actions\n",
    "                action_mask = torch.tensor(self.env.get_valid_action_mask(state))\n",
    "                masked_logits = P_F_logits.where(action_mask.bool(), torch.tensor(-100.0))\n",
    "                \n",
    "                # Sample from policy\n",
    "                probs = F.softmax(masked_logits, dim=0)\n",
    "                action_idx = torch.multinomial(probs, 1).item()\n",
    "                action = self.env.index_to_action(action_idx)\n",
    "            \n",
    "            next_state = self.env.take_action(state, action)\n",
    "            trajectory.append(next_state)\n",
    "            state = next_state\n",
    "        \n",
    "        return trajectory\n",
    "    \n",
    "    def sample_batch(self, batch_size: int, max_steps: int = 20) -> List[List[Tuple[float, ...]]]:\n",
    "        \"\"\"Sample batch of trajectories\"\"\"\n",
    "        trajectories = []\n",
    "        for _ in range(batch_size):\n",
    "            traj = self.sample_trajectory(max_steps)\n",
    "            trajectories.append(traj)\n",
    "        return trajectories\n",
    "\n",
    "# ====================================================\n",
    "# MLflow Trajectory Balance Experiment\n",
    "# ====================================================\n",
    "def trajectory_balance_experiment(\n",
    "    lr: float = 0.001, \n",
    "    hidden_dim: int = 128, \n",
    "    n_steps: int = 1000, \n",
    "    batch_size: int = 32,\n",
    "    grid_size: int = 8,\n",
    "    reward_region_size: int = 2,\n",
    "    epsilon: float = 0.3,\n",
    "    max_trajectory_steps: int = 20\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Complete trajectory balance experiment with MLflow tracking\n",
    "    \"\"\"\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        # ====================================================\n",
    "        # Log Hyperparameters\n",
    "        # ====================================================\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"hidden_dim\", hidden_dim)\n",
    "        mlflow.log_param(\"n_steps\", n_steps)\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"grid_size\", grid_size)\n",
    "        mlflow.log_param(\"reward_region_size\", reward_region_size)\n",
    "        mlflow.log_param(\"epsilon\", epsilon)\n",
    "        mlflow.log_param(\"max_trajectory_steps\", max_trajectory_steps)\n",
    "        mlflow.log_param(\"method\", \"trajectory_balance\")\n",
    "        \n",
    "        # ====================================================\n",
    "        # Setup Environment and Model\n",
    "        # ====================================================\n",
    "        env = HyperGrid(size=grid_size, reward_region_size=reward_region_size)\n",
    "        state_dim = env.get_state_dim()\n",
    "        \n",
    "        mlflow.log_param(\"state_dim\", state_dim)\n",
    "        \n",
    "        # Create model and optimizer\n",
    "        model = TBModel(state_dim, hidden_dim)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Create policy-based sampler\n",
    "        sampler = PolicyTrajectorySampler(env, model, epsilon)\n",
    "        \n",
    "        mlflow.log_param(\"initial_logZ\", model.logZ.item())\n",
    "        \n",
    "        print(f\"ðŸš€ Training Trajectory Balance GFlowNet\")\n",
    "        print(f\"   Grid: {grid_size}x{grid_size}\")\n",
    "        print(f\"   State dim: {state_dim}\")\n",
    "        print(f\"   Hidden dim: {hidden_dim}\")\n",
    "        print(f\"   Learning rate: {lr}\")\n",
    "        print(f\"   Initial logZ: {model.logZ.item():.4f}\")\n",
    "        \n",
    "        # ====================================================\n",
    "        # Training Loop\n",
    "        # ====================================================\n",
    "        losses = []\n",
    "        log_z_values = []\n",
    "        all_trajectories = []\n",
    "        successful_trajectories = []\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar = tqdm(range(n_steps), desc=f\"TB Training\")\n",
    "        \n",
    "        for step in pbar:\n",
    "            # Sample trajectories using current policy\n",
    "            step_trajectories = sampler.sample_batch(batch_size, max_trajectory_steps)\n",
    "            all_trajectories.extend(step_trajectories)\n",
    "            \n",
    "            # Collect successful trajectories\n",
    "            for traj in step_trajectories:\n",
    "                if env.is_terminal(traj[-1]):\n",
    "                    successful_trajectories.append(traj)\n",
    "            \n",
    "            # Compute trajectory balance loss\n",
    "            loss = trajectory_balance_loss(model, step_trajectories, env)\n",
    "            \n",
    "            # Update model\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_value = loss.item()\n",
    "            losses.append(loss_value)\n",
    "            log_z_values.append(model.logZ.item())\n",
    "            \n",
    "            # Update progress bar\n",
    "            success_count = sum(1 for traj in step_trajectories if env.is_terminal(traj[-1]))\n",
    "            success_rate = success_count / len(step_trajectories)\n",
    "            avg_length = sum(len(traj) for traj in step_trajectories) / len(step_trajectories)\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{loss_value:.4f}',\n",
    "                'LogZ': f'{model.logZ.item():.3f}',\n",
    "                'Success': f'{success_rate:.1%}',\n",
    "                'AvgLen': f'{avg_length:.1f}',\n",
    "                'TotalSucc': len(successful_trajectories)\n",
    "            })\n",
    "            \n",
    "            # Log metrics periodically\n",
    "            log_interval = max(1, n_steps // 50)\n",
    "            if step % log_interval == 0:\n",
    "                mlflow.log_metric(\"loss\", loss_value, step=step)\n",
    "                mlflow.log_metric(\"logZ\", model.logZ.item(), step=step)\n",
    "                mlflow.log_metric(\"success_rate\", success_rate, step=step)\n",
    "                mlflow.log_metric(\"avg_trajectory_length\", avg_length, step=step)\n",
    "        \n",
    "        pbar.close()\n",
    "        \n",
    "        # ====================================================\n",
    "        # Final Evaluation\n",
    "        # ====================================================\n",
    "        print(f\"ðŸŽ¯ Final evaluation...\")\n",
    "        \n",
    "        # Test final policy (no exploration)\n",
    "        model.eval()\n",
    "        test_sampler = PolicyTrajectorySampler(env, model, epsilon=0.0)\n",
    "        test_trajectories = test_sampler.sample_batch(100, max_trajectory_steps)\n",
    "        \n",
    "        test_successful = sum(1 for traj in test_trajectories if env.is_terminal(traj[-1]))\n",
    "        test_success_rate = test_successful / len(test_trajectories)\n",
    "        \n",
    "        # Final metrics\n",
    "        final_loss = losses[-1]\n",
    "        final_logZ = log_z_values[-1]\n",
    "        final_Z = math.exp(final_logZ)\n",
    "        \n",
    "        # Overall training success rate\n",
    "        total_successful = sum(1 for traj in all_trajectories if env.is_terminal(traj[-1]))\n",
    "        overall_success_rate = total_successful / len(all_trajectories)\n",
    "        \n",
    "        # Log final metrics\n",
    "        mlflow.log_metric(\"final_loss\", final_loss)\n",
    "        mlflow.log_metric(\"final_logZ\", final_logZ)\n",
    "        mlflow.log_metric(\"final_Z\", final_Z)\n",
    "        mlflow.log_metric(\"training_success_rate\", overall_success_rate)\n",
    "        mlflow.log_metric(\"test_success_rate\", test_success_rate)\n",
    "        mlflow.log_metric(\"total_trajectories_sampled\", len(all_trajectories))\n",
    "        \n",
    "        # ====================================================\n",
    "        # Generate Comprehensive Visualizations\n",
    "        # ====================================================\n",
    "        print(f\"ðŸŽ¨ Generating comprehensive visualizations...\")\n",
    "        \n",
    "        # 1. Unique successful trajectories\n",
    "        unique_successful = []\n",
    "        seen_paths = set()\n",
    "        for traj in successful_trajectories:\n",
    "            raw_path = tuple(env.decode_state_to_raw(state) for state in traj)\n",
    "            if raw_path not in seen_paths:\n",
    "                unique_successful.append(traj)\n",
    "                seen_paths.add(raw_path)\n",
    "        \n",
    "        # 2. Generate visualizations\n",
    "        if unique_successful:\n",
    "            visualize_trajectory_grid(unique_successful[:10], env, \n",
    "                                     \"Unique Successful Trajectories\", \n",
    "                                     max_trajectories=10,\n",
    "                                     save_path=\"successful_trajectories.png\")\n",
    "            mlflow.log_artifact(\"successful_trajectories.png\")\n",
    "        \n",
    "        # 3. Pattern analysis of recent trajectories\n",
    "        recent_trajectories = all_trajectories[-500:] if len(all_trajectories) > 500 else all_trajectories\n",
    "        analyze_trajectory_patterns(recent_trajectories, env,\n",
    "                                   save_path=\"trajectory_patterns.png\")\n",
    "        mlflow.log_artifact(\"trajectory_patterns.png\")\n",
    "        \n",
    "        # 4. Policy heatmaps\n",
    "        visualize_policy_heatmaps(model, env, \n",
    "                                 save_path=\"policy_heatmaps.png\")\n",
    "        mlflow.log_artifact(\"policy_heatmaps.png\")\n",
    "        \n",
    "        # 5. Recent trajectory sample (what model is currently generating)\n",
    "        very_recent = all_trajectories[-50:] if len(all_trajectories) > 50 else all_trajectories\n",
    "        visualize_trajectory_grid(very_recent, env,\n",
    "                                 \"Recent Trajectory Sample (Last 50)\",\n",
    "                                 max_trajectories=15,\n",
    "                                 save_path=\"recent_trajectories.png\")\n",
    "        mlflow.log_artifact(\"recent_trajectories.png\")\n",
    "        \n",
    "        # 6. Basic training metrics plot\n",
    "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss curve\n",
    "        ax1.plot(losses)\n",
    "        ax1.set_title('Trajectory Balance Loss')\n",
    "        ax1.set_xlabel('Step')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # LogZ evolution\n",
    "        ax2.plot(log_z_values)\n",
    "        ax2.set_title('Log Partition Function Evolution')\n",
    "        ax2.set_xlabel('Step')\n",
    "        ax2.set_ylabel('Log Z')\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        # Success rate over time\n",
    "        window_size = max(1, len(all_trajectories) // 20)\n",
    "        success_rates = []\n",
    "        for i in range(0, len(all_trajectories), window_size):\n",
    "            window_trajs = all_trajectories[i:i+window_size]\n",
    "            window_success = sum(1 for traj in window_trajs if env.is_terminal(traj[-1])) / len(window_trajs)\n",
    "            success_rates.append(window_success)\n",
    "        \n",
    "        ax3.plot(success_rates)\n",
    "        ax3.set_title('Success Rate Over Training')\n",
    "        ax3.set_xlabel('Window')\n",
    "        ax3.set_ylabel('Success Rate')\n",
    "        ax3.grid(True)\n",
    "        \n",
    "        # Trajectory length distribution\n",
    "        lengths = [len(traj) for traj in all_trajectories[-200:]]\n",
    "        ax4.hist(lengths, bins=15, alpha=0.7)\n",
    "        ax4.set_title('Trajectory Length Distribution (Recent)')\n",
    "        ax4.set_xlabel('Length')\n",
    "        ax4.set_ylabel('Count')\n",
    "        ax4.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"tb_training_summary.png\", dpi=150, bbox_inches='tight')\n",
    "        mlflow.log_artifact(\"tb_training_summary.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        # Log additional metrics\n",
    "        mlflow.log_metric(\"unique_successful_paths\", len(unique_successful))\n",
    "        recent_success_rate = sum(1 for traj in very_recent if env.is_terminal(traj[-1])) / len(very_recent) if very_recent else 0\n",
    "        mlflow.log_metric(\"recent_success_rate\", recent_success_rate)\n",
    "        \n",
    "        # ====================================================\n",
    "        # Log Results Summary\n",
    "        # ====================================================\n",
    "        if successful_trajectories:\n",
    "            unique_successful = []\n",
    "            seen_paths = set()\n",
    "            for traj in successful_trajectories:\n",
    "                # Convert to raw coordinates for deduplication\n",
    "                raw_path = tuple(env.decode_state_to_raw(state) for state in traj)\n",
    "                if raw_path not in seen_paths:\n",
    "                    unique_successful.append(traj)\n",
    "                    seen_paths.add(raw_path)\n",
    "            \n",
    "            mlflow.log_metric(\"unique_successful_trajectories\", len(unique_successful))\n",
    "            \n",
    "            # Save analysis\n",
    "            with open(\"tb_results.txt\", \"w\") as f:\n",
    "                f.write(\"Trajectory Balance GFlowNet Results\\n\")\n",
    "                f.write(\"=\"*50 + \"\\n\\n\")\n",
    "                f.write(f\"Hyperparameters:\\n\")\n",
    "                f.write(f\"  Learning Rate: {lr}\\n\")\n",
    "                f.write(f\"  Hidden Dim: {hidden_dim}\\n\")\n",
    "                f.write(f\"  Grid Size: {grid_size}x{grid_size}\\n\")\n",
    "                f.write(f\"  Training Steps: {n_steps}\\n\")\n",
    "                f.write(f\"  Batch Size: {batch_size}\\n\\n\")\n",
    "                f.write(f\"Results:\\n\")\n",
    "                f.write(f\"  Final Loss: {final_loss:.6f}\\n\")\n",
    "                f.write(f\"  Final LogZ: {final_logZ:.4f} (Z = {final_Z:.4f})\\n\")\n",
    "                f.write(f\"  Training Success Rate: {overall_success_rate:.2%}\\n\")\n",
    "                f.write(f\"  Test Success Rate: {test_success_rate:.2%}\\n\")\n",
    "                f.write(f\"  Total Trajectories: {len(all_trajectories)}\\n\")\n",
    "                f.write(f\"  Successful Trajectories: {len(successful_trajectories)}\\n\")\n",
    "                f.write(f\"  Unique Successful: {len(unique_successful)}\\n\\n\")\n",
    "                \n",
    "                f.write(\"Sample successful paths (raw coordinates):\\n\")\n",
    "                for i, traj in enumerate(unique_successful[:10]):\n",
    "                    raw_path = [env.decode_state_to_raw(state) for state in traj]\n",
    "                    f.write(f\"  {i+1}: {raw_path} (length: {len(traj)})\\n\")\n",
    "            \n",
    "            mlflow.log_artifact(\"tb_results.txt\")\n",
    "            \n",
    "            print(f\"âœ… Found {len(successful_trajectories)} successful trajectories ({len(unique_successful)} unique)\")\n",
    "        else:\n",
    "            print(\"âŒ No successful trajectories found!\")\n",
    "        \n",
    "        # Save model weights\n",
    "        torch.save(model.state_dict(), \"tb_model_weights.pth\")\n",
    "        mlflow.log_artifact(\"tb_model_weights.pth\")\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Final Results:\")\n",
    "        print(f\"   Loss: {final_loss:.6f}\")\n",
    "        print(f\"   LogZ: {final_logZ:.4f} (Z = {final_Z:.4f})\")\n",
    "        print(f\"   Training Success: {overall_success_rate:.2%}\")\n",
    "        print(f\"   Test Success: {test_success_rate:.2%}\")\n",
    "        print(f\"   Total Trajectories: {len(all_trajectories)}\")\n",
    "        \n",
    "        return final_loss\n",
    "\n",
    "# ====================================================\n",
    "# Hyperparameter Sweep\n",
    "# ====================================================\n",
    "def run_trajectory_balance_sweep():\n",
    "    \"\"\"Run systematic hyperparameter sweep\"\"\"\n",
    "    \n",
    "    # Hyperparameter grid\n",
    "    learning_rates = [0.01, 0.001, 0.0001]\n",
    "    hidden_dims = [64, 128, 256]\n",
    "    grid_sizes = [6, 8]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for lr in learning_rates:\n",
    "        for hidden_dim in hidden_dims:\n",
    "            for grid_size in grid_sizes:\n",
    "                print(f\"\\n{'='*60}\")\n",
    "                print(f\"ðŸ§ª Running: lr={lr}, hidden_dim={hidden_dim}, grid_size={grid_size}\")\n",
    "                print(f\"{'='*60}\")\n",
    "                \n",
    "                final_loss = trajectory_balance_experiment(\n",
    "                    lr=lr,\n",
    "                    hidden_dim=hidden_dim,\n",
    "                    grid_size=grid_size,\n",
    "                    n_steps=500,  # Shorter for sweep\n",
    "                    batch_size=32\n",
    "                )\n",
    "                \n",
    "                results.append({\n",
    "                    'lr': lr,\n",
    "                    'hidden_dim': hidden_dim,\n",
    "                    'grid_size': grid_size,\n",
    "                    'final_loss': final_loss\n",
    "                })\n",
    "    \n",
    "    # Print sweep summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"ðŸ† TRAJECTORY BALANCE HYPERPARAMETER SWEEP RESULTS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Sort by final loss\n",
    "    results.sort(key=lambda x: x['final_loss'])\n",
    "    \n",
    "    for i, result in enumerate(results):\n",
    "        print(f\"{i+1:2d}. lr={result['lr']:6.4f}, hidden_dim={result['hidden_dim']:3d}, \"\n",
    "              f\"grid_size={result['grid_size']:2d} -> loss={result['final_loss']:8.6f}\")\n",
    "    \n",
    "    # Best configuration\n",
    "    best = results[0]\n",
    "    print(f\"\\nðŸ¥‡ Best Configuration:\")\n",
    "    print(f\"   Learning Rate: {best['lr']}\")\n",
    "    print(f\"   Hidden Dim: {best['hidden_dim']}\")\n",
    "    print(f\"   Grid Size: {best['grid_size']}\")\n",
    "    print(f\"   Final Loss: {best['final_loss']:.6f}\")\n",
    "\n",
    "# ====================================================\n",
    "# Main Execution\n",
    "# ====================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # MLflow setup\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    mlflow.set_experiment(\"Trajectory_Balance_GFlowNet\")\n",
    "    \n",
    "    # Run single experiment\n",
    "    trajectory_balance_experiment(lr=0.001, hidden_dim=128, n_steps=1000)\n",
    "    \n",
    "    # Or run hyperparameter sweep\n",
    "    # run_trajectory_balance_sweep()\n",
    "    \n",
    "    # Clean up\n",
    "    try:\n",
    "        mlflow.end_run()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ee31c3-13ff-4d89-9e33-ba7169e959ea",
   "metadata": {},
   "source": [
    "## v5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92b7d36-5c1b-4b0b-992f-82bd5a2e6a32",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da80c2d3e26b4ae5b4eb62aaeaa46a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h2>ðŸ§ª Trajectory Balance GFlowNet Experiment</h2>'), HBox(children=(VBox(children=(â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4d4901c2914bbb9192bd0c888ff38e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='\\n<div style=\\'padding: 10px; background-color: #e3f2fd; border-radius: 5px; margin-top: 10px;\\'>\\â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import mlflow\n",
    "from hypergrid_trajectory_balance_experiment import trajectory_balance_experiment, run_trajectory_balance_sweep\n",
    "\n",
    "# ====================================================\n",
    "# Interactive Experiment Widget\n",
    "# ====================================================\n",
    "\n",
    "class TrajectoryBalanceWidget:\n",
    "    def __init__(self):\n",
    "        self.setup_widgets()\n",
    "        self.setup_mlflow()\n",
    "    \n",
    "    def setup_mlflow(self):\n",
    "        \"\"\"Setup MLflow experiment\"\"\"\n",
    "        try:\n",
    "            mlflow.end_run()\n",
    "        except:\n",
    "            pass\n",
    "        mlflow.set_experiment(\"Trajectory_Balance_GFlowNet\")\n",
    "    \n",
    "    def setup_widgets(self):\n",
    "        \"\"\"Create interactive widgets\"\"\"\n",
    "        \n",
    "        # Hyperparameter controls\n",
    "        self.lr_slider = widgets.FloatLogSlider(\n",
    "            value=0.001,\n",
    "            base=10,\n",
    "            min=-5,\n",
    "            max=-1,\n",
    "            step=0.1,\n",
    "            description='Learning Rate:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.hidden_dim_slider = widgets.IntSlider(\n",
    "            value=128,\n",
    "            min=32,\n",
    "            max=512,\n",
    "            step=32,\n",
    "            description='Hidden Dim:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.n_steps_slider = widgets.IntSlider(\n",
    "            value=1000,\n",
    "            min=100,\n",
    "            max=5000,\n",
    "            step=100,\n",
    "            description='Training Steps:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.batch_size_slider = widgets.IntSlider(\n",
    "            value=32,\n",
    "            min=8,\n",
    "            max=128,\n",
    "            step=8,\n",
    "            description='Batch Size:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.grid_size_dropdown = widgets.Dropdown(\n",
    "            options=[6, 8, 10, 12],\n",
    "            value=8,\n",
    "            description='Grid Size:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.epsilon_slider = widgets.FloatSlider(\n",
    "            value=0.3,\n",
    "            min=0.0,\n",
    "            max=1.0,\n",
    "            step=0.1,\n",
    "            description='Epsilon (Îµ-greedy):',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Experiment type\n",
    "        self.experiment_type = widgets.RadioButtons(\n",
    "            options=['Single Experiment', 'Quick Test (100 steps)', 'Hyperparameter Sweep'],\n",
    "            value='Single Experiment',\n",
    "            description='Experiment Type:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Run button\n",
    "        self.run_button = widgets.Button(\n",
    "            description='ðŸš€ Run Experiment',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='200px', height='40px')\n",
    "        )\n",
    "        \n",
    "        # Stop button\n",
    "        self.stop_button = widgets.Button(\n",
    "            description='â¹ï¸ Stop',\n",
    "            button_style='danger',\n",
    "            layout=widgets.Layout(width='100px', height='40px'),\n",
    "            disabled=True\n",
    "        )\n",
    "        \n",
    "        # Progress and output\n",
    "        self.progress_bar = widgets.IntProgress(\n",
    "            value=0,\n",
    "            min=0,\n",
    "            max=100,\n",
    "            description='Progress:',\n",
    "            bar_style='info',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='100%')\n",
    "        )\n",
    "        \n",
    "        self.output_area = widgets.Output(layout={'border': '1px solid black', 'height': '300px'})\n",
    "        \n",
    "        # Results display\n",
    "        self.results_text = widgets.HTML(value=\"<b>Results will appear here after experiment</b>\")\n",
    "        \n",
    "        # Event handlers\n",
    "        self.run_button.on_click(self.run_experiment)\n",
    "        self.stop_button.on_click(self.stop_experiment)\n",
    "        \n",
    "        # Layout\n",
    "        self.setup_layout()\n",
    "    \n",
    "    def setup_layout(self):\n",
    "        \"\"\"Organize widget layout\"\"\"\n",
    "        \n",
    "        # Hyperparameter group\n",
    "        hp_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>ðŸ”§ Hyperparameters</h3>\"),\n",
    "            self.lr_slider,\n",
    "            self.hidden_dim_slider,\n",
    "            self.n_steps_slider,\n",
    "            self.batch_size_slider,\n",
    "            self.grid_size_dropdown,  # Fixed: use dropdown instead of slider\n",
    "            self.epsilon_slider\n",
    "        ])\n",
    "        \n",
    "        # Experiment control group\n",
    "        control_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>âš™ï¸ Experiment Control</h3>\"),\n",
    "            self.experiment_type,\n",
    "            widgets.HBox([self.run_button, self.stop_button])\n",
    "        ])\n",
    "        \n",
    "        # Progress group\n",
    "        progress_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>ðŸ“Š Progress</h3>\"),\n",
    "            self.progress_bar,\n",
    "            self.output_area\n",
    "        ])\n",
    "        \n",
    "        # Results group\n",
    "        results_box = widgets.VBox([\n",
    "            widgets.HTML(\"<h3>ðŸ“ˆ Results</h3>\"),\n",
    "            self.results_text\n",
    "        ])\n",
    "        \n",
    "        # Main layout\n",
    "        self.main_widget = widgets.VBox([\n",
    "            widgets.HTML(\"<h2>ðŸ§ª Trajectory Balance GFlowNet Experiment</h2>\"),\n",
    "            widgets.HBox([hp_box, control_box]),\n",
    "            progress_box,\n",
    "            results_box\n",
    "        ])\n",
    "    \n",
    "    def run_experiment(self, button):\n",
    "        \"\"\"Run the selected experiment\"\"\"\n",
    "        # Disable run button, enable stop button\n",
    "        self.run_button.disabled = True\n",
    "        self.stop_button.disabled = False\n",
    "        \n",
    "        # Clear previous output\n",
    "        self.output_area.clear_output()\n",
    "        self.progress_bar.value = 0\n",
    "        \n",
    "        # Get parameters\n",
    "        params = {\n",
    "            'lr': self.lr_slider.value,\n",
    "            'hidden_dim': self.hidden_dim_slider.value,\n",
    "            'n_steps': self.n_steps_slider.value,\n",
    "            'batch_size': self.batch_size_slider.value,\n",
    "            'grid_size': self.grid_size_dropdown.value,\n",
    "            'epsilon': self.epsilon_slider.value\n",
    "        }\n",
    "        \n",
    "        experiment_type = self.experiment_type.value\n",
    "        \n",
    "        try:\n",
    "            with self.output_area:\n",
    "                print(f\"ðŸš€ Starting {experiment_type}\")\n",
    "                print(f\"Parameters: {params}\")\n",
    "                print(\"-\" * 50)\n",
    "                \n",
    "                if experiment_type == 'Quick Test (100 steps)':\n",
    "                    params['n_steps'] = 100\n",
    "                    final_loss = trajectory_balance_experiment(**params)\n",
    "                    \n",
    "                elif experiment_type == 'Single Experiment':\n",
    "                    final_loss = trajectory_balance_experiment(**params)\n",
    "                    \n",
    "                elif experiment_type == 'Hyperparameter Sweep':\n",
    "                    print(\"Running hyperparameter sweep...\")\n",
    "                    run_trajectory_balance_sweep()\n",
    "                    final_loss = \"Sweep completed\"\n",
    "                \n",
    "                # Update results\n",
    "                self.update_results(final_loss, params)\n",
    "                \n",
    "        except Exception as e:\n",
    "            with self.output_area:\n",
    "                print(f\"âŒ Error: {str(e)}\")\n",
    "            self.results_text.value = f\"<b style='color: red;'>âŒ Experiment failed: {str(e)}</b>\"\n",
    "        \n",
    "        finally:\n",
    "            # Re-enable run button, disable stop button\n",
    "            self.run_button.disabled = False\n",
    "            self.stop_button.disabled = True\n",
    "            self.progress_bar.value = 100\n",
    "            \n",
    "            # Clean up MLflow\n",
    "            try:\n",
    "                mlflow.end_run()\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    def stop_experiment(self, button):\n",
    "        \"\"\"Stop the current experiment\"\"\"\n",
    "        with self.output_area:\n",
    "            print(\"â¹ï¸ Stopping experiment...\")\n",
    "        \n",
    "        # Note: This is a simplified stop - in practice you'd need more complex interruption\n",
    "        self.run_button.disabled = False\n",
    "        self.stop_button.disabled = True\n",
    "        \n",
    "        try:\n",
    "            mlflow.end_run()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def update_results(self, final_loss, params):\n",
    "        \"\"\"Update results display\"\"\"\n",
    "        if isinstance(final_loss, str):\n",
    "            results_html = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: #f0f0f0; border-radius: 5px;'>\n",
    "                <h4>âœ… {final_loss}</h4>\n",
    "                <p><b>Grid Size:</b> {params['grid_size']}x{params['grid_size']}</p>\n",
    "                <p><b>Learning Rate:</b> {params['lr']}</p>\n",
    "                <p><b>Hidden Dim:</b> {params['hidden_dim']}</p>\n",
    "                <p><b>Training Steps:</b> {params['n_steps']}</p>\n",
    "                <p>ðŸ“Š Check MLflow UI for detailed results and visualizations</p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        else:\n",
    "            results_html = f\"\"\"\n",
    "            <div style='padding: 10px; background-color: #f0f0f0; border-radius: 5px;'>\n",
    "                <h4>âœ… Experiment Completed!</h4>\n",
    "                <p><b>Final Loss:</b> {final_loss:.6f}</p>\n",
    "                <p><b>Grid Size:</b> {params['grid_size']}x{params['grid_size']}</p>\n",
    "                <p><b>Learning Rate:</b> {params['lr']}</p>\n",
    "                <p><b>Hidden Dim:</b> {params['hidden_dim']}</p>\n",
    "                <p><b>Training Steps:</b> {params['n_steps']}</p>\n",
    "                <p><b>Batch Size:</b> {params['batch_size']}</p>\n",
    "                <p><b>Epsilon:</b> {params['epsilon']}</p>\n",
    "                <p>ðŸ“Š Check MLflow UI for detailed results and visualizations</p>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        self.results_text.value = results_html\n",
    "    \n",
    "    def display(self):\n",
    "        \"\"\"Display the widget\"\"\"\n",
    "        display(self.main_widget)\n",
    "\n",
    "# ====================================================\n",
    "# Create and Display Widget\n",
    "# ====================================================\n",
    "\n",
    "# Create the widget\n",
    "experiment_widget = TrajectoryBalanceWidget()\n",
    "\n",
    "# Display it\n",
    "experiment_widget.display()\n",
    "\n",
    "# Show MLflow info\n",
    "display(widgets.HTML(\"\"\"\n",
    "<div style='padding: 10px; background-color: #e3f2fd; border-radius: 5px; margin-top: 10px;'>\n",
    "    <h4>ðŸ“Š MLflow Tracking</h4>\n",
    "    <p>Experiments are logged to MLflow. View results at: <a href=\"http://localhost:5000\" target=\"_blank\">http://localhost:5000</a></p>\n",
    "    <p>All visualizations and metrics will be automatically saved and logged.</p>\n",
    "</div>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfffcff-c69d-47ef-9d24-0fc9738f986a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bpygfn\n",
   "language": "python",
   "name": "bpygfn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
